Abstract
"We analyze the effect of using a screening CT-scan for evaluation of
potential COVID-19 infections in order to isolate and perform contact tracing
based upon a viral pneumonia diagnosis. RT-PCR is then used for continued
isolation based upon a COVID diagnosis. Both the low false negative rates and
rapid results of CT-scans lead to dramatically reduced transmission. The
reduction in cases after 60 days with widespread use of CT-scan screening
compared to PCR by itself is as high as $50\times$, and the reduction of
effective reproduction rate $R(t)$ is $0.20$. Our results imply that much more
rapid extinction of COVID is possible by combining social distancing with
CT-scans and contact tracing."
"In this paper we introduce novel Virtual Reality (VR) and Augmented Reality
(AR) treatments to improve the psychological well being of patients in
palliative care, based on interviews with a clinical psychologist who has
successfully implemented VR assisted interventions on palliative care patients
in the Hong Kong hospital system. Our VR and AR assisted interventions are
adaptations of traditional palliative care therapies which simultaneously
facilitate patients communication with family and friends while isolated in
hospital due to physical weakness and COVID-19 related restrictions. The first
system we propose is a networked, metaverse platform for palliative care
patients to create customized virtual environments with therapists, family and
friends which function as immersive and collaborative versions of 'life review'
and 'reminiscence therapy'. The second proposed system will investigate the use
of Mixed Reality telepresence and haptic touch in an AR environment, which will
allow palliative care patients to physically feel friends and family in a
virtual space, adding to the sense of presence and immersion in that
environment."
"From the basic impact of nutrient intake on health maintenance to the
psychosocial benefits of mealtime, great advancements in nutritional sciences
for support of human space travel have occurred over the past 60 years.
Nutrition in space has many areas of impact, including provision of required
nutrients and maintenance of endocrine, immune, and musculoskeletal systems. It
is affected by environmental conditions such as radiation, temperature, and
atmospheric pressures, and these are reviewed. Nutrition with respect to space
flight is closely interconnected with other life sciences research disciplines
including the study of hematology, immunology, as well as neurosensory,
cardiovascular, gastrointestinal, circadian rhythms, and musculoskeletal
physiology. Psychosocial aspects of nutrition are also important for more
productive missions and crew morale. Research conducted to determine the impact
of spaceflight on human physiology and subsequent nutritional requirements will
also have direct and indirect applications in Earth-based nutrition research.
Cumulative nutritional research over the past five decades has resulted in the
current nutritional requirements for astronauts. Realization of the full role
of nutrition during spaceflight is critical for the success of
extended-duration missions. Long-duration missions will require quantitation of
nutrient requirements for maintenance of health and protection against the
effects of microgravity.
  Keywords: Space nutrition, space flight, effects of microgravity, astronauts,
space food"
"Benchmark datasets for digital dermatology unwittingly contain inaccuracies
that reduce trust in model performance estimates. We propose a
resource-efficient data-cleaning protocol to identify issues that escaped
previous curation. The protocol leverages an existing algorithmic cleaning
strategy and is followed by a confirmation process terminated by an intuitive
stopping criterion. Based on confirmation by multiple dermatologists, we remove
irrelevant samples and near duplicates and estimate the percentage of label
errors in six dermatology image datasets for model evaluation promoted by the
International Skin Imaging Collaboration. Along with this paper, we publish
revised file lists for each dataset which should be used for model evaluation.
Our work paves the way for more trustworthy performance assessment in digital
dermatology."
"Many medical and biological protocols for analyzing individual biological
cells involve morphological evaluation based on cell staining, designed to
enhance imaging contrast and enable clinicians and biologists to differentiate
between various cell organelles. However, cell staining is not always allowed
in certain medical procedures. In other cases, staining may be time consuming
or expensive to implement. Here, we present a new deep-learning approach,
called HoloStain, which converts images of isolated biological cells acquired
without staining by holographic microscopy to their virtually stained images.
We demonstrate this approach for human sperm cells, as there is a
well-established protocol and global standardization for characterizing the
morphology of stained human sperm cells for fertility evaluation, but, on the
other hand, staining might be cytotoxic and thus is not allowed during human in
vitro fertilization (IVF). We use deep convolutional Generative Adversarial
Networks (DCGANs) with training that is based on both the quantitative phase
images and two gradient phase images, all extracted from the digital holograms
of the stain-free cells, with the ground truth of bright-field images of the
same cells that subsequently underwent chemical staining. To validate the
quality of our virtual staining approach, an experienced embryologist analyzed
the unstained cells, the virtually stained cells, and the chemically stained
sperm cells several times in a blinded and randomized manner. We obtained a
5-fold recall (sensitivity) improvement in the analysis results. With the
introduction of simple holographic imaging methods in clinical settings, the
proposed method has a great potential to become a common practice in human IVF
procedures, as well as to significantly simplify and facilitate other cell
analyses and techniques such as imaging flow cytometry."
"Sleep has been shown to be an indispensable and important component of
patients recovery process. Nonetheless, sleep quality of patients in the
Intensive Care Unit (ICU) is often low, due to factors such as noise, pain, and
frequent nursing care activities. Frequent sleep disruptions by the medical
staff and/or visitors at certain times might lead to disruption of patient
sleep-wake cycle and can also impact the severity of pain. Examining the
association between sleep quality and frequent visitation has been difficult,
due to lack of automated methods for visitation detection. In this study, we
recruited 38 patients to automatically assess visitation frequency from
captured video frames. We used the DensePose R-CNN (ResNet-101) model to
calculate the number of people in the room in a video frame. We examined when
patients are interrupted the most, and we examined the association between
frequent disruptions and patient outcomes on pain and length of stay."
"In Silico Clinical Trials (ISTC), i.e., clinical experimental campaigns
carried out by means of computer simulations, hold the promise to decrease time
and cost for the safety and efficacy assessment of pharmacological treatments,
reduce the need for animal and human testing, and enable precision medicine. In
this paper we present methods and an algorithm that, by means of extensive
computer simulation--based experimental campaigns (ISTC) guided by intelligent
search, optimise a pharmacological treatment for an individual patient
(precision medicine). e show the effectiveness of our approach on a case study
involving a real pharmacological treatment, namely the downregulation phase of
a complex clinical protocol for assisted reproduction in humans."
"Despite being crucial to health and quality of life, sleep -- especially
pediatric sleep -- is not yet well understood. This is exacerbated by lack of
access to sufficient pediatric sleep data with clinical annotation. In order to
accelerate research on pediatric sleep and its connection to health, we create
the Nationwide Children's Hospital (NCH) Sleep DataBank and publish it at
Physionet and the National Sleep Research Resource (NSRR), which is a large
sleep data common with physiological data, clinical data, and tools for
analyses. The NCH Sleep DataBank consists of 3,984 polysomnography studies and
over 5.6 million clinical observations on 3,673 unique patients between 2017
and 2019 at NCH. The novelties of this dataset include: 1) large-scale sleep
dataset suitable for discovering new insights via data mining, 2) explicit
focus on pediatric patients, 3) gathered in a real-world clinical setting, and
4) the accompanying rich set of clinical data. The NCH Sleep DataBank is a
valuable resource for advancing automatic sleep scoring and real-time sleep
disorder prediction, among many other potential scientific discoveries."
"Timely and adequate rehabilitation is critical in facilitating post-stroke
recovery. However, the organization and delivery of rehabilitation are
resource-demanding, and are only available to approximately 25% of stroke
survivors in low-to-middle-income countries. Improving access to stroke
rehabilitation services through innovative solutions is therefore urgently
required. Tele-rehabilitation, which transits care to home- and community
settings, has emerged as a promising solution. However, current approaches
using video tutorial, teleconference, or other specialized devices face
inherent shortfalls that limit their uptake. In this study, we proposed and
validated the use of an open-source, markerless motion capture model with
consumer-grade devices to overcome these challenges. Our solution enables
reliable measurement of the end range of motion during upper limb exercises
with near-perfect waveform similarity and intraclass correlation to that of the
gold standard Kinect approach. Our multidisciplinary team developed an
automated telerehabilitation framework incorporating the validated markerless
technique to facilitate a seamless telerehabilitation process. It enables
personalized rehabilitation plans with real-time feedback, and individual
progress reports using objective quantitative and qualitative features to
improve patient monitoring and management, and home-based rehabilitation
service uptake and compliance. This study serves as a proof-of-concept in
preparation for the future development of a detailed model of care, and
feasibility, usability, and cost-effectiveness studies of an automated
telerehabilitation platform and framework in improving the state of post-stroke
rehabilitation and functional outcome."
"Diagnosis of pulmonary lesions from computed tomography (CT) is important but
challenging for clinical decision making in lung cancer related diseases. Deep
learning has achieved great success in computer aided diagnosis (CADx) area for
lung cancer, whereas it suffers from label ambiguity due to the difficulty in
the radiological diagnosis. Considering that invasive pathological analysis
serves as the clinical golden standard of lung cancer diagnosis, in this study,
we solve the label ambiguity issue via a large-scale radio-pathomics dataset
containing 5,134 radiological CT images with pathologically confirmed labels,
including cancers (e.g., invasive/non-invasive adenocarcinoma, squamous
carcinoma) and non-cancer diseases (e.g., tuberculosis, hamartoma). This
retrospective dataset, named Pulmonary-RadPath, enables development and
validation of accurate deep learning systems to predict invasive pathological
labels with a non-invasive procedure, i.e., radiological CT scans. A
three-level hierarchical classification system for pulmonary lesions is
developed, which covers most diseases in cancer-related diagnosis. We explore
several techniques for hierarchical classification on this dataset, and propose
a Leaky Dense Hierarchy approach with proven effectiveness in experiments. Our
study significantly outperforms prior arts in terms of data scales (6x larger),
disease comprehensiveness and hierarchies. The promising results suggest the
potentials to facilitate precision medicine."
"Clinical texts, represented in electronic medical records (EMRs), contain
rich medical information and are essential for disease prediction, personalised
information recommendation, clinical decision support, and medication pattern
mining and measurement. Relation extractions between medication mentions and
temporal information can further help clinicians better understand the
patients' treatment history. To evaluate the performances of deep learning (DL)
and large language models (LLMs) in medication extraction and temporal
relations classification, we carry out an empirical investigation of
\textbf{MedTem} project using several advanced learning structures including
BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER),
and BERT-CNN for temporal relation extraction (RE), in addition to the
exploration of different word embedding techniques. Furthermore, we also
designed a set of post-processing roles to generate structured output on
medications and the temporal relation. Our experiments show that CNN-BiLSTM
slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding
75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro
Average. BERT-CNN model also produced reasonable evaluation scores 64.48,
67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction
test set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted
at \url{https://github.com/HECTA-UoM/MedTem}"
"An overview of several standardization activities for machine-to-machine
(M2M) communications is presented, analyzing some of the enabling technologies
and applications of M2M in industry sectors such as Smart Grid and e-Health.
This summary and overview of the ongoing work in M2M from the industrial and
standardization perspective complements the prevalent academic perspective of
such publications to date in this field."
"Optical coherence tomography (OCT) has seen widespread success as an in vivo
clinical diagnostic 3D imaging modality, impacting areas including
ophthalmology, cardiology, and gastroenterology. Despite its many advantages,
such as high sensitivity, speed, and depth penetration, OCT suffers from
several shortcomings that ultimately limit its utility as a 3D microscopy tool,
such as its pervasive coherent speckle noise and poor lateral resolution
required to maintain millimeter-scale imaging depths. Here, we present 3D
optical coherence refraction tomography (OCRT), a computational extension of
OCT which synthesizes an incoherent contrast mechanism by combining multiple
OCT volumes, acquired across two rotation axes, to form a resolution-enhanced,
speckle-reduced, refraction-corrected 3D reconstruction. Our label-free
computational 3D microscope features a novel optical design incorporating a
parabolic mirror to enable the capture of 5D plenoptic datasets, consisting of
millimetric 3D fields of view over up to $\pm75^\circ$ without moving the
sample. We demonstrate that 3D OCRT reveals 3D features unobserved by
conventional OCT in fruit fly, zebrafish, and mouse samples."
"Activation of naive CD8 T-cells can lead to the generation of multiple
effector and memory subsets. Multiple parameters associated with activation
conditions are involved in generating this diversity that is associated with
heterogeneous molecular contents of activated cells. Although naive cell
polarisation upon antigenic stimulation and the resulting asymmetric division
are known to be a major source of heterogeneity and cell fate regulation, the
consequences of stochastic uneven partitioning of molecular content upon
subsequent divisions remain unclear yet. Here we aim at studying the impact of
uneven partitioning on molecular-content heterogeneity and then on the immune
response dynamics at the cellular level. To do so, we introduce a multiscale
mathematical model of the CD8 T-cell immune response in the lymph node. In the
model, cells are described as agents evolving and interacting in a 2D
environment while a set of differential equations, embedded in each cell,
models the regulation of intra and extracellular proteins involved in cell
differentiation. Based on the analysis of in silico data at the single cell
level, we 1 show that immune response dynamics can be explained by the
molecular-content heterogeneity generated by uneven partitioning at cell
division. In particular, uneven partitioning acts as a regulator of cell
differentiation and induces the emergence of two coexisting sub-populations of
cells exhibiting antagonistic fates. We show that the degree of unevenness of
molecular partitioning, along all cell divisions, affects the outcome of the
immune response and can promote the generation of memory cells."
"Successful deployment of machine learning algorithms in healthcare requires
careful assessments of their performance and safety. To date, the FDA approves
locked algorithms prior to marketing and requires future updates to undergo
separate premarket reviews. However, this negates a key feature of machine
learning--the ability to learn from a growing dataset and improve over time.
This paper frames the design of an approval policy, which we refer to as an
automatic algorithmic change protocol (aACP), as an online hypothesis testing
problem. As this process has obvious analogy with noninferiority testing of new
drugs, we investigate how repeated testing and adoption of modifications might
lead to gradual deterioration in prediction accuracy, also known as
``biocreep'' in the drug development literature. We consider simple policies
that one might consider but do not necessarily offer any error-rate guarantees,
as well as policies that do provide error-rate control. For the latter, we
define two online error-rates appropriate for this context: Bad Approval Count
(BAC) and Bad Approval and Benchmark Ratios (BABR). We control these rates in
the simple setting of a constant population and data source using policies
aACP-BAC and aACP-BABR, which combine alpha-investing, group-sequential, and
gate-keeping methods. In simulation studies, bio-creep regularly occurred when
using policies with no error-rate guarantees, whereas aACP-BAC and -BABR
controlled the rate of bio-creep without substantially impacting our ability to
approve beneficial modifications."
"Pediatric brain and spinal cancers remain the leading cause of cancer-related
death in children. Advancements in clinical decision-support in pediatric
neuro-oncology utilizing the wealth of radiology imaging data collected through
standard care, however, has significantly lagged other domains. Such data is
ripe for use with predictive analytics such as artificial intelligence (AI)
methods, which require large datasets. To address this unmet need, we provide a
multi-institutional, large-scale pediatric dataset of 23,101 multi-parametric
MRI exams acquired through routine care for 1,526 brain tumor patients, as part
of the Children's Brain Tumor Network. This includes longitudinal MRIs across
various cancer diagnoses, with associated patient-level clinical information,
digital pathology slides, as well as tissue genotype and omics data. To
facilitate downstream analysis, treatment-na\""ive images for 370 subjects were
processed and released through the NCI Childhood Cancer Data Initiative via the
Cancer Data Service. Through ongoing efforts to continuously build these
imaging repositories, our aim is to accelerate discovery and translational AI
models with real-world data, to ultimately empower precision medicine for
children."
"COVID-19 vaccines have proven to be effective against SARS-CoV-2 infection.
However, the dynamics of vaccine-induced immunological memory development and
neutralizing antibodies generation are not fully understood, limiting vaccine
development and vaccination regimen determination. Herein, we constructed a
mathematical model to characterize the vaccine-induced immune response based on
fitting the viral infection and vaccination datasets. With the example of
CoronaVac, we revealed the association between vaccine-induced immunological
memory development and neutralizing antibody levels. The establishment of the
intact immunological memory requires more than 6 months after the first and
second doses, after that a booster shot can induce high levels neutralizing
antibodies. By introducing the maximum viral load and recovery time after viral
infection, we quantitatively studied the protective effect of vaccines against
viral infection. Accordingly, we optimized the vaccination regimen, including
dose and vaccination timing, and predicted the effect of the fourth dose. Last,
by combining the viral transmission model, we showed the suppression of virus
transmission by vaccination, which may be instructive for the development of
public health policies."
"Compared with 2D MRI, 3D MRI provides superior volumetric spatial resolution
and signal-to-noise ratio. However, it is more challenging to reconstruct 3D
MRI images. Current methods are mainly based on convolutional neural networks
(CNN) with small kernels, which are difficult to scale up to have sufficient
fitting power for 3D MRI reconstruction due to the large image size and GPU
memory constraint. Furthermore, MRI reconstruction is a deconvolution problem,
which demands long-distance information that is difficult to capture by CNNs
with small convolution kernels. The multi-layer perceptron (MLP) can model such
long-distance information, but it requires a fixed input size. In this paper,
we proposed Recon3DMLP, a hybrid of CNN modules with small kernels for
low-frequency reconstruction and adaptive MLP (dMLP) modules with large kernels
to boost the high-frequency reconstruction, for 3D MRI reconstruction. We
further utilized the circular shift operation based on MRI physics such that
dMLP accepts arbitrary image size and can extract global information from the
entire FOV. We also propose a GPU memory efficient data fidelity module that
can reduce $>$50$\%$ memory. We compared Recon3DMLP with other CNN-based models
on a high-resolution (HR) 3D MRI dataset. Recon3DMLP improves HR 3D
reconstruction and outperforms several existing CNN-based models under similar
GPU memory consumption, which demonstrates that Recon3DMLP is a practical
solution for HR 3D MRI reconstruction."
"Web scraping is a technique that allows us to extract data from websites
automatically. in the field of medicine, web scraping can be used to collect
information about medical procedures, treatments, and healthcare providers.
this information can be used to improve patient care, monitor the quality of
healthcare services, and identify areas for improvement. one area where web
scraping can be particularly useful is in medical ministrations. medical
ministrations are the actions taken to provide medical care to patients, and
web scraping can help healthcare providers identify the most effective
ministrations for their patients. for example, healthcare providers can use web
scraping to collect data about the symptoms and medical histories of their
patients, and then use this information to determine the most appropriate
ministrations. they can also use web scraping to gather information about the
latest medical research and clinical trials, which can help them stay
up-to-date with the latest treatments and procedures."
"The present paper aims at introducing the innovative technologies, based on
the concept of ""sensory substitution"" or ""perceptual supplementation"", we are
developing in the fields of human disability and biomedical engineering.
Precisely, our goal is to design, develop and validate practical assistive
biomedical and/technical devices and/or rehabilitating procedures for persons
with disabilities, using artificial tongue-placed tactile biofeedback systems.
Proposed applications are dealing with: (1) pressure sores prevention in case
of spinal cord injuries (persons with paraplegia, or tetraplegia); (2) ankle
proprioceptive acuity improvement for driving assistance in older and/or
disabled adults; and (3) balance control improvement to prevent fall in older
and/or disabled adults. This paper presents results of three feasibility
studies performed on young healthy adults."
"Infectious keratitis is the most common entities of corneal diseases, in
which pathogen grows in the cornea leading to inflammation and destruction of
the corneal tissues. Infectious keratitis is a medical emergency, for which a
rapid and accurate diagnosis is needed for speedy initiation of prompt and
precise treatment to halt the disease progress and to limit the extent of
corneal damage; otherwise it may develop sight-threatening and even
eye-globe-threatening condition. In this paper, we propose a sequential-level
deep learning model to effectively discriminate the distinction and subtlety of
infectious corneal disease via the classification of clinical images. In this
approach, we devise an appropriate mechanism to preserve the spatial structures
of clinical images and disentangle the informative features for clinical image
classification of infectious keratitis. In competition with 421
ophthalmologists, the performance of the proposed sequential-level deep model
achieved 80.00% diagnostic accuracy, far better than the 49.27% diagnostic
accuracy achieved by ophthalmologists over 120 test images."
"Covid-19 is responsible for high mortality in all countries, with the
maternal population it is no different. Countries with a high rate of maternal
mortality have deficiencies in the health care of pregnant women and women who
have recently given birth, which will certainly be enhanced in a situation of
overload in the health system, as occurred in this pandemic. Understanding the
impact of the pandemic on maternal health is essential to discuss public
policies and assist in solutions to future crises. With that in mind, we
present the Brazilian Obstetric Observatory COVID-19 (OOBr COVID-19). OOBr
COVID-19 is a dynamic panel with analyzes of the cases of pregnant and
postpartum women with Severe Acute Respiratory Syndrome (SARI) during the
pandemic due to the new coronavirus. In this article, we present data loading,
case selections, and processing of the variables for the analyzes available in
OOBr COVID-19."
"We explore the upper bound on the tensor-to-scalar ratio $r$ in
supersymmetric (F-term) hybrid inflation models with the gauge symmetry
breaking scale set equal to the value $2.86\cdot10^{16} {\rm GeV}$, as dictated
by the unification of the MSSM gauge couplings. We employ a unique
renormalizable superpotential and a quasi-canonical K\""ahler potential, and the
scalar spectral index $n_s$ is required to lie within the two-sigma interval
from the central value found by the Planck satellite. In a sizable region of
the parameter space the potential along the inflationary trajectory is a
monotonically increasing function of the inflaton, and for this case,
$r\lesssim2.9\cdot10^{-4}$, while the spectral index running, $|dn_{\rm s}/d\ln
k|$, can be as large as $0.01$. Ignoring higher order terms which ensure the
boundedness of the potential for large values of the inflaton, the upper bound
on $r$ is significantly larger, of order $0.01$, for subplanckian values of the
inflaton, and $|dn_{\rm s}/d\ln k|\simeq0.006$."
"In this paper, we examine how deep learning can be utilized to investigate
neural health and the difficulties in interpreting neurological analyses within
algorithmic models. The key contribution of this paper is the investigation of
the impact of a dead neuron on the performance of artificial neural networks
(ANNs). Therefore, we conduct several tests using different training algorithms
and activation functions to identify the precise influence of the training
process on neighboring neurons and the overall performance of the ANN in such
cases. The aim is to assess the potential application of the findings in the
biological domain, the expected results may have significant implications for
the development of effective treatment strategies for neurological disorders.
Successive training phases that incorporate visual and acoustic data derived
from past social and familial experiences could be suggested to achieve this
goal. Finally, we explore the conceptual analogy between the Adam optimizer and
the learning process of the brain by delving into the specifics of both systems
while acknowledging their fundamental differences."
"Adipose tissue (AT) transcriptome studies provide holistic pictures of
adaptation to weight and related bioclinical settings changes. Objective To
implement AT gene expression profiling and investigate the link between changes
in bioclinical parameters and AT gene expression during 3 steps of a 2-phase
dietary intervention (DI). Methods AT transcriptome profiling was obtained from
sequencing 1051 samples, corresponding to 556 distinct individuals enrolled in
a weight loss intervention (8-week low-calorie diet (LCD) at 800 kcal/day)
followed with a 6-month ad libitum randomized DI. Transcriptome profiles
obtained with QuantSeq sequencing were benchmarked against Illumina RNAseq.
Reverse transcription quantitative polymerase chain reaction was used to
further confirm associations. Cell specificity was assessed using freshly
isolated cells and THP-1 cell line. Results During LCD, 5 modules were found,
of which 3 included at least 1 bioclinical variable. Change in body mass index
(BMI) connected with changes in mRNA level of genes with inflammatory response
signature. In this module, change in BMI was negatively associated with changes
in expression of genes encoding secreted protein (GDF15, CCL3, and SPP1).
Through all phases of the DI, change in GDF15 was connected to changes in SPP1,
CCL3, LIPA and CD68. Further characterization showed that these genes were
specific to macrophages (with LIPA, CD68 and GDF15 expressed in
anti-inflammatory macrophages) and GDF15 also expressed in preadipocytes.
Conclusion Network analyses identified a novel AT feature with GDF15
upregulated with calorie restriction induced weight loss, concomitantly to
macrophage markers. In AT, GDF15 was expressed in preadipocytes and macrophages
where it was a hallmark of anti-inflammatory cells."
"The COVID-19 pandemic has highlighted the need for a tool to speed up triage
in ultrasound scans and provide clinicians with fast access to relevant
information. The proposed video-summarization technique is a step in this
direction that provides clinicians access to relevant key-frames from a given
ultrasound scan (such as lung ultrasound) while reducing resource, storage and
bandwidth requirements. We propose a new unsupervised reinforcement learning
(RL) framework with novel rewards that facilitates unsupervised learning
avoiding tedious and impractical manual labelling for summarizing ultrasound
videos to enhance its utility as a triage tool in the emergency department (ED)
and for use in telemedicine. Using an attention ensemble of encoders, the high
dimensional image is projected into a low dimensional latent space in terms of:
a) reduced distance with a normal or abnormal class (classifier encoder), b)
following a topology of landmarks (segmentation encoder), and c) the distance
or topology agnostic latent representation (convolutional autoencoders). The
decoder is implemented using a bi-directional long-short term memory (Bi-LSTM)
which utilizes the latent space representation from the encoder. Our new
paradigm for video summarization is capable of delivering classification labels
and segmentation of key landmarks for each of the summarized keyframes.
Validation is performed on lung ultrasound (LUS) dataset, that typically
represent potential use cases in telemedicine and ED triage acquired from
different medical centers across geographies (India, Spain and Canada)."
"Chinese characters carry a wealth of morphological and semantic information;
therefore, the semantic enhancement of the morphology of Chinese characters has
drawn significant attention. The previous methods were intended to directly
extract information from a whole Chinese character image, which usually cannot
capture both global and local information simultaneously. In this paper, we
develop a stroke-based autoencoder(SAE), to model the sophisticated morphology
of Chinese characters with the self-supervised method. Following its canonical
writing order, we first represent a Chinese character as a series of stroke
images with a fixed writing order, and then our SAE model is trained to
reconstruct this stroke image sequence. This pre-trained SAE model can predict
the stroke image series for unseen characters, as long as their strokes or
radicals appeared in the training set. We have designed two contrasting SAE
architectures on different forms of stroke images. One is fine-tuned on
existing stroke-based method for zero-shot recognition of handwritten Chinese
characters, and the other is applied to enrich the Chinese word embeddings from
their morphological features. The experimental results validate that after
pre-training, our SAE architecture outperforms other existing methods in
zero-shot recognition and enhances the representation of Chinese characters
with their abundant morphological and semantic information."
"Vaccination may be the solution to the pandemic-induced health crisis, but
the allocation of vaccines is a complex task in which economic and social
considerations can be important. The central problem is to use the limited
number of vaccines in a country to reduce the risk of infection and mitigate
economic uncertainty at the same time. In this paper, we propose a simple
economic model for vaccine allocation across two types of workers:
white-collars can work from home; while blue-collars must work on site. These
worker types are complementary to each other, thus a negative shock to the
supply of either one decreases the demand for the other that leads to
unemployment. Using parameters of blue and white-collar labor supply, their
infection risks, productivity losses at home office during lock-down, and
available vaccines, we express the optimal share of vaccines allocated to
blue-collars. The model points to the dominance of blue-collar vaccination,
especially during waves when their relative infection risks increase and when
the number of available vaccines is limited. Taking labor supply data from 28
European countries, we quantify blue-collar vaccine allocation that minimizes
unemployment across levels of blue- and white-collar infection risks. The model
favours blue-collar vaccination identically across European countries in case
of vaccine scarcity. As more vaccines become available, economies that host
large-shares of employees in home-office shall increasingly immunize them in
case blue-collar infection risks can be kept down. Our results highlight that
vaccination plans should include workers and rank them by type of occupation.
We propose that prioritizing blue-collar workers during infection waves and
early vaccination can also favour economy besides helping the most vulnerable
who can transmit more infection."
"Pretrained language models have been used in various natural language
processing applications. In the mental health domain, domain-specific language
models are pretrained and released, which facilitates the early detection of
mental health conditions. Social posts, e.g., on Reddit, are usually long
documents. However, there are no domain-specific pretrained models for
long-sequence modeling in the mental health domain. This paper conducts
domain-specific continued pretraining to capture the long context for mental
health. Specifically, we train and release MentalXLNet and MentalLongformer
based on XLNet and Longformer. We evaluate the mental health classification
performance and the long-range ability of these two domain-specific pretrained
models. Our models are released in HuggingFace."
"Witnessed the development of deep learning in recent years, increasing number
of researches try to adopt deep learning model for medical image analysis.
However, the usage of deep learning networks for the pathological image
analysis encounters several challenges, e.g. high resolution (gigapixel) of
pathological images and lack of annotations of cancer areas. To address the
challenges, we proposed a complete framework for the pathological image
classification, which consists of a novel training strategy, namely reversed
active learning (RAL), and an advanced network, namely atrous DenseNet (ADN).
The proposed RAL can remove the mislabel patches in the training set. The
refined training set can then be used to train widely used deep learning
networks, e.g. VGG-16, ResNets, etc. A novel deep learning network, i.e. atrous
DenseNet (ADN), is also proposed for the classification of pathological images.
The proposed ADN achieves multi-scale feature extraction by integrating the
atrous convolutions to the Dense Block. The proposed RAL and ADN have been
evaluated on two pathological datasets, i.e. BACH and CCG. The experimental
results demonstrate the excellent performance of the proposed ADN + RAL
framework, i.e. the average patch-level ACAs of 94.10% and 92.05% on BACH and
CCG validation sets were achieved."
"Background: Many authors have described MELD as a predictor of short-term
mortality in the liver transplantation waiting list. However MELD score
accuracy to predict long term mortality has not been statistically evaluated.
Objective: The aim of this study is to analyze the MELD score as well as other
variables as a predictor of long-term mortality using a new model: the Survival
Tree analysis. Study Design and Setting: The variables obtained at the time of
liver transplantation list enrollment and considered in this study are: sex,
age, blood type, body mass index, etiology of liver disease, hepatocellular
carcinoma, waiting time for transplant and MELD. Mortality on the waiting list
is the outcome. Exclusion, transplantation or still in the transplantation list
at the end of the study are censored data. Results: The graphical
representation of the survival trees showed that the most statistically
significant cut off is related to MELD score at point 16. Conclusion: The
results are compatible with the cut off point of MELD indicated in the clinical
literature."
"A particular challenge for disease progression modeling is the heterogeneity
of a disease and its manifestations in the patients. Existing approaches often
assume the presence of a single disease progression characteristics which is
unlikely for neurodegenerative disorders such as Parkinson's disease. In this
paper, we propose a hierarchical time-series model that can discover multiple
disease progression dynamics. The proposed model is an extension of an
input-output hidden Markov model that takes into account the clinical
assessments of patients' health status and prescribed medications. We
illustrate the benefits of our model using a synthetically generated dataset
and a real-world longitudinal dataset for Parkinson's disease."
"We formulate and analyze a mathematical model describing immune response to
avascular tumor under the influence of immunotherapy and chemotherapy and their
combinations as well as vaccine treatments. The effect of vaccine therapy is
considered as a parametric perturbation of the model. In the case of a weak
immune response, neither immunotherapy nor chemotherapy is found to cause tumor
regression to a small size, which would be below the clinically detectable
threshold. Numerical simulations show that the efficiency of vaccine therapy
depends on both the tumor size and the condition of immune system as well as on
the response of the organism to vaccination. In particular, we found that
vaccine therapy becomes more effective when used without time delay from a
prescribed date of vaccination after surgery and is ineffective without
preliminary treatment. For a strong immune response, our model predicts the
tumor remission under vaccine therapy. Our study of successive chemo/immuno,
immuno/chemo and concurrent chemoimmunotherapy shows that the chemo/immuno
sequence is more effective while concurrent chemoimmunotherapy is more sparing."
"A mental health crisis is looming large, and needs to be addressed. But
across age groups, even just in the United States, more than 50% of people with
any mental illness (AMI) did not seek or receive any service or treatment. The
proliferation of telehealth and telepsychiatry tools and systems can help
address this crisis, but outside of traditional regulatory aspects on privacy,
e.g. Health Insurance Portability and Accountability Act (HIPPA), there does
not seem to be enough attention on the security needs, concerns, or user
experience of people with AMI using those telehealth systems. In this text, I
try to explore some priority security properties for telehealth systems used by
people with AMI for mental heath services (MHS). I will also suggest some key
steps in a proposed process for designing and building security mechanisms into
such systems, so that security is accessible and usable to patients with AMI,
and these systems can achieve their goals of ameliorate this mental health
crisis."
"We use supersonic shear wave imaging (SSI) technique to measure not only the
linear but also the nonlinear elastic properties of brain matter. Here, we
tested six porcine brains ex vivo and measured the velocities of the plane
shear waves induced by acoustic radiation force at different states of
pre-deformation when the ultrasonic probe is pushed into the soft tissue. We
relied on an inverse method based on the theory governing the propagation of
small-amplitude acoustic waves in deformed solids to interpret the experimental
data. We found that, depending on the subjects, the resulting initial shear
modulus mu0 varies from 1.8 to 3.2 kPa, the stiffening parameter b of the
hyperelastic Demiray-Fung model from 0.13 to 0.73, and the third- (A) and
fourth-order (D) constants of weakly nonlinear elasticity from -1.3 to -20.6
kPa and from 3.1 to 8.7 kPa, respectively. Paired t-test performed on the
experimental results of the left and right lobes of the brain shows no
significant difference. These values are in line with those reported in the
literature on brain tissue, indicating that the SSI method, combined to the
inverse analysis, is an efficient and powerful tool for the mechanical
characterization of brain tissue, which is of great importance for computer
simulation of traumatic brain injury and virtual neurosurgery."
"Surgical robotics is a rising field in medical technology and advanced
robotics. Robot assisted surgery, or robotic surgery, allows surgeons to
perform complicated surgical tasks with more precision, automation, and
flexibility than is possible for traditional surgical approaches. The main type
of robot assisted surgery is minimally invasive surgery, which could be
automated and result in a faster healing time for the patient. The surgical
robot we are particularly interested in is the da Vinci surgical system, which
is developed and manufactured by Intuitive Surgical. In the current iteration
of the system, the endoscopic camera arm on the da Vinci robot has to be
manually controlled and calibrated by the surgeon during a surgical task, which
interrupts the flow of the operation. The main goal of this capstone project is
to automate the motion of the camera arm using a probabilistic model based on
surgeon eye gaze data and da Vinci robot kinematic data."
"Obstructive sleep apnea is a serious condition causing a litany of health
problems especially in the pediatric population. However, this chronic
condition can be treated if diagnosis is possible. The gold standard for
diagnosis is an overnight sleep study, which is often unobtainable by many
potentially suffering from this condition. Hence, we attempt to develop a fast
non-invasive diagnostic tool by training a classifier on 2D and 3D facial
images of a patient to recognize facial features associated with obstructive
sleep apnea. In this comparative study, we consider both persistent homology
and geometric shape analysis from the field of computational topology as well
as convolutional neural networks, a powerful method from deep learning whose
success in image and specifically facial recognition has already been
demonstrated by computer scientists."
"The paper considers existence results of solution for a linear coupled system
of Boltzmann transport equations and related inverse problem. The system models
the evolution of three species of particles, photons, electrons and positrons.
Hyper-singularities of differential cross sections associated with charged
particle transport cause that modelling contains the first order partial
differential term with respect to energy and the second order partial
differential term with respect to velocity angle. The overall system is a
partial integro-differential equation. The model is intended especially for
dose calculation in the forward problem of radiation therapy. Firstly we
consider a single transport equation for charged particles. After that we
verify under physically relevant assumptions that the coupled equation together
with relevant initial and inflow boundary values has a unique solution in
appropriate $L^2$-based spaces. The existence of solutions for the adjoint
problem is verified as well. Moreover, we deal with the related inverse
problem, a so called inverse radiation treatment planning problem. It is
formulated as an optimal boundary control problem. Variational equations for an
optimal control related to an appropriate differentiable strictly convex object
function are verified. Its solution can be used as an initial point for an
actual optimization which needs global optimization methods."
"How to induce differentiated cells into pluripotent cells has elicited
researchers' interests for a long time since pluripotent stem cells are able to
offer remarkable potential in numerous subfields of biological research.
However, the nature of cell reprogramming, especially the mechanisms still
remain elusive for the sake of most protocols of inducing pluripotent stem
cells were discovered by screening but not from the knowledge of gene
regulation networks. Generally there are two hypotheses to elucidate the
mechanism termed as elite model and stochastic model which regard reprogramming
process a deterministic process or a stochastic process, respectively. However,
the difference between these two models cannot yet be discriminated
experimentally. Here we used a general mathematical model to elucidate the
nature of cell reprogramming which can fit both hypotheses. We investigated
this process from a novel perspective, the timing. We calculated the time of
reprogramming in a general way and find that noise would play a significant
role if the stochastic hypothesis holds. Thus the two hypotheses may be
discriminated experimentally by counting the time of reprogramming in different
magnitudes of noise. Because our approach is general, our results should
facilitate broad studies of rational design of cell reprogramming protocols."
"Epidemiological compartmental models are useful for understanding infectious
disease propagation and directing public health policy decisions. Calibration
of these models is an important step in offering accurate forecasts of disease
dynamics and the effectiveness of interventions. In this study, we present an
overview of calibrating strategies that can be employed, including several
optimization methods and reinforcement learning (RL). We discuss the benefits
and drawbacks of these methods and highlight relevant practical conclusions
from our experiments. Optimization methods iteratively adjust the parameters of
the model until the model output matches the available data, whereas RL uses
trial and error to learn the optimal set of parameters by maximizing a reward
signal. Finally, we discuss how the calibration of parameters of
epidemiological compartmental models is an emerging field that has the
potential to improve the accuracy of disease modeling and public health
decision-making. Further research is needed to validate the effectiveness and
scalability of these approaches in different epidemiological contexts. All
codes and resources are available on
\url{https://github.com/Nikunj-Gupta/On-the-Calibration-of-Compartmental-Epidemiological-Models}.
We hope this work can facilitate related research."
"Computational Intelligence (CI) in computer games plays an important role
that could simulate various aspects of real-life problems. CI in real-time
decision-making games can provide a platform for the examination of tree search
algorithms. In this paper, we present a rehabilitation serious game (ReHabgame)
in which the Monte-Carlo Tree Search (MCTS) algorithm is utilized. The game is
designed to combat the physical impairment of post-stroke/brain injury
casualties in order to improve upper limb movement. Through the process of
ReHabgame the player chooses paths via upper limb according to his/her movement
ability to reach virtual goal objects. The system adjusts the difficulty level
of the game based on the player's quality of activity through MCTS. It learns
from the movements made by a player and generates further subsequent objects
for collection. The system collects orientation, muscle and joint activity data
and utilizes them to make decisions. Players data are collected through Kinect
Xbox One and Myo Armband. The results show the effectiveness of the MCTS in the
ReHabgame that progresses from highly achievable paths to the less achievable
ones, thus configuring and personalizing the rehabilitation process."
"Next-generation sequencing technology enables routine detection of bacterial
pathogens for clinical diagnostics and genetic research. Whole genome
sequencing has been of importance in the epidemiologic analysis of bacterial
pathogens. However, few whole genome sequencing-based genotyping pipelines are
available for practical applications. Here, we present the whole genome
sequencing-based single nucleotide polymorphism (SNP) genotyping method and
apply to the evolutionary analysis of methicillin-resistant Staphylococcus
aureus. The SNP genotyping method calls genome variants using next-generation
sequencing reads of whole genomes and calculates the pair-wise Jaccard
distances of the genome variants. The method may reveal the high-resolution
whole genome SNP profiles and the structural variants of different isolates of
methicillin-resistant S. aureus (MRSA) and methicillin-susceptible S. aureus
(MSSA) strains. The phylogenetic analysis of whole genomes and particular
regions may monitor and track the evolution and the transmission dynamic of
bacterial pathogens. The computer programs of the whole genome sequencing-based
SNP genotyping method are available to the public at
https://github.com/cyinbox/NGS."
"Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Due to rapid
technological advances and their extreme versatility, LLMs nowadays have
millions of users and are at the cusp of being the main go-to technology for
information retrieval, content generation, problem-solving, etc. Therefore, it
is of great importance to thoroughly assess and scrutinize their capabilities.
Due to increasingly complex and novel behavioral patterns in current LLMs, this
can be done by treating them as participants in psychology experiments that
were originally designed to test humans. For this purpose, the paper introduces
a new field of research called ""machine psychology"". The paper outlines how
different subfields of psychology can inform behavioral tests for LLMs. It
defines methodological standards for machine psychology research, especially by
focusing on policies for prompt designs. Additionally, it describes how
behavioral patterns discovered in LLMs are to be interpreted. In sum, machine
psychology aims to discover emergent abilities in LLMs that cannot be detected
by most traditional natural language processing benchmarks."
"Vaccination is essential for the management of infectious diseases, many of
which continue to pose devastating public health and economic challenges across
the world. However, many vaccines are imperfect having only a partial
protective effect in decreasing disease transmission and/or favouring recovery
of infected individuals, and possibly exhibiting trade-off between these two
properties. Furthermore, population turnover, that is the rate at which
individuals enter and exit the population, is another key factor determining
the epidemiological dynamics. While these factors have yet been studied
separately, we investigate the interplay between the efficiency and property of
an imperfect vaccine and population turnover. We build a mathematical model
with frequency incidence rate, a recovered compartment, and an heterogeneous
host population with respect to vaccination. We first compute the basic
reproduction number $\mathcal{R}_0$ and study the global stability of the
equilibrium points. Using a sensitivity analysis, we then assess the most
influential parameters determining the total number of infected and
$\mathcal{R}_0$ over time. We derive analytically and numerically conditions
for the vaccination coverage and efficiency to achieve disease eradication
($\mathcal{R}_0 < 1$) assuming different intensity of the population turnover
(weak and strong), vaccine properties (transmission and/or recovery) and
trade-off between the latter. We show that the minimum vaccination coverage
increases with lower population turnover, decreases with higher vaccine
efficiency (transmission or recovery), and is increased/decreased by up to 15\%
depending on the trade-off between the vaccine properties. We conclude that the
coverage target for vaccination campaigns should be evaluated based on the
interplay between these factors."
"The COVID-19 pandemic has devastated the world in an unprecedented way,
causing enormous loss of life. Time and again, public health authorities have
urged people to become vaccinated to protect themselves and mitigate the spread
of the disease. However, vaccine hesitancy has stalled vaccination levels in
the United States. This study explores the effect of vaccine hesitancy on the
spread of disease by introducing an SIRS-V$_\kappa$ model, with compartments of
susceptible (S), infected (I), recovered (R), and vaccinated (V). We leverage
the concept of carrying capacity to account for vaccine hesitancy by defining a
vaccine confidence level $\kappa$, which is the maximum number of people that
will become vaccinated during the course of a disease. The inverse of vaccine
confidence is vaccine hesitance, $(\frac{1}{\kappa})$. We explore the
equilibria of the SIRS-V$_\kappa$ model and their stability, and illustrate the
impact of vaccine hesitance on epidemic spread analytically and via
simulations."
"Automatic identification of clinical trials for which a patient is eligible
is complicated by the fact that trial eligibility is stated in natural
language. A potential solution to this problem is to employ text classification
methods for common types of eligibility criteria. In this study, we focus on
seven common exclusion criteria in cancer trials: prior malignancy, human
immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,
drug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase
III cancer trials with these exclusions annotated at the trial level. We
experiment with common transformer models as well as a new pre-trained clinical
trial BERT model. Our results demonstrate the feasibility of automatically
classifying common exclusion criteria. Additionally, we demonstrate the value
of a pre-trained language model specifically for clinical trials, which yields
the highest average performance across all criteria."
"In recent years, cancer genome sequencing and other high-throughput studies
of cancer genomes have generated many notable discoveries. In this review,
Novel genomic alteration mechanisms, such as chromothripsis (chromosomal
crisis) and kataegis (mutation storms), and their implications for cancer are
discussed. Genomic alterations spur cancer genome evolution. Thus, the
relationship between cancer clonal evolution and cancer stems cells is
commented. The key question in cancer biology concerns how these genomic
alterations support cancer development and metastasis in the context of
biological functioning. Thus far, efforts such as pathway analysis have
improved the understanding of the functional contributions of genetic mutations
and DNA copy number variations to cancer development, progression and
metastasis. However, the known pathways correspond to a small fraction,
plausibly 5-10%, of somatic mutations and genes with an altered copy number. To
develop a comprehensive understanding of the function of these genomic
alterations in cancer, an integrative network framework is proposed and
discussed. Finally, the challenges and the directions of studying cancer omic
data using an integrative network approach are commented."
"T cells monitor the health status of cells by identifying foreign peptides
displayed on their surface. T-cell receptors (TCRs), which are protein
complexes found on the surface of T cells, are able to bind to these peptides.
This process is known as TCR recognition and constitutes a key step for immune
response. Optimizing TCR sequences for TCR recognition represents a fundamental
step towards the development of personalized treatments to trigger immune
responses killing cancerous or virus-infected cells. In this paper, we
formulated the search for these optimized TCRs as a reinforcement learning (RL)
problem, and presented a framework TCRPPO with a mutation policy using proximal
policy optimization. TCRPPO mutates TCRs into effective ones that can recognize
given peptides. TCRPPO leverages a reward function that combines the
likelihoods of mutated sequences being valid TCRs measured by a new scoring
function based on deep autoencoders, with the probabilities of mutated
sequences recognizing peptides from a peptide-TCR interaction predictor. We
compared TCRPPO with multiple baseline methods and demonstrated that TCRPPO
significantly outperforms all the baseline methods to generate positive binding
and valid TCRs. These results demonstrate the potential of TCRPPO for both
precision immunotherapy and peptide-recognizing TCR motif discovery."
"This paper introduces a new Finite Element biomechanical model of the human
face, which has been developed to be integrated into a simulator for plastic
and maxillo-facial surgery. The idea is to be able to predict, from an
aesthetic and functional point of view, the deformations of a patient face,
resulting from repositioning of the maxillary and mandibular bone structures.
This work will complete the simulator for bone-repositioning diagnosis that has
been developed by the laboratory. After a description of our research project
context, each step of the modeling is precisely described: the continuous and
elastic structure of the skin tissues, the orthotropic muscular fibers and
their insertions points, and the functional model of force generation. First
results of face deformations due to muscles activations are presented. They are
qualitatively compared to the functional studies provided by the literature on
face muscles roles and actions."
"Alzheimers Disease AD is an acute neuro disease that degenerates the brain
cells and thus leads to memory loss progressively. It is a fatal brain disease
that mostly affects the elderly. It steers the decline of cognitive and
biological functions of the brain and shrinks the brain successively, which in
turn is known as Atrophy. For an accurate diagnosis of Alzheimers disease,
cutting edge methods like machine learning are essential. Recently, machine
learning has gained a lot of attention and popularity in the medical industry.
As the illness progresses, those with Alzheimers have a far more difficult time
doing even the most basic tasks, and in the worst case, their brain completely
stops functioning. A persons likelihood of having early-stage Alzheimers
disease may be determined using the ML method. In this analysis, papers on
Alzheimers disease diagnosis based on deep learning techniques and
reinforcement learning between 2008 and 2023 found in google scholar were
studied. Sixty relevant papers obtained after the search was considered for
this study. These papers were analysed based on the biomarkers of AD and the
machine-learning techniques used. The analysis shows that deep learning methods
have an immense ability to extract features and classify AD with good accuracy.
The DRL methods have not been used much in the field of image processing. The
comparison results of deep learning and reinforcement learning illustrate that
the scope of Deep Reinforcement Learning DRL in dementia detection needs to be
explored."
"We extended dynamic time warping (DTW) into interval-based dynamic time
warping (iDTW), including (A) interval-based representation (iRep): [1]
abstracting raw, time-stamped data into interval-based abstractions, [2]
comparison-period scoping, [3] partitioning abstract intervals into a given
temporal granularity; (B) interval-based matching (iMatch): matching
partitioned, abstract-concepts records, using a modified DTW. Using domain
knowledge, we abstracted the raw data of medical records, for up to three
concepts out of four or five relevant concepts, into two interval types: State
abstractions (e.g. LOW, HIGH) and Gradient abstractions (e.g. INCREASING,
DECREASING). We created all uni-dimensional (State or Gradient) or
multi-dimensional (State and Gradient) abstraction combinations. Tasks:
Classifying 161 oncology patients records as autologous or allogenic
bone-marrow transplantation; classifying 125 hepatitis patients records as B or
C hepatitis; predicting micro- or macro-albuminuria in the next year for 151
Type 2 diabetes patients. We used a k-Nearest-Neighbors majority, k = an odd
number from 1 to SQRT(N), N = set size. 75,936 10-fold cross-validation
experiments were performed: 33,600 (Oncology), 28,800 (Hepatitis), 13,536
(Diabetes). Measures: Area Under the Curve (AUC), optimal Youden's Index.
Paired t-tests compared result vectors for equivalent configurations other than
a tested variable, to determine a significant mean accuracy difference
(P<0.05). Mean classification and prediction using abstractions was
significantly better than using only raw time-stamped data. In each domain, at
least one abstraction combination led to a significantly better mean
performance than raw data. Increasing feature number and using
Multi-dimensional abstractions enhanced performance. Unlike when using raw
data, optimal mean performance was often reached with k=5, using abstractions."
"It is well-known that mood and pain interact with each other, however
individual-level variability in this relationship has been less well quantified
than overall associations between low mood and pain. Here, we leverage the
possibilities presented by mobile health data, in particular the ""Cloudy with a
Chance of Pain"" study, which collected longitudinal data from the residents of
the UK with chronic pain conditions. Participants used an App to record
self-reported measures of factors including mood, pain and sleep quality. The
richness of these data allows us to perform model-based clustering of the data
as a mixture of Markov processes. Through this analysis we discover four
endotypes with distinct patterns of co-evolution of mood and pain over time.
The differences between endotypes are sufficiently large to play a role in
clinical hypothesis generation for personalised treatments of comorbid pain and
low mood."
"The radiotherapy of malignant diseases has reached much progress during the
past decade. Thus, intensity modulated radiation therapy (IMRT) and VMAT
(Rapidarc) now belong to the standard modalities of tumor treatment with high
energy radiation in clinical practice. In recent time, the particle therapy
(protons and partially with heavy carbon ions) has reached an important
completion of these modalities with regard to some suitable applications. In
spite of this enrichment essential features need further research activities
and publications in this field: Nuclear reactions and the role of the released
neutrons, electron capture of positively charged nuclei at lower projectile
energies (e.g. in the environment of the Bragg peak and at the distal end of
the particle track), correct dose delivery in scanning methods by accounting
for the influence of the lateral scatter of beam-lets. Deconvolution methods
can help to overcome these problems, which already occur in radiotherapy of
very small photon beams [1 - 8]."
"Tuberculosis (TB) is still considered a leading cause of death and a
substantial threat to global child health. Both TB infection and disease are
curable using antibiotics. However, most children who die of TB are never
diagnosed or treated. In clinical practice, experienced physicians assess TB by
examining chest X-rays (CXR). Pediatric CXR has specific challenges compared to
adult CXR, which makes TB diagnosis in children more difficult. Computer-aided
diagnosis systems supported by Artificial Intelligence have shown performance
comparable to experienced radiologist TB readings, which could ease mass TB
screening and reduce clinical burden. We propose a multi-view deep
learning-based solution which, by following a proposed template, aims to
automatically regionalize and extract lung and mediastinal regions of interest
from pediatric CXR images where key TB findings may be present. Experimental
results have shown accurate region extraction, which can be used for further
analysis to confirm TB finding presence and severity assessment. Code publicly
available at https://github.com/dani-capellan/pTB_LungRegionExtractor."
"This article presents our steps to integrate complex and partly unstructured
medical data into a clinical research database with subsequent decision
support. Our main application is an integrated faceted search tool, accompanied
by the visualisation of results of automatic information extraction from
textual documents. We describe the details of our technical architecture
(open-source tools), to be replicated at other universities, research
institutes, or hospitals. Our exemplary use cases are nephrology and
mammography. The software was first developed in the nephrology domain and then
adapted to the mammography use case. We report on these case studies,
illustrating how the application can be used by a clinician and which questions
can be answered. We show that our architecture and the employed software
modules are suitable for both areas of application with a limited amount of
adaptations. For example, in nephrology we try to answer questions about the
temporal characteristics of event sequences to gain significant insight from
the data for cohort selection. We present a versatile time-line tool that
enables the user to explore relations between a multitude of diagnosis and
laboratory values."
"Eating behaviors among a large population of children are studied as a
dynamic process driven by nonlinear interactions in the sociocultural school
environment. The impact of food association learning on diet dynamics, inspired
by a pilot study conducted among Arizona children in Pre-Kindergarten to 8th
grades, is used to build simple population-level learning models.
Qualitatively, mathematical studies are used to highlight the possible
ramifications of instruction, learning in nutrition, and health at the
community level. Model results suggest that nutrition education programs at the
population-level have minimal impact on improving eating behaviors, findings
that agree with prior field studies. Hence, the incorporation of food
association learning may be a better strategy for creating resilient
communities of healthy and non-healthy eaters. A \textit{Ratatouille} effect
can be observed when food association learners become food preference learners,
a potential sustainable behavioral change, which in turn, may impact the
overall distribution of healthy eaters. In short, this work evaluates the
effectiveness of population-level intervention strategies and the importance of
institutionalizing nutrition programs that factor in economical, social,
cultural, and environmental elements that mesh well with the norms and values
in the community."
"Alzheimer's Disease (AD) is one of the most concerned neurodegenerative
diseases. In the last decade, studies on AD diagnosis attached great
significance to artificial intelligence (AI)-based diagnostic algorithms. Among
the diverse modality imaging data, T1-weighted MRI and 18F-FDGPET are widely
researched for this task. In this paper, we propose a novel convolutional
neural network (CNN) to fuse the multi-modality information including T1-MRI
and FDG-PDT images around the hippocampal area for the diagnosis of AD.
Different from the traditional machine learning algorithms, this method does
not require manually extracted features, and utilizes the stateof-art 3D
image-processing CNNs to learn features for the diagnosis and prognosis of AD.
To validate the performance of the proposed network, we trained the classifier
with paired T1-MRI and FDG-PET images using the ADNI datasets, including 731
Normal (NL) subjects, 647 AD subjects, 441 stable MCI (sMCI) subjects and 326
progressive MCI (pMCI) subjects. We obtained the maximal accuracies of 90.10%
for NL/AD task, 87.46% for NL/pMCI task, and 76.90% for sMCI/pMCI task. The
proposed framework yields comparative results against state-of-the-art
approaches. Moreover, the experimental results have demonstrated that (1)
segmentation is not a prerequisite by using CNN, (2) the hippocampal area
provides enough information to give a reference to AD diagnosis. Keywords:
Alzheimer's Disease, Multi-modality, Image Classification, CNN, Deep Learning,
Hippocampal"
"The emergence of artificial general intelligence (AGI) is transforming
radiation oncology. As prominent vanguards of AGI, large language models (LLMs)
such as GPT-4 and PaLM 2 can process extensive texts and large vision models
(LVMs) such as the Segment Anything Model (SAM) can process extensive imaging
data to enhance the efficiency and precision of radiation therapy. This paper
explores full-spectrum applications of AGI across radiation oncology including
initial consultation, simulation, treatment planning, treatment delivery,
treatment verification, and patient follow-up. The fusion of vision data with
LLMs also creates powerful multimodal models that elucidate nuanced clinical
patterns. Together, AGI promises to catalyze a shift towards data-driven,
personalized radiation therapy. However, these models should complement human
expertise and care. This paper provides an overview of how AGI can transform
radiation oncology to elevate the standard of patient care in radiation
oncology, with the key insight being AGI's ability to exploit multimodal
clinical data at scale."
"This paper describes current progress on developing an ethical architecture
for robots that are designed to follow human ethical decision-making processes.
We surveyed both regular adults (folks) and ethics experts (experts) on what
they consider to be ethical behavior in two specific scenarios: pill-sorting
with an older adult and game playing with a child. A key goal of the surveys is
to better understand human ethical decision-making. In the first survey, folk
responses were based on the subject's ethical choices (""folk morality""); in the
second survey, expert responses were based on the expert's application of
different formal ethical frameworks to each scenario. We observed that most of
the formal ethical frameworks we included in the survey (Utilitarianism,
Kantian Ethics, Ethics of Care and Virtue Ethics) and ""folk morality"" were
conservative toward deception in the high-risk task with an older adult when
both the adult and the child had significant performance deficiencies."
"Mutual exclusivity is a widely recognized property of many cancer drivers.
Knowledge about these relationships can provide important insights into cancer
drivers, cancer-driving pathways, and cancer subtypes. It can also be used to
predict new functional interactions between cancer driving genes and uncover
novel cancer drivers. Currently, most of mutual exclusivity analyses are
preformed focusing on a limited set of genes in part due to the computational
cost required to rigorously compute p-values. To reduce the computing cost and
perform less restricted mutual exclusivity analysis, we developed an efficient
method to estimate p-values while controlling the mutation rates of individual
patients and genes similar to the permutation test. A comprehensive mutual
exclusivity analysis allowed us to uncover mutually exclusive pairs, some of
which may have relatively low mutation rates. These pairs often included likely
cancer drivers that have been missed in previous analyses. More importantly,
our results demonstrated that mutual exclusivity can also provide information
that goes beyond the interactions between cancer drivers and can, for example,
elucidate different mutagenic processes in different cancer groups. In
particular, including frequently mutated, long genes such as TTN in our
analysis allowed us to observe interesting patterns of APOBEC activity in
breast cancer and identify a set of related driver genes that are highly
predictive of patient survival. In addition, we utilized our mutual exclusivity
analysis in support of a previously proposed model where APOBEC activity is the
underlying process that causes TP53 mutations in a subset of breast cancer
cases."
"he segment minimization problem consists of finding the smallest set of
integer matrices that sum to a given intensity matrix, such that each summand
has only one non-zero value, and the non-zeroes in each row are consecutive.
This has direct applications in intensity-modulated radiation therapy, an
effective form of cancer treatment. We develop three approximation algorithms
for matrices with arbitrarily many rows. Our first two algorithms improve the
approximation factor from the previous best of $1+\log_2 h $ to (roughly) $3/2
\cdot (1+\log_3 h)$ and $11/6\cdot(1+\log_4{h})$, respectively, where $h$ is
the largest entry in the intensity matrix. We illustrate the limitations of the
specific approach used to obtain these two algorithms by proving a lower bound
of $\frac{(2b-2)}{b}\cdot\log_b{h} + \frac{1}{b}$ on the approximation
guarantee. Our third algorithm improves the approximation factor from $2 \cdot
(\log D+1)$ to $24/13 \cdot (\log D+1)$, where $D$ is (roughly) the largest
difference between consecutive elements of a row of the intensity matrix.
Finally, experimentation with these algorithms shows that they perform well
with respect to the optimum and outperform other approximation algorithms on
77% of the 122 test cases we consider, which include both real world and
synthetic data."
"In this paper, we present a hybrid deep learning framework named CTNet which
combines convolutional neural network and transformer together for the
detection of COVID-19 via 3D chest CT images. It consists of a CNN feature
extractor module with SE attention to extract sufficient features from CT
scans, together with a transformer model to model the discriminative features
of the 3D CT scans. Compared to previous works, CTNet provides an effective and
efficient method to perform COVID-19 diagnosis via 3D CT scans with data
resampling strategy. Advanced results on a large and public benchmarks,
COV19-CT-DB database was achieved by the proposed CTNet, over the
state-of-the-art baseline approachproposed together with the dataset."
"Pregnant women have increased susceptibility to malaria infection. In these
women, malaria parasites are frequently found sequestered in the placental
intervillous spaces, a condition referred to as placental malaria (PM).
Placental malaria threatens the health of the mother and the child's life by
causing still births and reduction in gestational age. An estimated 24 million
pregnant women in Sub-Saharan Africa are at risk. Mechanisms responsible for
increased susceptibility in pregnant women are not fully understood. Pregnancy
malaria studies have been limited by the lack of a suitable animal model. This
research aimed to develop a baboon (Papio anubis) model for studying PM. The
pregnancies of three adult female baboons were synchronized and their
gestational levels confirmed by ultrasonography. On the 150th day of gestation
the pregnant baboons were infected with Plasmodium knowlesi H strain parasites
together with four nulligravid control baboons. Parasitaemia was monitored from
two days post inoculation until the 159th day of gestation when caesarean
section was done on one baboon in order to obtain the placenta. Two baboons
aborted their conceptus. Smears prepared from placental blood demonstrated the
presence of Plasmodium knowlesi parasites in all the three sampled placentas.
These new findings show that P. knowlesi sequesters in the baboon placenta. In
addition, this study has characterized haemoglobin, eosinophil, Immunoglobulin
G and Immunoglobulin M profiles in this model. Thus a non human primate
(baboon) model for studying PM has been established. The established baboon -
P. knowlesi model for studying human placental/pregnancy malaria now offers an
opportunity for circumventing the obstacles experienced during human studies
like having inadequate tissue for analysis, inaccurate estimation of
gestational age, moral, ethical and financial limitations."
"For a genomically unstable cancer, a single tumour biopsy will often contain
a mixture of competing tumour clones. These tumour clones frequently differ
with respect to their genomic content (copy number of each gene) and structure
(order of genes on each chromosome). Modern bulk genome sequencing mixes the
signals of tumour clones and contaminating normal cells, complicating inference
of genomic content and structure. We propose a method to unmix tumour and
contaminating normal signals and jointly predict genomic structure and content
of each tumour clone. We use genome graphs to represent tumour clones, and
model the likelihood of the observed reads given clones and mixing proportions.
Our use of haplotype blocks allows us to accurately measure allele specific
read counts, and infer allele specific copy number for each clone. The proposed
method is a heuristic local search based on applying incremental, locally
optimal modifications of the genome graphs. Using simulated data, we show that
our method predicts copy counts and gene adjacencies with reasonable accuracy."
"Understanding human behavior and monitoring mental health are essential to
maintaining the community and society's safety. As there has been an increase
in mental health problems during the COVID-19 pandemic due to uncontrolled
mental health, early detection of mental issues is crucial. Nowadays, the usage
of Intelligent Virtual Personal Assistants (IVA) has increased worldwide.
Individuals use their voices to control these devices to fulfill requests and
acquire different services. This paper proposes a novel deep learning model
based on the gated recurrent neural network and convolution neural network to
understand human emotion from speech to improve their IVA services and monitor
their mental health."
"A knot in the 3-sphere is called an L--space knot if it admits a nontrivial
Dehn surgery yielding an L--space. Like torus knots and Berge knots, many
L--space knots admit also a Seifert fibered surgery. We give a concrete example
of a hyperbolic, L-space knot which has no exceptional surgeries, in
particular, no Seifert fibered surgeries."
"Tuberculosis (TB) remains a major global health concern, necessitating the
exploration of novel drug delivery systems to combat the challenges posed by
conventional approaches. We investigated the potential of monolayer transition
metal dichalcogenides (TMDs) as an innovative platform for efficient and
targeted delivery of antituberculosis drugs. Specifically, the electronic and
optical properties of prominent TB drugs, isoniazid (INH) and pyrazinamide
(PZA), adsorbed on tungsten diselenide (WSe2) and tungsten disulfide (WS2)
monolayers were studied using first-principles calculations based on density
functional theory (DFT). The investigation revealed that the band gaps of WSe2
and WS2 monolayers remain unaltered upon adsorption of PZA or INH, with
negative adsorption energy indicating stable physisorption. We explored
different vertical and horizontal configurations, and the horizontal ones were
more stable. Moreover, the adsorbed drugs could be readily released by light
within the visible or near-infrared (NIR) wavelength range. This opened up
possibilities for their potential application in photothermal therapy,
harnessing the unique properties of these 2D materials. The optical responses
of anti-TB drugs adsorbed in 2D WSe2 and WS2 were similar to pristine 2D WSe2
and WS2. We demonstrated the temperature-dependent release mechanism of our 2D
WSe2 and WS2 drug complexes, confirming the feasibility of releasing the
discussed anti-tuberculosis drugs by generating heat through photothermal
therapy. These findings hold significant promise for developing innovative drug
delivery systems that have enhanced efficacy for targeted and low-toxic TB
treatment."
"Understanding cell fate patterning and morphogenesis in the mammalian embryo
remains a formidable challenge. Recently, in vivo models based on embryonic
stem cells (ESCs) have emerged as complementary methods to quantitatively
dissect the physical and molecular processes that shape the embryo. Here we
review recent developments in using embryonic stem cells to create both two and
three-dimensional culture models that shed light on mammalian gastrulation."
"Outcomes in stem cell transplantation (SCT) are modeled using probability
theory. However the clinical course following SCT appears to demonstrate many
characteristics of dynamical systems, especially when outcomes are considered
in the context of immune reconstitution. Dynamical systems tend to evolve over
time according to mathematically determined rules. Characteristically, the
future states of the system are predicated on the states preceding them, and
there is sensitivity to initial conditions. In SCT, the interaction between
donor T cells and the recipient may be considered as such a system in which,
graft source, conditioning and early immunosuppression profoundly influence
immune reconstitution over time. This eventually determines clinical outcomes,
either the emergence of tolerance or the development of graft versus host
disease. In this paper parallels between SCT and dynamical systems are explored
and a conceptual framework for developing mathematical models to understand
disparate transplant outcomes is proposed."
"We formulate three famous, descriptive essays of C.N. Parkinson on
bureaucratic inefficiency in a quantifiable and dynamical socio-physical
framework. In the first model we show how the use of recent opinion formation
models for small groups can be used to understand Parkinson's observation that
decision making bodies such as cabinets or boards become highly inefficient
once their size exceeds a critical 'Coefficient of Inefficiency', typically
around 20. A second observation of Parkinson - which is sometimes referred to
as Parkinson's Law - is that the growth of bureaucratic or administrative
bodies usually goes hand in hand with a drastic decrease of its overall
efficiency. In our second model we view a bureaucratic body as a system of a
flow of workers, which enter, become promoted to various internal levels within
the system over time, and leave the system after having served for a certain
time. Promotion usually is associated with an increase of subordinates. Within
the proposed model it becomes possible to work out the phase diagram under
which conditions bureaucratic growth can be confined. In our last model we
assign individual efficiency curves to workers throughout their life in
administration, and compute the optimum time to send them to old age pension,
in order to ensure a maximum of efficiency within the body - in Parkinson's
words we compute the 'Pension Point'."
"This study proposes an automatic technique for liver segmentation in computed
tomography (CT) images. Localization of the liver volume is based on the
correlation with an optimized set of liver templates developed by the authors
that allows clear geometric interpretation. Radiodensity values are calculated
based on the boundaries of the segmented liver, which allows identifying liver
abnormalities. The performance of the technique was evaluated on 700 CT images
from dataset of the Unified Radiological Information System (URIS) of Moscow.
Despite the decrease in accuracy, the technique is applicable to CT volumes
with a partially visible region of the liver. The technique can be used to
process CT images obtained in various patient positions in a wide range of
exposition parameters. It is capable in dealing with low dose CT scans in real
large-scale medical database with over 1 million of studies."
"We have analysed the possibility of scaling the sexual Penna ageing model.
Assuming that the number of genes expressed before the reproduction age grows
linearly with the genome size and that the mutation rate per genome and
generation is constant, we have found that the fraction of defective genes
expressed before the minimum reproduction age drops with the genome size, while
the number of defective genes eliminated by the genetic death grows with genome
size. Thus, the evolutionary costs decrease with enlarging the genome. After
rescaling the time scale according to the mutational clock, age distributions
of populations do not depend on the genome size. Nevertheless, enlarging the
genome increases the reproduction potential of populations."
"Heterogeneous treatment effects (HTE) based on patients' genetic or clinical
factors are of significant interest to precision medicine. Simultaneously
modeling HTE and corresponding main effects for randomized clinical trials with
high-dimensional predictive markers is challenging. Motivated by the modified
covariates approach, we propose a two-stage statistical learning procedure for
estimating HTE with optimal efficiency augmentation, generalizing to arbitrary
interaction model and exploiting powerful extreme gradient boosting trees
(XGBoost). Target estimands for HTE are defined in the scale of mean difference
for quantitative outcomes, or risk ratio for binary outcomes, which are the
minimizers of specialized loss functions. The first stage is to estimate the
main-effect equivalency of the baseline markers on the outcome, which is then
used as an augmentation term in the second stage estimation for HTE. The
proposed two-stage procedure is robust to model mis-specification of main
effects and improves efficiency for estimating HTE through nonparametric
function estimation, e.g., XGBoost. A permutation test is proposed for global
assessment of evidence for HTE. An analysis of a genetic study in Prostate
Cancer Prevention Trial led by the SWOG Cancer Research Network, is conducted
to showcase the properties and the utilities of the two-stage method."
"Cross-sectional imaging of the lungs, or pulmonary imaging, has proven to be
an incredibly valuable tool in a wide range of pulmonary diseases. The vast
majority of lung imaging is done with CT, as it is fast enough to freeze
respiratory motion and provides high spatial resolution to visualize fine
structure of the lungs.
  MRI of the lungs is inherently challenging due to the presence of large local
magnetic field gradients, relatively low proton density, and motion. The
benefits of performing MRI for lung imaging include no ionizing radiation,
opportunities for multiple contrasts, and integration with other MRI also
offers the opportunity to obtain multiple tissue contrasts.
  The most common lung MRI techniques are structural T1-weighted scans, but
also emerging are functional contrasts such as ventilation and perfusion, as
well as other MRI contrast mechanisms including T2-weighting and
diffusion-weighting. Finally, lung MRI can be combined with other MRI scanning
techniques, including cardiac MRI, abdominal MRI, whole-body MRI, and PET/MRI,
for increasing examination efficiency by only requiring a single scan session
and providing more comprehensive assessment that includes evaluation of the
pulmonary system.
  This article covers pulse sequences, motion management methods, image
reconstruction, and contrast mechanisms of UTE MRI (e.g. T1-weighting,
ventilation mapping) for imaging of the lung."
"The utilization of computational photography becomes increasingly essential
in the medical field. Today, imaging techniques for dermatology range from
two-dimensional (2D) color imagery with a mobile device to professional
clinical imaging systems measuring additional detailed three-dimensional (3D)
data. The latter are commonly expensive and not accessible to a broad audience.
In this work, we propose a novel system and software framework that relies only
on low-cost (and even mobile) commodity devices present in every household to
measure detailed 3D information of the human skin with a
3D-gradient-illumination-based method. We believe that our system has great
potential for early-stage diagnosis and monitoring of skin diseases, especially
in vastly populated or underdeveloped areas."
"This paper describes an avenue for artificial and computational intelligence
techniques applied within games research to be deployed for purposes of
physical therapy. We provide an overview of prototypical research focussed on
the application of motion sensor input devices and virtual reality equipment
for rehabilitation of motor impairment an issue typical of patient's of
traumatic brain injuries. We highlight how advances in procedural content
generation and player modelling can stimulate development in this area by
improving quality of rehabilitation programmes and measuring patient
performance."
"We consider a state-constrained optimal control problem of a system of two
non-local partial-differential equations, which is an extension of the one
introduced in a previous work in mathematical oncology. The aim is to minimize
the tumor size through chemotherapy while avoiding the emergence of resistance
to the drugs. The numerical approach to solve the problem was the combination
of direct methods and continuation on discretization parameters, which happen
to be insufficient for the more complicated model, where diffusion is added to
account for mutations. In the present paper, we propose an approach relying on
changing the problem so that it can theoretically be solved thanks to a
Pontryagin Maximum Principle in infinite dimension. This provides an excellent
starting point for a much more reliable and efficient algorithm combining
direct methods and continuations. The global idea is new and can be thought of
as an alternative to other numerical optimal control techniques."
"Leukemia is a hematologic cancer which develops in blood tissue and triggers
rapid production of immature and abnormal shaped white blood cells. Based on
statistics it is found that the leukemia is one of the leading causes of death
in men and women alike. Microscopic examination of blood sample or bone marrow
smear is the most effective technique for diagnosis of leukemia. Pathologists
analyze microscopic samples to make diagnostic assessments on the basis of
characteristic cell features. Recently, computerized methods for cancer
detection have been explored towards minimizing human intervention and
providing accurate clinical information. This paper presents an algorithm for
automated image based acute leukemia detection systems. The method implemented
uses basic enhancement, morphology, filtering and segmenting technique to
extract region of interest using k-means clustering algorithm. The proposed
algorithm achieved an accuracy of 92.8% and is tested with Nearest Neighbor
(KNN) and Naive Bayes Classifier on the data-set of 60 samples."
"Gene mutation prediction in hepatocellular carcinoma (HCC) is of great
diagnostic and prognostic value for personalized treatments and precision
medicine. In this paper, we tackle this problem with multi-instance multi-label
learning to address the difficulties on label correlations, label
representations, etc. Furthermore, an effective oversampling strategy is
applied for data imbalance. Experimental results have shown the superiority of
the proposed approach."
"There is urgent clinical need to improve the clinical outcome of peripheral
nerve injury. Many efforts are directed towards the fabrication of
bioengineered conduits, which could deliver stem cells to the site of injury to
promote and guide peripheral nerve regeneration. The aim of this study is to
assess if graphene and related nanomaterials can be useful in the fabrication
of such conduits. A comparison is made between GO and reduced GO substrates.
Our results show that the graphene substrates are highly biocompatible, and the
reduced GO substrates are more effective in ncreasing the gene expression of
the biomolecules involved in the regeneration process compared to the other
substrates studied."
"The symptoms of many infectious diseases influence their host to withdraw
from social activity limiting their own potential to spread. Successful
transmission therefore requires the onset of infectiousness to coincide with a
time when its host is socially active. Since social activity and infectiousness
are both temporal phenomena, we hypothesize that diseases are most pervasive
when these two processes are synchronized. We consider disease dynamics that
incorporate a behavioral response that effectively shortens the infectious
period of the disease. We apply this model to data collected from face-to-face
social interactions and look specifically at how the duration of the latent
period effects the reachability of the disease. We then simulate the spread of
the model disease on the network to test the robustness of our results.
Diseases with latent periods that synchronize with the temporal social behavior
of people, i.e. latent periods of 24 hours or 7 days, correspond to peaks in
the number of individuals who are potentially at risk of becoming infected. The
effect of this synchronization is present for a range of disease models with
realistic parameters. The relationship between the latent period of an
infectious disease and its pervasiveness is non-linear and depends strongly on
the social context in which the disease is spreading."
"Vaccination is an effective way to prevent and control the occurrence and
epidemic of infectious diseases. However, many factors influence whether the
residents decide to get vaccinated or not, such as the efficacy and side
effects while individuals hope to obtain immunity through vaccination. In this
paper, the public attitude toward vaccination is investigated, especially how
it is influenced by the public estimation of vaccines efficacy and reliance on
their neighbors' vaccination behavior. We find that improving people's trust in
the vaccination greatly benefits increasing the vaccination rate and
accelerating the vaccination process. Counterintuitively, if the individual's
attitude towards vaccination is more reliant on his neighbors' vaccination
behavior, more individuals will get vaccinated, and the vaccination process
will speed up. Besides, individuals are more willing to get vaccinated if they
have more neighbors."
"Induced effects by direct exposure to ionizing radiation (IR) are a central
issue in many fields like radiation protection, clinic diagnosis and
oncological therapies. Direct irradiation at certain doses induce cell death,
but similar effects can also occur in cells no directly exposed to IR, a
mechanism known as bystander effect. Non-IR (radiofrequency waves) can induce
the death of cells loaded with MNPs in a focused oncological therapy known as
magnetic hyperthermia. Indirect mechanisms are also able to induce the death of
unloaded MNPs cells. Using in vitro cell models, we found that colocalization
of the MNPs at the lysosomes and the non-increase of the temperature induces
bystander effect under non-IR. Our results provide a landscape in which
bystander effects are a more general mechanism, up to now only observed and
clinically used in the field of radiotherapy."
"Large multimodal language models (LMMs) have achieved significant success in
general domains. However, due to the significant differences between medical
images and text and general web content, the performance of LMMs in medical
scenarios is limited. In ophthalmology, clinical diagnosis relies on multiple
modalities of medical images, but unfortunately, multimodal ophthalmic large
language models have not been explored to date. In this paper, we study and
construct an ophthalmic large multimodal model. Firstly, we use fundus images
as an entry point to build a disease assessment and diagnosis pipeline to
achieve common ophthalmic disease diagnosis and lesion segmentation. Then, we
establish a new ophthalmic multimodal instruction-following and dialogue
fine-tuning dataset based on disease-related knowledge data and publicly
available real-world medical dialogue. We introduce visual ability into the
large language model to complete the ophthalmic large language and vision
assistant (OphGLM). Our experimental results demonstrate that the OphGLM model
performs exceptionally well, and it has the potential to revolutionize clinical
applications in ophthalmology. The dataset, code, and models will be made
publicly available at https://github.com/ML-AILab/OphGLM."
"Detection of interactions between treatment effects and patient descriptors
in clinical trials is critical for optimizing the drug development process. The
increasing volume of data accumulated in clinical trials provides a unique
opportunity to discover new biomarkers and further the goal of personalized
medicine, but it also requires innovative robust biomarker detection methods
capable of detecting non-linear, and sometimes weak, signals. We propose a set
of novel univariate statistical tests, based on the theory of random walks,
which are able to capture non-linear and non-monotonic covariate-treatment
interactions. We also propose a novel combined test, which leverages the power
of all of our proposed univariate tests into a single general-case tool. We
present results for both synthetic trials as well as real-world clinical
trials, where we compare our method with state-of-the-art techniques and
demonstrate the utility and robustness of our approach."
"In this study, we investigated the inhibition of SARS-CoV-2 spike
glycoprotein with HIV drugs and their combinations. This glycoprotein is
essential for the reproduction of the SARS-COV-2 virus, so its inhibition opens
new avenues for the treatment of patients with COVID-19 disease. In doing so,
we used the VINI in silico model of cancer, whose high accuracy in finding
effective drugs and their combinations was confirmed in vitro by comparison
with existing results from NCI-60 bases, and in vivo by comparison with
existing clinical trial results. In the first step, the VINI model calculated
the inhibition efficiency of SARS-CoV-2 spike glycoprotein with 44 FDA-approved
antiviral drugs. Of these drugs, HIV drugs have been shown to be effective,
while others mainly have shown weak or no efficiency. Subsequently, the VINI
model calculated the inhibition efficiency of all possible double and triple
HIV drug combinations, and among them identified ten with the highest
inhibition efficiency. These ten combinations were analyzed by Medscape
drug-drug interaction software and LexiComp Drug Interactions. All combinations
except the combination of cobicistat_abacavir_rilpivirine appear to have
serious interactions (risk rating category D) when dosage
adjustments/reductions are required for possible toxicity. Finally, the VINI
model compared the inhibition efficiency of cobicistat_abacivir_rilpivirine
combination with cocktails and individual drugs already used or planned to be
tested against SARS-CoV-2. Combination cobicistat_abacivir_rilpivirine
demonstrated the highest inhibition of SARS-CoV-2 spike glycoprotein over
others. Thus, this combination seems to be a promising candidate for the
further in vitro testing and clinical trials."
"Human genetic diseases often arise from point mutations, emphasizing the
critical need for precise genome editing techniques. Among these, base editing
stands out as it allows targeted alterations at the single nucleotide level.
However, its clinical application is hindered by low editing efficiency and
unintended mutations, necessitating extensive trial-and-error experimentation
in the laboratory. To speed up this process, we present an attention-based
two-stage machine learning model that learns to predict the likelihood of all
possible editing outcomes for a given genomic target sequence. We further
propose a multi-task learning schema to jointly learn multiple base editors
(i.e. variants) at once. Our model's predictions consistently demonstrated a
strong correlation with the actual experimental results on multiple datasets
and base editor variants. These results provide further validation for the
models' capacity to enhance and accelerate the process of refining base editing
designs."
"Analysis of flow cytometry data is an essential tool for clinical diagnosis
of hematological and immunological conditions. Current clinical workflows rely
on a manual process called gating to classify cells into their canonical types.
This dependence on human annotation limits the rate, reproducibility, and
complexity of flow cytometry analysis. In this paper, we propose using Mondrian
processes to perform automated gating by incorporating prior information of the
kind used by gating technicians. The method segments cells into types via
Bayesian nonparametric trees. Examining the posterior over trees allows for
interpretable visualizations and uncertainty quantification - two vital
qualities for implementation in clinical practice."
"Mental health conversational agents (a.k.a. chatbots) are widely studied for
their potential to offer accessible support to those experiencing mental health
challenges. Previous surveys on the topic primarily consider papers published
in either computer science or medicine, leading to a divide in understanding
and hindering the sharing of beneficial knowledge between both domains. To
bridge this gap, we conduct a comprehensive literature review using the PRISMA
framework, reviewing 534 papers published in both computer science and
medicine. Our systematic review reveals 136 key papers on building mental
health-related conversational agents with diverse characteristics of modeling
and experimental design techniques. We find that computer science papers focus
on LLM techniques and evaluating response quality using automated metrics with
little attention to the application while medical papers use rule-based
conversational agents and outcome metrics to measure the health outcomes of
participants. Based on our findings on transparency, ethics, and cultural
heterogeneity in this review, we provide a few recommendations to help bridge
the disciplinary divide and enable the cross-disciplinary development of mental
health conversational agents."
"Hospital emergency departments frequently receive lots of bone fracture
cases, with pediatric wrist trauma fracture accounting for the majority of
them. Before pediatric surgeons perform surgery, they need to ask patients how
the fracture occurred and analyze the fracture situation by interpreting X-ray
images. The interpretation of X-ray images often requires a combination of
techniques from radiologists and surgeons, which requires time-consuming
specialized training. With the rise of deep learning in the field of computer
vision, network models applying for fracture detection has become an important
research topic. In this paper, we use data augmentation to improve the model
performance of YOLOv8 algorithm (the latest version of You Only Look Once) on a
pediatric wrist trauma X-ray dataset (GRAZPEDWRI-DX), which is a public
dataset. The experimental results show that our model has reached the
state-of-the-art (SOTA) mean average precision (mAP 50). Specifically, mAP 50
of our model is 0.638, which is significantly higher than the 0.634 and 0.636
of the improved YOLOv7 and original YOLOv8 models. To enable surgeons to use
our model for fracture detection on pediatric wrist trauma X-ray images, we
have designed the application ""Fracture Detection Using YOLOv8 App"" to assist
surgeons in diagnosing fractures, reducing the probability of error analysis,
and providing more useful information for surgery."
"The visual analysis of retinal data contributes to the understanding of a
wide range of eye diseases. For the evaluation of cross-sectional studies,
ophthalmologists rely on workflows and toolsets established in their work
environment. That is, they know what tools and data are needed at each step of
their workflow. Yet, manually operating the various tools, including
activation, data handling, or view arrangement, can be cumbersome and
time-consuming. We thus introduce a new visualization-supported toolchaining
approach that combines workflow, tools, and data. First, we provide access to
the tools required for each step of the workflow. Second, we handle the
exchange of data between these tools. Third, we organize the views of the tools
on screen using suitable layouts. Fourth, we visualize the connection between
workflow, tools, and data to support the data analysis. We demonstrate our
approach with a use case in ophthalmic research and report on initial feedback
from experts."
"Two Dehn surgeries on a knot are called {\it purely cosmetic}, if they yield
manifolds that are homeomorphic as oriented manifolds. Suppose there exist
purely cosmetic surgeries on a knot in $S^3$, we show that the two surgery
slopes must be the opposite of each other. One ingredient of our proof is a
Dehn surgery formula for correction terms in Heegaard Floer homology."
"Automatic pain intensity estimation plays a pivotal role in healthcare and
medical fields. While many methods have been developed to gauge human pain
using behavioral or physiological indicators, facial expressions have emerged
as a prominent tool for this purpose. Nevertheless, the dependence on labeled
data for these techniques often renders them expensive and time-consuming. To
tackle this, we introduce the Adaptive Hierarchical Spatio-temporal Dynamic
Image (AHDI) technique. AHDI encodes spatiotemporal changes in facial videos
into a singular RGB image, permitting the application of simpler 2D deep models
for video representation. Within this framework, we employ a residual network
to derive generalized facial representations. These representations are
optimized for two tasks: estimating pain intensity and differentiating between
genuine and simulated pain expressions. For the former, a regression model is
trained using the extracted representations, while for the latter, a binary
classifier identifies genuine versus feigned pain displays. Testing our method
on two widely-used pain datasets, we observed encouraging results for both
tasks. On the UNBC database, we achieved an MSE of 0.27 outperforming the SOTA
which had an MSE of 0.40. On the BioVid dataset, our model achieved an accuracy
of 89.76%, which is an improvement of 5.37% over the SOTA accuracy. Most
notably, for distinguishing genuine from simulated pain, our accuracy stands at
94.03%, marking a substantial improvement of 8.98%. Our methodology not only
minimizes the need for extensive labeled data but also augments the precision
of pain evaluations, facilitating superior pain management."
"In this paper we argue that the data management community should devote far
more effort to building data integration (DI) systems, in order to truly
advance the field. Toward this goal, we make three contributions. First, we
draw on our recent industrial experience to discuss the limitations of current
DI systems. Second, we propose an agenda to build a new kind of DI systems to
address these limitations. These systems guide users through the DI workflow,
step by step. They provide tools to address the ""pain points"" of the steps, and
tools are built on top of the Python data science and Big Data ecosystem
(PyData). We discuss how to foster an ecosystem of such tools within PyData,
then use it to build DI systems for collaborative/cloud/crowd/lay user
settings. Finally, we discuss ongoing work at Wisconsin, which suggests that
these DI systems are highly promising and building them raises many interesting
research challenges."
"Drones have shown to be useful aerial vehicles for unmanned transport
missions such as food and medical supply delivery. This can be leveraged to
deliver life-saving nutrition and medicine for people in emergency situations.
However, commercial drones can generally only carry 10 % - 30 % of their own
mass as payload, which limits the amount of food delivery in a single flight.
One novel solution to noticeably increase the food-carrying ratio of a drone,
is recreating some structures of a drone, such as the wings, with edible
materials. We thus propose a drone, which is no longer only a food transporting
aircraft, but itself is partially edible, increasing its food-carrying mass
ratio to 50 %, owing to its edible wings. Furthermore, should the edible drone
be left behind in the environment after performing its task in an emergency
situation, it will be more biodegradable than its non-edible counterpart,
leaving less waste in the environment. Here we describe the choice of materials
and scalable design of edible wings, and validate the method in a
flight-capable prototype that can provide 300 kcal and carry a payload of 80 g
of water."
"Noninvasive MR-guided focused ultrasound (MRgFUS) treatments are promising
alternatives to the surgical removal of malignant tumors. A significant
challenge is assessing the viability of treated tissue during and immediately
after MRgFUS procedures. Current clinical assessment uses the nonperfused
volume (NPV) biomarker immediately after treatment from contrast-enhanced MRI.
The NPV has variable accuracy, and the use of contrast agent prevents
continuing MRgFUS treatment if tumor coverage is inadequate. This work presents
a novel, noncontrast, learned multiparametric MR biomarker that can be used
during treatment for intratreatment assessment, validated in a VX2 rabbit tumor
model. A deep convolutional neural network was trained on noncontrast
multiparametric MR images using the NPV biomarker from follow-up MR imaging
(3-5 days after MRgFUS treatment) as the accurate label of nonviable tissue. A
novel volume-conserving registration algorithm yielded a voxel-wise correlation
between treatment and follow-up NPV, providing a rigorous validation of the
biomarker. The learned noncontrast multiparametric MR biomarker predicted the
follow-up NPV with an average DICE coefficient of 0.71, substantially
outperforming the current clinical standard (DICE coefficient = 0.53).
Noncontrast multiparametric MR imaging integrated with a deep convolutional
neural network provides a more accurate prediction of MRgFUS treatment outcome
than current contrast-based techniques."
"The use of engineered nanoscale magnetic materials in healthcare and
biomedical technologies is rapidly growing. Two examples which have recently
attracted significant attention are magnetic particle imaging (MPI) for
biological monitoring, and magnetic field hyperthermia (MFH) for cancer
therapy. Here for the first time, the capability of a Lissajous scanning MPI
device to act as a standalone platform to support the application of MFH cancer
treatment is presented. The platform is shown to offer functionalities for
nanoparticle localization, focused hyperthermia therapy application, and
non-invasive tissue thermometry in one device. Combined, these capabilities
have the potential to significantly enhance the accuracy, effectiveness and
safety of MFH therapy. Measurements of nanoparticle hyperthermia during
protracted exposure to the MPI scanner's 3D imaging field sequence revealed
spatially focused heating, with a maximum that is significantly enhanced
compared with a simple 1-dimensional sinusoidal excitation. The observed
spatial heating behavior is qualitatively described based on a phenomenological
model considering torques exerted in the Brownian regime. In-vitro cell studies
using a human acute monocytic leukemia cell line (THP-1) demonstrated strong
suppression of both structural integrity and metabolic activity within 24 h
following a 40 min MFH treatment actuated within the Lissajous MPI scanner.
Furthermore, reconstructed MPI images of the nanoparticles distributed among
the cells, and the temperature-sensitivity of the MPI imaging signal obtained
during treatment are demonstrated. In summary, combined Lissajous MPI and MFH
technologies are presented; demonstrating for the first time their potential
for cancer treatment with maximum effectiveness, and minimal collateral damage
to surrounding tissues."
"White matter hyperintensities (WMH) are commonly found in the brains of
healthy elderly individuals and have been associated with various neurological
and geriatric disorders. In this paper, we present a study using deep fully
convolutional network and ensemble models to automatically detect such WMH
using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance
(MR) scans. The algorithm was evaluated and ranked 1 st in the WMH Segmentation
Challenge at MICCAI 2017. In the evaluation stage, the implementation of the
algorithm was submitted to the challenge organizers, who then independently
tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score,
precision and robust Hausdorff distance obtained on held-out test datasets were
80%, 84% and 6.30mm respectively. These were the highest achieved in the
challenge, suggesting the proposed method is the state-of-the-art. In this
paper, we provide detailed descriptions and quantitative analysis on key
components of the system. Furthermore, a study of cross-scanner evaluation is
presented to discuss how the combination of modalities and data augmentation
affect the generalization capability of the system. The adaptability of the
system to different scanners and protocols is also investigated. A quantitative
study is further presented to test the effect of ensemble size. Additionally,
software and models of our method are made publicly available. The
effectiveness and generalization capability of the proposed system show its
potential for real-world clinical practice."
"The abrupt decline in the Total Fertility Rate (TFR) of Puerto Rico since
2000 makes the prospect of a sustained population decline a real possibility.
From 2000 to 2021 the TFR declined from 2.1 to 0.9 children per woman, one of
the lowest in the world. Population projections produced by the United States
Census Bureau and the United Nations Population Division show that the island
population may decline from 3.8 millions in 2000 to slightly above 2 million by
2050, a dramatic 47% population decline in 50 years. As dire as this prospect
may be, this may be an optimistic scenario. Both projections have the TFR
increasing to 1.5 by 2050, but a fertility projection conducted by us show that
fertility can remain much closer to 1.0 until 2050. Bayesian Hierarchical
Probabilistic Theory has been used by the United Nations to incorporate a way
to measure the uncertainty and to estimate the projection parameters. However,
the assumption that the fertility level in countries with low fertility will
eventually increase to 2.1 has been widely criticized as unrealistic and not
supported by evidence. We modified the assumptions used by the United Nations
considering countries with TFR similar to Puerto Rico and find that by 2050
Puerto Rico may have a TFR of 1.1 bounded by a 95% credibility interval
(0.56,1.77). This indicates that there may be a larger population decline than
what current projections show."
"For minimally invasive endovascular surgery, the localization of catheters
and guidewires inside the human body is essential. Electromagnetic (EM)
tracking is one technology that allows localizing such surgical instruments.
For localizing intra-operatively EM-tracked instruments with respect to
preoperative volume data, it is necessary to bring pre- and intraoperative
imaging into the same coordinate frame. In most existing solutions, such
registration requires additional interactions, modifying the procedure's
original workflow. We propose a new method taking advantage of Bioelectric
signals to initialize and register preoperative volumes to the EM tracking
system without significantly changing the interventional workflow. We envision
the most natural use-case of our concept in cardiac electrophysiology (EP)
procedures, in which EP catheters are already equipped with all the necessary
sensing, including electric sensing for the measurement of electrophysiological
signals and EM tracking for catheter localization. We use EP catheters for
Bioelectric sensing to detect local features of the vasculature while advancing
the catheter inside the human body. Such features can be automatically labeled
before the procedure within the preoperative data. The combination of
Bioelectric and EM tracking can localize vascular features such as bifurcations
and stenosis within the EM tracking space. Mapping them to preoperative data
automatically registers patients' CT space to EM tracking. The proposed
registration process is entirely based on Bioelectric sensed features, with no
need for external markers or other interventional imaging devices."
"In this research was implemented the use of an Arduino UNO R3 microcontroller
to control the movements of a prototype robotic functional developed to perform
rehabilitation exercises in the wrist joint; This device can be used to assist
the physiatrist to rehabilitate the tendinitis, synovitis, rheumatoid arthritis
and for pre-operative and post-operative therapy in this joint. During the
design stage of the functional prototype, the methodology of the industrial
design process was used from a concurrent engineering approach, through which
anthropometric studies could be performed related to the dimensions and angles
of movement of the wrist joint in the population Venezuelan from the
information collected, the design proposal was elaborated, and the use of CAD
programs defined the different forms, geometries and materials of the
components of the rehabilitation device, which were later analyzed using the
finite element method for the determination The tensional state of efforts and
safety factors through the use of CAE programs. In addition, a software was
developed for the acquisition, registration, reproduction and execution of the
different movements produced during the rehabilitation therapy. Through the
research developed, a device was designed that will help the rehabilitation of
the wrist joint allowing the combination of dorsal-palmar flexion and
ulnar-radial movements to recover the joint function of various pathologies
presented in the Venezuelan population."
"Neuromatch Academy designed and ran a fully online 3-week Computational
Neuroscience summer school for 1757 students with 191 teaching assistants
working in virtual inverted (or flipped) classrooms and on small group
projects. Fourteen languages, active community management, and low cost allowed
for an unprecedented level of inclusivity and universal accessibility."
"Radiomics is an active area of research focusing on high throughput feature
extraction from medical images with a wide array of applications in clinical
practice, such as clinical decision support in oncology. However, noise in low
dose computed tomography (CT) scans can impair the accurate extraction of
radiomic features. In this article, we investigate the possibility of using
deep learning generative models to improve the performance of radiomics from
low dose CTs. We used two datasets of low dose CT scans -NSCLC Radiogenomics
and LIDC-IDRI - as test datasets for two tasks - pre-treatment survival
prediction and lung cancer diagnosis. We used encoder-decoder networks and
conditional generative adversarial networks (CGANs) trained in a previous study
as generative models to transform low dose CT images into full dose CT images.
Radiomic features extracted from the original and improved CT scans were used
to build two classifiers - a support vector machine (SVM) and a deep attention
based multiple instance learning model - for survival prediction and lung
cancer diagnosis respectively. Finally, we compared the performance of the
models derived from the original and improved CT scans. Encoder-decoder
networks and CGANs improved the area under the curve (AUC) of survival
prediction from 0.52 to 0.57 (p-value<0.01). On the other hand, Encoder-decoder
network and CGAN can improve the AUC of lung cancer diagnosis from 0.84 to 0.88
and 0.89 respectively (p-value<0.01). Moreover, there are no statistically
significant differences in improving AUC by using encoder-decoder network and
CGAN (p-value=0.34) when networks trained at 75 and 100 epochs. Generative
models can improve the performance of low dose CT-based radiomics in different
tasks. Hence, denoising using generative models seems to be a necessary
pre-processing step for calculating radiomic features from low dose CTs."
"In assessing the severity of age-related macular degeneration (AMD), the
Age-Related Eye Disease Study (AREDS) Simplified Severity Scale predicts the
risk of progression to late AMD. However, its manual use requires the
time-consuming participation of expert practitioners. Although several
automated deep learning systems have been developed for classifying color
fundus photographs (CFP) of individual eyes by AREDS severity score, none to
date has used a patient-based scoring system that uses images from both eyes to
assign a severity score. DeepSeeNet, a deep learning model, was developed to
classify patients automatically by the AREDS Simplified Severity Scale (score
0-5) using bilateral CFP. DeepSeeNet was trained on 58,402 and tested on 900
images from the longitudinal follow-up of 4549 participants from AREDS. Gold
standard labels were obtained using reading center grades. DeepSeeNet simulates
the human grading process by first detecting individual AMD risk factors
(drusen size, pigmentary abnormalities) for each eye and then calculating a
patient-based AMD severity score using the AREDS Simplified Severity Scale.
DeepSeeNet performed better on patient-based classification (accuracy = 0.671;
kappa = 0.558) than retinal specialists (accuracy = 0.599; kappa = 0.467) with
high AUC in the detection of large drusen (0.94), pigmentary abnormalities
(0.93), and late AMD (0.97). DeepSeeNet demonstrated high accuracy with
increased transparency in the automated assignment of individual patients to
AMD risk categories based on the AREDS Simplified Severity Scale. These results
highlight the potential of deep learning to assist and enhance clinical
decision-making in patients with AMD, such as early AMD detection and risk
prediction for developing late AMD. DeepSeeNet is publicly available on
https://github.com/ncbi-nlp/DeepSeeNet."
"Mental health disorders may cause severe consequences on all the countries'
economies and health. For example, the impacts of the COVID-19 pandemic, such
as isolation and travel ban, can make us feel depressed. Identifying early
signs of mental health disorders is vital. For example, depression may increase
an individual's risk of suicide. The state-of-the-art research in identifying
mental disorder patterns from textual data, uses hand-labelled training sets,
especially when a domain expert's knowledge is required to analyse various
symptoms. This task could be time-consuming and expensive. To address this
challenge, in this paper, we study and analyse the various clinical and
non-clinical approaches to identifying mental health disorders. We leverage the
domain knowledge and expertise in cognitive science to build a domain-specific
Knowledge Base (KB) for the mental health disorder concepts and patterns. We
present a weaker form of supervision by facilitating the generating of training
data from a domain-specific Knowledge Base (KB). We adopt a typical scenario
for analysing social media to identify major depressive disorder symptoms from
the textual content generated by social users. We use this scenario to evaluate
how our knowledge-based approach significantly improves the quality of results."
"3D printing has raised a lot of attention from fields outside the
manufacturing one in the last years. In this paper, we will illustrate some
recent advances of 3D printing technology, applied to the field of telemedicine
and remote patient care. The potentiality of this technology will be detailed
without lab examples. Some crucial aspect such as the regulation of these
devices and the need of some standards will also be discussed. The purpose of
this paper is to present some of the most promising applications of such
technology."
"The adult sex ratio (ASR) is defined as the number of fertile males divided
by the number of fertile females in a population. We build an ODE model with
minimal age structure, in which males compete for paternities using either a
multiple-mating or searching-then-guarding strategy, to investigate the value
of ASR as an index for predicting which strategy males will adopt, with a focus
in our investigation on the differences of strategy choice between chimpanzees
Pan troglodytes and human hunter-gatherers Homo sapiens. Parameters in the
model characterise aspects of life history and behaviour, and determine both
dominant strategy and the ASR when the population is at or near equilibrium.
Sensitivity analysis on the model parameters informs us that ASR is strongly
influenced by parameters characterising life history, while dominant strategy
is affected most strongly by the effectiveness of guarding (average length of
time a guarded pair persists, and resistance to paternity theft) and moderately
by some life history traits. For fixed effectiveness of guarding and other
parameters, dominant strategy tends to change from multiple mating to guarding
along a curve that aligns well with a contour of constant ASR, under variation
of parameters such as longevity and age female fertility ends. This confirms
the hypothesis that ASR may be a useful index for predicting the optimal male
mating strategy, provided we have some limited information about ecology and
behaviour."
"Artificial Intelligence (AI) is gradually changing the practice of surgery
with the advanced technological development of imaging, navigation and robotic
intervention. In this article, the recent successful and influential
applications of AI in surgery are reviewed from pre-operative planning and
intra-operative guidance to the integration of surgical robots. We end with
summarizing the current state, emerging trends and major challenges in the
future development of AI in surgery."
"Two-dimensional gel electrophoresis has been instrumental in the development
of proteomics. Although it is no longer the exclusive scheme used for
proteomics, its unique features make it a still highly valuable tool,
especially when multiple quantitative comparisons of samples must be made, and
even for large samples series. However, quantitative proteomics using 2D gels
is critically dependent on the performances of the protein detection methods
used after the electrophoretic separations. This chapter therefore examines
critically the various detection methods (radioactivity, dyes, fluorescence,
and silver) as well as the data analysis issues that must be taken into account
when quantitative comparative analysis of 2D gels is performed."
"Alzheimer's is a brain disease that gets worse over time and affects memory,
thinking, and behavior. Alzheimer's disease (AD) can be treated and managed if
it is diagnosed early, which can slow the progression of symptoms and improve
quality of life. In this study, we suggested using the Visual Transformer (ViT)
and bi-LSTM to process MRI images for diagnosing Alzheimer's disease. We used
ViT to extract features from the MRI and then map them to a feature sequence.
Then, we used Bi-LSTM sequence modeling to keep the interdependencies between
related features. In addition, we evaluated the performance of the proposed
model for the binary classification of AD patients using data from the
Alzheimer's Disease Neuroimaging Initiative (ADNI). Finally, we evaluated our
method against other deep learning models in the literature. The proposed
method performs well in terms of accuracy, precision, F-score, and recall for
the diagnosis of AD."
"Factors contributing to social inequalities are also associated with negative
mental health outcomes leading to disparities in mental well-being. We propose
a Bayesian hierarchical model which can evaluate the impact of policies on
population well-being, accounting for spatial/temporal dependencies. Building
on an interrupted time series framework, our approach can evaluate how
different profiles of individuals are affected in different ways, whilst
accounting for their uncertainty. We apply the framework to assess the impact
of the United Kingdoms welfare reform, which took place throughout the 2010s,
on mental well-being using data from the UK Household Longitudinal Study. The
additional depth of knowledge is essential for effective evaluation of current
policy and implementation of future policy."
"The cone beam computed tomography (CBCT) technique was first inserted in
dental imaging 15 years ago. Due to this technique 3D imaging in dentistry has
been excessively changed. The purpose beyond using CBCT instead of computed
tomography (CT) imaging is that CT can not be used in many cases in dentistry,
in addition to the higher radiation and cost of CT. Nowadays, CBCT can be
applied in diagnostics for several dental specialties because of the variety of
services it offers and the specification of use. In contrast to CT, CBCT has
shown great benefits in endodontics, implant planning oral and maxillofacial
surgery and even in orthodontics."
"In this paper, we present work in progress on the role of artificial
intelligence (AI) chatbots, such as ChatGPT, in facilitating data access to
federated knowledge graphs. In particular, we provide examples from the field
of bioinformatics, to illustrate the potential use of Conversational AI to
describe datasets, as well as generate and explain (federated) queries across
datasets for the benefit of domain experts."
"The extraction of structured clinical information from free-text radiology
reports in the form of radiology graphs has been demonstrated to be a valuable
approach for evaluating the clinical correctness of report-generation methods.
However, the direct generation of radiology graphs from chest X-ray (CXR)
images has not been attempted. To address this gap, we propose a novel approach
called Prior-RadGraphFormer that utilizes a transformer model with prior
knowledge in the form of a probabilistic knowledge graph (PKG) to generate
radiology graphs directly from CXR images. The PKG models the statistical
relationship between radiology entities, including anatomical structures and
medical observations. This additional contextual information enhances the
accuracy of entity and relation extraction. The generated radiology graphs can
be applied to various downstream tasks, such as free-text or structured reports
generation and multi-label classification of pathologies. Our approach
represents a promising method for generating radiology graphs directly from CXR
images, and has significant potential for improving medical image analysis and
clinical decision-making."
"In this article, we propose a new BSS approach for identifying skin diseases
from RGB images that proceeds in two steps. We begin by separating the three
main chromophores (oxyhemoglobin, deoxyhemoglobin and melanin) using
Non-negative Matrix Factorization (NMF). For this purpose, we propose a special
initialization of the solution matrices based on the sparsity of the
chromophores, instead of initializing them with random matrices as is the case
for basic versions of NMF. We then propose a new disease identification
criterion that exploits the three contributions of each chromophore on the
three spectral bands of our RGB dermatological image. To validate our approach,
we used an open access database containing RGB images of melanoma and neavus.
The results obtained showed good performance for our approach in terms of
chromophore separation, compared to the most commonly used method in the
literature, as well as disease identification compared to identification based
on the most popular criterion."
"Future intelligent autonomous systems (IAS) are inevitably deciding on moral
and legal questions, e.g. in self-driving cars, health care or human-machine
collaboration. As decision processes in most modern sub-symbolic IAS are
hidden, the simple political plea for transparency, accountability and
governance falls short. A sound ecosystem of trust requires ways for IAS to
autonomously justify their actions, that is, to learn giving and taking reasons
for their decisions. Building on social reasoning models in moral psychology
and legal philosophy such an idea of >>Reasonable Machines<< requires novel,
hybrid reasoning tools, ethico-legal ontologies and associated argumentation
technology. Enabling machines to normative communication creates trust and
opens new dimensions of AI application and human-machine interaction.
  Keywords: Trusthworthy and Explainable AI, Ethico-Legal Governors, Social
Reasoning Model, Pluralistic and Expressive Normative Reasoning"
"Automated cardiac segmentation from magnetic resonance imaging datasets is an
essential step in the timely diagnosis and management of cardiac pathologies.
We propose to tackle the problem of automated left and right ventricle
segmentation through the application of a deep fully convolutional neural
network architecture. Our model is efficiently trained end-to-end in a single
learning stage from whole-image inputs and ground truths to make inference at
every pixel. To our knowledge, this is the first application of a fully
convolutional neural network architecture for pixel-wise labeling in cardiac
magnetic resonance imaging. Numerical experiments demonstrate that our model is
robust to outperform previous fully automated methods across multiple
evaluation measures on a range of cardiac datasets. Moreover, our model is fast
and can leverage commodity compute resources such as the graphics processing
unit to enable state-of-the-art cardiac segmentation at massive scales. The
models and code are available at
https://github.com/vuptran/cardiac-segmentation"
"A factor effect study was conducted on a set of observations at the
contingency of a series of plant species and bacteria species regarding the
antibacterial activity of essential oil extracts. The study reveals a very good
agreement between the observations and the hypothesis of independent and
multiplicative effect of plant and bacteria species factors on the
antibacterial activity. Shaping of the observable to a Negative Binomial
distribution allowed the separation of two convoluted Gamma distributions in
the observable further assigned to the distribution of factors. Statistics of
the Gamma distribution allowed estimating the ratio between diversity of plants
factors and bacteria factors in the antibacterial activity of essential oils
extracts."
"Perioperative data are essential to investigating the causes of adverse
surgical outcomes. In some low to middle income countries, these data are
computationally inaccessible due to a lack of digitization of surgical
flowsheets. In this paper, we present a deep image segmentation approach using
a U-Net architecture that can detect hand-drawn symbols on a flowsheet graph.
The segmentation mask outputs are post-processed with techniques unique to each
symbol to convert into numeric values. The U-Net method can detect, at the
appropriate time intervals, the symbols for heart rate and blood pressure with
over 99 percent accuracy. Over 95 percent of the predictions fall within an
absolute error of five when compared to the actual value. The deep learning
model outperformed template matching even with a small size of annotated images
available for the training set."
"Among all insect genomes, honeybee displays one of the most unusual patterns
with interspersed long AT and GC-rich segments. Nearly 75% of the
protein-coding genes are located in the AT-rich segments of the genome, but the
biological significance of the GC-rich regions is not well understood. Based on
an observation that the bee miRNAs, actins and tubulins are located in the
GC-rich segments, this work investigated whether other highly conserved genomic
regions show similar preferences. Sequences ultraconserved between the genomes
of honeybee and Nasonia, another hymenopteran insect, were determined. They
showed strong preferences towards locating in the GC-rich regions of the bee
genome."
"Clinical trials with a hybrid control arm (a control arm constructed from a
combination of randomized patients and real-world data on patients receiving
usual care in standard clinical practice) have the potential to decrease the
cost of randomized trials while increasing the proportion of trial patients
given access to novel therapeutics. However, due to stringent trial inclusion
criteria and differences in care and data quality between trials and community
practice, trial patients may have systematically different outcomes compared to
their real-world counterparts. We propose a new method for analyses of trials
with a hybrid control arm that efficiently controls bias and type I error.
Under our proposed approach, selected real-world patients are weighted by a
function of the ""on-trial score,"" which reflects their similarity to trial
patients. In contrast to previously developed hybrid control designs that
assign the same weight to all real-world patients, our approach upweights of
real-world patients who more closely resemble randomized control patients while
dissimilar patients are discounted. Estimates of the treatment effect are
obtained via Cox proportional hazards models. We compare our approach to
existing approaches via simulations and apply these methods to a study using
electronic health record data. Our proposed method is able to control type I
error, minimize bias, and decrease variance when compared to using only trial
data in nearly all scenarios examined. Therefore, our new approach can be used
when conducting clinical trials by augmenting the standard-of-care arm with
weighted patients from the EHR to increase power without inducing bias."
"The current state of cancer therapeutics has been moving away from
one-size-fits-all cytotoxic chemotherapy, and towards a more individualized and
specific approach involving the targeting of each tumor's genetic
vulnerabilities. Different tumors, even of the same type, may be more reliant
on certain cellular pathways more than others. With modern advancements in our
understanding of cancer genome sequencing, these pathways can be discovered.
Investigating each of the millions of possible small molecule inhibitors for
each kinase in vitro, however, would be extremely expensive and time consuming.
This project focuses on predicting the inhibition activity of small molecules
targeting 8 different kinases using multiple deep learning models. We trained
fingerprint-based MLPs and simplified molecular-input line-entry specification
(SMILES)-based recurrent neural networks (RNNs) and molecular graph
convolutional networks (GCNs) to accurately predict inhibitory activity
targeting these 8 kinases."
"Cold atmospheric plasma (CAP) has shown its promising application in cancer
treatment both in vitro and in vivo. However, the anti-cancer mechanism is
still largely unknown. CAP may kill cancer cells via triggering the rise of
intracellular ROS, DNA damage, mitochondrial damage, or cellular membrane
damage. While, the specific vulnerability of cancer cells to CAP has been
observed, the underlying mechanism of such cell-based specific vulnerability to
CAP is completely unknown. Here, through the comparison of CAP treatment and
H2O2 treatment on 10 different cancer cell lines in vitro, we observed that the
H2O2 consumption speed by cancer cells was strongly correlated to the
cytotoxicity of CAP treatment on cancer cells. Cancer cells that clear
extracellular H2O2 more quickly are more resistant to the cytotoxicity of CAP
treatment. This finding strongly indicates that the anti-oxidant system in
cancer cells play a key role in the specific vulnerability of cancer cells to
CAP treatment in vitro."
"Despite the ever-strong demand for mental health care globally, access to
traditional mental health services remains severely limited expensive, and
stifled by stigma and systemic barriers. Thus, over the last few years, young
people are increasingly turning to content on video-sharing platforms (VSPs)
like TikTok and YouTube to help them navigate their mental health journey.
However, navigating towards trustworthy information relating to mental health
on these platforms is challenging, given the uncontrollable and unregulated
growth of dedicated mental health content and content creators catering to a
wide array of mental health conditions on these platforms. In this paper, we
attempt to define what constitutes as ""mental health misinformation"" through
examples. In addition, we also suggest some open questions to answer and
challenges to tackle regarding this important and timely research topic"
"Purpose: To report the feasibility and the safety of a surgeon-controlled
robotic endoscope holder in laparoscopic surgery. Materials and methods: From
March 2010 to September 2010, 20 patients were enrolled prospectively to
undergo a laparoscopic surgery using an innovative robotic endoscope holder.
Two surgeons performed 6 adrenalectomies, 4 sacrocolpopexies, 5 pyeloplasties,
4 radical prostatectomies and 1 radical nephrectomy. Demographic data, overall
set-up time, operative time, number of assistants needed were reviewed.
Surgeon's satisfaction regarding the ergonomics was assessed using a ten point
scale. Postoperative clinical outcomes were reviewed at day 1 and 1 month
postoperatively. Results: The per-protocol analysis was performed on 17
patients for whom the robot was effectively used for surgery. Median age was 63
years, 10 patients were female (59%). Median BMI was 26.8. Surgical procedures
were completed with the robot in 12 cases (71 %). Median number of surgical
assistant was 0. Overall set-up time with the robot was 19 min, operative time
was 130 min) during which the robot was used 71% of the time. Mean hospital
stay was 6.94 days $\pm$ 2.3. Median score regarding the easiness of use was 7.
Median pain level was 1.5/10 at day 1 and 0 at 1 month postoperatively. Open
conversion was needed in 1 case (6 %) and 4 minor complications occurred in 2
patients (12%). Conclusion: This use of this novel robotic laparoscope holder
is safe, feasible and it provides a good comfort to the surgeon."
"Beneath the uncertain primitive visual features of face images are the
primitive intrinsic structural patterns (PISP) essential for characterizing a
sample face discriminative attributes. It is on this basis that this paper
presents a simple yet effective facial descriptor formed from derivatives of
Gaussian and Gabor Wavelets. The new descriptor is coined local edge gradient
Gabor magnitude (LEGGM) pattern. LEGGM first uncovers the PISP locked in every
pixel through determining the pixel gradient in relation to its neighbors using
the Derivatives of Gaussians. Then, the resulting output is embedded into the
global appearance of the face which are further processed using Gabor wavelets
in order to express its frequency characteristics. Additionally, we adopted
various subspace models for dimensionality reduction in order to ascertain the
best fit model for reporting a more effective representation of the LEGGM
patterns. The proposed descriptor-based face recognition method is evaluated on
three databases: Plastic surgery, LFW, and GT face databases. Through
experiments, using a base classifier, the efficacy of the proposed method is
demonstrated, especially in the case of plastic surgery database. The
heterogeneous database, which we created to typify real-world scenario, show
that the proposed method is to an extent insensitive to image formation factors
with impressive recognition performances."
"In the pharmaceutical industry, the use of artificial intelligence (AI) has
seen consistent growth over the past decade. This rise is attributed to major
advancements in statistical machine learning methodologies, computational
capabilities and the increased availability of large datasets. AI techniques
are applied throughout different stages of drug development, ranging from drug
discovery to post-marketing benefit-risk assessment. Kolluri et al. provided a
review of several case studies that span these stages, featuring key
applications such as protein structure prediction, success probability
estimation, subgroup identification, and AI-assisted clinical trial monitoring.
From a regulatory standpoint, there was a notable uptick in submissions
incorporating AI components in 2021. The most prevalent therapeutic areas
leveraging AI were oncology (27%), psychiatry (15%), gastroenterology (12%),
and neurology (11%). The paradigm of personalized or precision medicine has
gained significant traction in recent research, partly due to advancements in
AI techniques \cite{hamburg2010path}. This shift has had a transformative
impact on the pharmaceutical industry. Departing from the traditional
""one-size-fits-all"" model, personalized medicine incorporates various
individual factors, such as environmental conditions, lifestyle choices, and
health histories, to formulate customized treatment plans. By utilizing
sophisticated machine learning algorithms, clinicians and researchers are
better equipped to make informed decisions in areas such as disease prevention,
diagnosis, and treatment selection, thereby optimizing health outcomes for each
individual."
"Our previous work classified a taxonomy of suturing gestures during a
vesicourethral anastomosis of robotic radical prostatectomy in association with
tissue tears and patient outcomes. Herein, we train deep-learning based
computer vision (CV) to automate the identification and classification of
suturing gestures for needle driving attempts. Using two independent raters, we
manually annotated live suturing video clips to label timepoints and gestures.
Identification (2395 videos) and classification (511 videos) datasets were
compiled to train CV models to produce two- and five-class label predictions,
respectively. Networks were trained on inputs of raw RGB pixels as well as
optical flow for each frame. Each model was trained on 80/20 train/test splits.
In this study, all models were able to reliably predict either the presence of
a gesture (identification, AUC: 0.88) as well as the type of gesture
(classification, AUC: 0.87) at significantly above chance levels. For both
gesture identification and classification datasets, we observed no effect of
recurrent classification model choice (LSTM vs. convLSTM) on performance. Our
results demonstrate CV's ability to recognize features that not only can
identify the action of suturing but also distinguish between different
classifications of suturing gestures. This demonstrates the potential to
utilize deep learning CV towards future automation of surgical skill
assessment."
"Purpose: MRI cell tracking can be used to monitor immune cells involved in
the immunotherapy response, providing insight into the mechanism of action,
temporal progression of tumour growth and individual potency of therapies. To
evaluate whether MRI could be used to track immune cell populations in response
to immunotherapy, CD8+ cytotoxic T cells (CTLs), CD4+CD25+FoxP3+ regulatory T
cells (Tregs) and myeloid derived suppressor cells (MDSCs) were labelled with
superparamagnetic iron oxide (SPIO) particles.
  Methods: SPIO-labelled cells were injected into mice (one cell type/mouse)
implanted with an HPV-based cervical cancer model. Half of these mice were also
vaccinated with DepoVaxTM, a lipid-based vaccine platform that was developed to
enhance the potency of peptide-based vaccines.
  Results: MRI visualization of CTLs, Tregs and MDSCs was apparent 24 hours
post-injection, with hypointensities due to iron labelled cells clearing
approximately 72 hours post-injection. Vaccination resulted in increased
recruitment of CTLs and decreased recruitment of MDSCs and Tregs to the tumour.
We also found that MDSC and Treg recruitment was positively correlated with
final tumour volume.
  Conclusion: This type of analysis can be used to non-invasively study changes
in immune cell recruitment in individual mice over time, potentially allowing
improved application and combination of immunotherapies."
"Background: During the early stages of hospital admission, clinicians must
use limited information to make diagnostic and treatment decisions as patient
acuity evolves. However, it is common that the time series vital sign
information from patients to be both sparse and irregularly collected, which
poses a significant challenge for machine / deep learning techniques to analyze
and facilitate the clinicians to improve the human health outcome. To deal with
this problem, We propose a novel deep interpolation network to extract latent
representations from sparse and irregularly sampled time-series vital signs
measured within six hours of hospital admission. Methods: We created a
single-center longitudinal dataset of electronic health record data for all
(n=75,762) adult patient admissions to a tertiary care center lasting six hours
or longer, using 55% of the dataset for training, 23% for validation, and 22%
for testing. All raw time series within six hours of hospital admission were
extracted for six vital signs (systolic blood pressure, diastolic blood
pressure, heart rate, temperature, blood oxygen saturation, and respiratory
rate). A deep interpolation network is proposed to learn from such irregular
and sparse multivariate time series data to extract the fixed low-dimensional
latent patterns. We use k-means clustering algorithm to clusters the patient
admissions resulting into 7 clusters. Findings: Training, validation, and
testing cohorts had similar age (55-57 years), sex (55% female), and admission
vital signs. Seven distinct clusters were identified. M Interpretation: In a
heterogeneous cohort of hospitalized patients, a deep interpolation network
extracted representations from vital sign data measured within six hours of
hospital admission. This approach may have important implications for clinical
decision-support under time constraints and uncertainty."
"We present a mechanism that puts users in the center of control and empowers
them to dictate the access to their collections of data. Revisiting the
fundamental mechanisms in security for providing protection, our solution uses
capabilities, access lists, and access rights following well-understood formal
notions for reasoning about access. This contribution presents a practical,
correct, auditable, transparent, distributed, and decentralized mechanism that
is well-matched to the current emerging environments including Internet of
Things, smart city, precision medicine, and autonomous cars. It is based on
well-tested principles and practices used in a distributed authorization,
cryptocurrencies, and scalable computing."
"Class imbalance is a common problem in medical diagnosis, causing a standard
classifier to be biased towards the common classes and perform poorly on the
rare classes. This is especially true for dermatology, a specialty with
thousands of skin conditions but many of which have low prevalence in the real
world. Motivated by recent advances, we explore few-shot learning methods as
well as conventional class imbalance techniques for the skin condition
recognition problem and propose an evaluation setup to fairly assess the
real-world utility of such approaches. We find the performance of few-show
learning methods does not reach that of conventional class imbalance
techniques, but combining the two approaches using a novel ensemble improves
model performance, especially for rare classes. We conclude that ensembling can
be useful to address the class imbalance problem, yet progress can further be
accelerated by real-world evaluation setups for benchmarking new methods."
"Previous researches on dialogue system assessment usually focus on the
quality evaluation (e.g. fluency, relevance, etc) of responses generated by the
chatbots, which are local and technical metrics. For a chatbot which responds
to millions of online users including minors, we argue that it should have a
healthy mental tendency in order to avoid the negative psychological impact on
them. In this paper, we establish several mental health assessment dimensions
for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce
the questionnaire-based mental health assessment methods. We conduct
assessments on some well-known open-domain chatbots and find that there are
severe mental health issues for all these chatbots. We consider that it is due
to the neglect of the mental health risks during the dataset building and the
model training procedures. We expect to attract researchers' attention to the
serious mental health problems of chatbots and improve the chatbots' ability in
positive emotional interaction."
"The paper proposes to analyze epidemiological data using regression models
which enable subject-matter (epidemiological) interpretation of such data
whether with uncorrelated or correlated predictors. To this end, response
functions should include not only terms linear in predictors but also higher
order ones (e.g. quadratic and cross terms). For epidemiological interpretation
of a regression model, the suggestion is to construct conditional functions
derived from the general regression function with the values of all predictor
variables held fixed excepting one predictor. Unlike the conventional
techniques based on linear-predictor models in which the coefficient at any
variable is interpreted, our approach proposes to interpret this conditional
function, which is multivariate for any predictor being dependent on the values
of all the other predictors. It is such functions that can describe
relationships between Y and a predictor that have different forms in different
predictor domains. The paper discusses differences in the interpretation of the
proposed conditional functions between cases involving correlated and
uncorrelated predictor variables. The construction and analysis of regression
models for epidemiological and environmental data are illustrated with
examples."
"The examination of Osteoarthritis disease through X-ray by rheumatology can
be classified into four grade of severity. This paper discusses about the
application of artificial neural network backpropagation method for measuring
the severity of the disease, where the observed X-ray range from wrist to
fingers. The main procedures of system in this paper is divided into three,
which are image processing, feature extraction, and artificial neural network
process. First, an X-ray image digital (200x150 pixels and greyscale) will be
thresholded, then extracted features based on probabilistic values of the color
intensity of seven bit quantization result, and statistical textures. That
feature values then will be normalizing to interval [0.1, 0.9], and then the
result would be processing on backpropagation artificial neural network system
as input to determine the severity of disease from an X-ray had input before
it. From testing with learning rate 0.3, momentum 0.4, hidden units five pieces
and about 132 feature vectors, this system had had a level of accuracy of 100%
for learning data, 80% for learning and non-learning data, and 66.6% for
non-learning data"
"We have measured the coexistence curve of the binary liquid mixture
n-heptane+nitrobenzene near its consolute point using an optical method. In
particular, the critical exponent beta describing the coexistence curve was
measured for this system. Previous experimental values of beta for
n-heptane+nitrobenzene were higher than the typical theoretically calculated
value, an unusual, although not unique, occurrence. In an effort to study this
discrepancy, we have used an improved experimental apparatus for our
measurements. We have taken special care to minimize temperature gradients and
maximize the temperature stability of our thermal control system. We have also
exploited features of a known optical method to analyze, thoroughly, sources of
systematic errors. We measured an apparent value of beta as 0.367+/- 0.006 and
by a careful study of the known sources of error we find that they are not able
to remove the discrepancy between the measured and the theoretical values of
beta. We also measured the critical temperature of the system at Tc=291.80+/-
0.02 K (18.65 C)."
"The Raven I and the Raven II surgical robots, as open research platforms,
have been serving the robotic surgery research community for ten years. The
paper 1) briefly presents the Raven I and the Raven II robots, 2) reviews the
recent publications that are built upon the Raven robots, aim to be applied to
the Raven robots, or are directly compared with the Raven robots, and 3) uses
the Raven robots as a case study to discuss the popular research problems in
the research community and the trend of robotic surgery study. Instead of being
a thorough literature review, this work only reviews the works formally
published in the past three years and uses these recent publications to analyze
the research interests, the popular open research problems, and opportunities
in the topic of robotic surgery."
"The last two centuries saw groundbreaking advances in the field of
healthcare: from the invention of the vaccine to organ transplant, and
eradication of numerous deadly diseases. Yet, these breakthroughs have only
illuminated the role that individual traits and behaviours play in the health
state of a person. Continuous patient monitoring and individually-tailored
therapies can help in early detection and efficient tackling of health issues.
However, even the most developed nations cannot afford proactive personalised
healthcare at scale. Mobile computing devices, nowadays equipped with an array
of sensors, high-performance computing power, and carried by their owners at
all time, promise to revolutionise modern healthcare. These devices can enable
continuous patient monitoring, and, with the help of machine learning, can
build predictive models of patient's health and behaviour. Finally, through
their close integration with a user's lifestyle mobiles can be used to deliver
personalised proactive therapies. In this article, we develop the concept of
anticipatory mobile-based healthcare - anticipatory mobile digital health - and
examine the opportunities and challenges associated with its practical
realisation."
"We show that textual analysis of microbial genomes reveal telling footprints
of the early evolution of the genomes. The frequencies of word occurrence of
random DNA sequences considered as texts in their four nucleotides are expected
to obey Poisson distributions. It is noticed that for words less than nine
letters the average width of the distributions for complete microbial genomes
is many times that of a Poisson distribution. We interpret this phenomenon as
follows: the genome is a large system that possesses the statistical
characteristics of a much smaller ``random'' system, and certain textual
statistical properties of genomes we now see are remnants of those of their
ancestral genomes, which were much shorter than the genomes are now. This
interpretation suggests a simple biologically plausible model for the growth of
genomes: the genome first grows randomly to an initial length of approximately
one thousand nucleotides (1k nt), or about one thousandth of its final length,
thereafter mainly grows by random segmental duplication. We show that using
duplicated segments averaging around 25 nt, the model sequences generated
possess statistical properties characteristic of present day genomes. Both the
initial length and the duplicated segment length support an RNA world at the
time duplication began. Random segmental duplication would greatly enhance the
ability of a genome to use its hard-to-acquire codes repeatedly, and a genome
that practiced it would have evolved enormously faster than those that did not."
"In this article, a new conceptual biomedical engineering strategy to tackle
modern disease challenges, termed as liquid metal enabled electrobiology, is
proposed. This generalized and easy going way is based on the physiological
fact that specially administrated electricity would induce a series of
subsequent desired biological effects, either shortly, transitional or
permanently. Owing high compliance within any part of the biological tissues,
the liquid metal would aid to mold a pervasive way to treat physiological or
psychological diseases. As highly conductive and non-toxic multifunctional
flexible materials, such liquid metals (LMs) consist of the core to generate
any requested electric treating fields (ETFields) which can adapt to various
sites inside the human body. The basic mechanisms of electrobiology in
delivering electricity to the target tissues and then inducing expected outputs
for disease treatment are interpreted. The methods toward realizing soft and
conformable electronics based on liquid metal are illustrated. Further, a group
of typical disease challenges were taken to illustrate the basic strategies to
perform liquid metal electrobiology therapy, which include but are not limited
to: tissue electronics, brain disorder, immunotherapy, neural functional
recovery, muscle stimulation, skin rejuvenation, cosmetology and dieting,
artificial organs, cardiac pacing and cancer therapy etc. Some practical issues
involved in the electrobiology for future disease therapy were discussed.
Perspective along this direction to incubate an easy-going biomedical tool for
health care was pointed out."
"This paper draws correlations between several challenges and opportunities
within the area of team sports analytics and key research areas within
multiagent systems (MAS). We specifically consider invasion games, defined as
sports where players invade the opposing team's territory and can interact
anywhere on a playing surface such as ice hockey, soccer, and basketball. We
argue that MAS is well-equipped to study invasion games and will benefit both
MAS and sports analytics fields. Our discussion highlights areas for MAS
implementation and further development along two axes: short-term in-game
strategy (coaching) and long-term team planning (management)."
"Bismaleimide (BMI) are thermosetting polymers mainly used in aerospace
applications having properties of dimensional stability, low shrinkage,
chemical resistance, fire resistance, good mechanical properties and high
resistance against various solvents, acids, and water. BMI is commercially
available as Homide 250. BMI coating has also been used for the corrosion
protection. Metallization (AL) of BMI using vacuum evaporation was done which
serves the purpose of prevention of space charge accumulation in aircraft
bodies. Addition of inorganic materials like metal oxides can influence the
properties of the polymer as an inorganic-organic composite. The
organic-ionorganic composites have wide applications in electronics, optics,
chemistry and medicine. Titanium dioxide (TiO2, Titania) has a wide range of
applications starting from photocatalysis, dye-sensitized solar cells to
optical coatings and electronics. A BMI-TiO2 composite was prepared by chemical
route. Atmospheric Plasma Jet (APPJ) using Helium gas was also treated on BMI.
XRD and FTIR studies of the composite system prepared at different temperatures
showed its crystalline and structural configuration."
"Immersive stories for health are 360-degree videos that intend to alter
viewer perceptions about behaviors detrimental to health. They have potential
to inform public health at scale, however, immersive story design is still in
early stages and largely devoid of best practices. This paper presents a focus
group study with 147 viewers of an immersive story about binge drinking
experienced through VR headsets and mobile phones. The objective of the study
is to identify aspects of immersive story design that influence attitudes
towards the health issue exhibited, and to understand how health information is
consumed in immersive stories. Findings emphasize the need for an immersive
story to provide reasoning behind character engagement in the focal health
behavior, to show the main character clearly engaging in the behavior, and to
enable viewers to experience escalating symptoms of the behavior before the
penultimate health consequence. Findings also show how the design of supporting
characters can inadvertently distract viewers and lead them to justify the
detrimental behavior being exhibited. The paper concludes with design
considerations for enabling immersive stories to better inform public
perception of health issues."
"The clinical practice of Medical Physics in Mexico has not been subject of
comprehensive occupational analyses. The absence of such studies not only
arises radiation safety concerns, but also imposes challenges to work-policy
making. This work presents an initial effort to overview the current
occupational status of clinical Medical Physics in Mexico. Our motivation and
final goal is to support, based on data, the legal recognition of Medical
Physics high-end training, and to provide information that will potentially
improve the Mexican health-care system. For the ease of analysis, the concept
of ""person(s) developing Medical Physics tasks"" (PDMPT) is introduced to refer
to professionals playing clinical medical physicist's (cMP) roles, disregarding
academic profile or training. A database of PDMPT in Mexico was built from
official sources and personal communication with peers. Our database included:
employer(s), specialty and academic profile. It was found that 133 hospitals in
Mexico employ PDMPT, 49% of which are public institutions. A total of 360
positions involving cMP roles were identified in the National Health-Care
System, 77% of which corresponded to radiation oncology. Public health services
hold 65% of the reported positions. Cases of double- and triple-shift workers
where identified in this study, as 283 PDMPT occupied the 360 reported
positions. Of all PDMPT, 32% were women. Only 40% of PDMPT hold a graduate
degree in Medical Physics, 46% of which were located in the most densely
populated region of Mexico. Our data suggests that Mexico is far from
fulfilling the international recommendations regarding cMP academic profile;
however, this problem could be solved in the near future for the specific cases
of radiation oncology and nuclear medicine services in the public health-care
sector."
"Combination drug therapies are treatment regimens that involve two or more
drugs, administered more commonly for patients with cancer, HIV, malaria, or
tuberculosis. Currently there are over 350K articles in PubMed that use the
""combination drug therapy"" MeSH heading with at least 10K articles published
per year over the past two decades. Extracting combination therapies from
scientific literature inherently constitutes an $n$-ary relation extraction
problem. Unlike in the general $n$-ary setting where $n$ is fixed (e.g.,
drug-gene-mutation relations where $n=3$), extracting combination therapies is
a special setting where $n \geq 2$ is dynamic, depending on each instance.
Recently, Tiktinsky et al. (NAACL 2022) introduced a first of its kind dataset,
CombDrugExt, for extracting such therapies from literature. Here, we use a
sequence-to-sequence style end-to-end extraction method to achieve an F1-Score
of $66.7\%$ on the CombDrugExt test set for positive (or effective)
combinations. This is an absolute $\approx 5\%$ F1-score improvement even over
the prior best relation classification score with spotted drug entities (hence,
not end-to-end). Thus our effort introduces a state-of-the-art first model for
end-to-end extraction that is already superior to the best prior non end-to-end
model for this task. Our model seamlessly extracts all drug entities and
relations in a single pass and is highly suitable for dynamic $n$-ary
extraction scenarios."
"Lymphomas are a large group of neoplasms developed from lymphoid cells (LCs)
in lymph nodes (LNs) or lymphoid tissues (LTs). Some forms of lymphomas,
including Burkitt lymphoma (BL), ALK+ anaplastic large cell lymphoma
(ALK+-ALCL), and T-cell lymphoblastic lymphoma/leukemia (T-LBL), occur mainly
in children and teenagers. Hodgkin's lymphoma (HL) has a peak incidence at age
20s. To understand pediatric lymphoma, we have recently proposed two hypotheses
on the causes and the mechanism of cell transformation of a LC. Hypothesis A
is: repeated bone-remodeling during bone-growth and bone-repair may be a source
of cell injuries of marrow cells including hematopoietic stem cells (HSCs),
myeloid cells, and LCs, and thymic involution may be a source of damage to the
developing T-cells in thymus. Hypothesis B is: a LC may have three pathways on
transformation: a slow, a rapid, and an accelerated. In this paper, we discuss
pediatric lymphomas by this hypothesis. Having a peak incidence at young age,
BL, T-LBL, ALK+-ALCL, and HL develop more likely as a result of rapid
transformation of a LC. In BL, ALK+-ALCL, and HL, the cell transformations may
be triggered by severe viral infections. In T-LBL, the cell transformation may
be related to thymic involution. Occurring in both adults and children, diffuse
large B-cell lymphoma (DLBCL) may develop via slow or accelerated pathway. In
conclusion, pediatric lymphoma may develop as a result of ""one-step"" cell
transformation of a LC, and severe viral infections may be the main trigger for
the rapid transformation of a LC in a LN/LT."
"The performance of a reinforcement learning algorithm can vary drastically
during learning because of exploration. Existing algorithms provide little
information about the quality of their current policy before executing it, and
thus have limited use in high-stakes applications like healthcare. We address
this lack of accountability by proposing that algorithms output policy
certificates. These certificates bound the sub-optimality and return of the
policy in the next episode, allowing humans to intervene when the certified
quality is not satisfactory. We further introduce two new algorithms with
certificates and present a new framework for theoretical analysis that
guarantees the quality of their policies and certificates. For tabular MDPs, we
show that computing certificates can even improve the sample-efficiency of
optimism-based exploration. As a result, one of our algorithms is the first to
achieve minimax-optimal PAC bounds up to lower-order terms, and this algorithm
also matches (and in some settings slightly improves upon) existing minimax
regret bounds."
"In this work, the novel task of detecting and classifying table tennis
strokes solely using the ball trajectory has been explored. A single camera
setup positioned in the umpire's view has been employed to procure a dataset
consisting of six stroke classes executed by four professional table tennis
players. Ball tracking using YOLOv4, a traditional object detection model, and
TrackNetv2, a temporal heatmap based model, have been implemented on our
dataset and their performances have been benchmarked. A mathematical approach
developed to extract temporal boundaries of strokes using the ball trajectory
data yielded a total of 2023 valid strokes in our dataset, while also detecting
services and missed strokes successfully. The temporal convolutional network
developed performed stroke recognition on completely unseen data with an
accuracy of 87.155%. Several machine learning and deep learning based model
architectures have been trained for stroke recognition using ball trajectory
input and benchmarked based on their performances. While stroke recognition in
the field of table tennis has been extensively explored based on human action
recognition using video data focused on the player's actions, the use of ball
trajectory data for the same is an unexplored characteristic of the sport.
Hence, the motivation behind the work is to demonstrate that meaningful
inferences such as stroke detection and recognition can be drawn using minimal
input information."
"Robot-assisted surgery has made great progress with the development of
medical imaging and robotics technology. Medical scene understanding can
greatly improve surgical performance while the semantic segmentation of the
robotic instrument is a key enabling technology for robot-assisted surgery.
However, how to locate an instrument's position and estimate their pose in
complex surgical environments is still a challenging fundamental problem. In
this paper, pixel-wise instrument segmentation is investigated. The
contributions of the paper are twofold: 1) We proposed a two-level nested
U-structure model, which is an encoder-decoder architecture with
skip-connections and each layer of the network structure adopts a U-structure
instead of a simple superposition of convolutional layers. The model can
capture more context information from multiple scales and better fuse the local
and global information to achieve high-quality segmentation. 2) Experiments
have been conducted to qualitatively and quantitatively show the performance of
our approach on three segmentation tasks: the binary segmentation, the parts
segmentation, and the type segmentation, respectively."
"Using the PreventS trial data, our objective is to estimate average effects
of a Health Wellness Coaching (HWC) intervention on improvement of
cardiovascular health at 9 months post randomization and in three consecutive
3-month periods over 9 months post randomization. Conventional approaches,
including instrumental variable models, are not applicable in the presence of
multiple correlated multivalued exposures and unmeasured confounding. We
propose a causal framework and its Bayesian modelling procedures to identify
and estimate average effects of one or multiple multivalued exposures on one
outcome in the presence of unmeasured confounding, noncompliance and missing
data, in a two-arm randomized trial. We also propose estimation methods of
unmeasured confounders, where the exposure and outcome distributions are
conditional on unmeasured confounders and then unmeasured confounders are
imputed as completely missing variables. Several types of model
non-identifiability and possible solutions are described. There is a risk that
estimation methods of unmeasured confounders can fail when multiple
contradictory posterior solutions are produced. The random intercept outcome
models that only adjust for unmeasured confounding in the outcome distribution
are proposed as a good surrogate causal model in this case, and they need
further development.
  There is evidence that the HWC intervention is beneficial to cardiovascular
health at 9 months post randomization. On average, completing one HWC session
improves the Life's Simple Seven total score by 0.16 (0.09, 0.22) and reduces
systolic blood pressure by 0.54 (0.19, 0.90) mm Hg. There is also evidence that
the HWC intervention has a larger beneficial effect on cardiovascular health
during 3 months post randomization. There is no clear evidence that the HWC
intervention benefits or harms mental health. The complete abstract is in the
article."
"Central venous catheters (CVCs) are commonly used in critical care settings
for monitoring body functions and administering medications. They are often
described in radiology reports by referring to their presence, identity and
placement. In this paper, we address the problem of automatic detection of
their presence and identity through automated segmentation using deep learning
networks and classification based on their intersection with previously learned
shape priors from clinician annotations of CVCs. The results not only
outperform existing methods of catheter detection achieving 85.2% accuracy at
91.6% precision, but also enable high precision (95.2%) classification of
catheter types on a large dataset of over 10,000 chest X-rays, presenting a
robust and practical solution to this problem."
"Anterior temporal lobe resection (ATLR) is a surgical procedure to treat
drug-resistant temporal lobe epilepsy (TLE). Resection may involve large
amounts of cortical tissue. Here, we examine the effects of this surgery on
cortical morphology measured in independent variables both near the resection
and remotely.
  We studied 101 individuals with TLE (55 left, 46 right onset) who underwent
ATLR. For each individual we considered one pre-surgical MRI and one follow-up
MRI 2 to 13 months after surgery. We used our newly developed surface-based
method to locally compute traditional morphological variables (average cortical
thickness, exposed surface area, and total surface area), and the independent
measures $K$, $I$, and $S$, where $K$ measures white matter tension, $I$
captures isometric scaling, and $S$ contains the remaining information about
cortical shape. Data from 924 healthy controls was included to account for
healthy ageing effects occurring during scans. A SurfStat random field theory
clustering approach assessed changes across the cortex caused by ATLR.
  Compared to preoperative data, surgery had marked effects on all
morphological measures. Ipsilateral effects were located in the orbitofrontal
and inferior frontal gyri, the pre- and postcentral gyri and supramarginal
gyrus, and the lateral occipital gyrus and lingual cortex. Contralateral
effects were in the lateral occipital gyrus, and inferior frontal gyrus and
frontal pole.
  The restructuring following ATLR is reflected in widespread morphological
changes, mainly in regions near the resection, but also remotely in regions
that are structurally connected to the anterior temporal lobe. The causes could
include mechanical effects, Wallerian degeneration, or compensatory plasticity.
The study of independent measures revealed additional effects compared to
traditional measures."
"AI systems are often used to make or contribute to important decisions in a
growing range of applications, including criminal justice, hiring, and
medicine. Since these decisions impact human lives, it is important that the AI
systems act in ways which align with human values. Techniques for preference
modeling and social choice help researchers learn and aggregate peoples'
preferences, which are used to guide AI behavior; thus, it is imperative that
these learned preferences are accurate. These techniques often assume that
people are willing to express strict preferences over alternatives; which is
not true in practice. People are often indecisive, and especially so when their
decision has moral implications. The philosophy and psychology literature shows
that indecision is a measurable and nuanced behavior -- and that there are
several different reasons people are indecisive. This complicates the task of
both learning and aggregating preferences, since most of the relevant
literature makes restrictive assumptions on the meaning of indecision. We begin
to close this gap by formalizing several mathematical \emph{indecision} models
based on theories from philosophy, psychology, and economics; these models can
be used to describe (indecisive) agent decisions, both when they are allowed to
express indecision and when they are not. We test these models using data
collected from an online survey where participants choose how to
(hypothetically) allocate organs to patients waiting for a transplant."
"A major issue in the clinical management of epilepsy is the unpredictability
of seizures. Yet, traditional approaches to seizure forecasting and risk
assessment in epilepsy rely heavily on raw seizure frequencies, which are a
stochastic measurement of seizure risk. We consider a Bayesian non-homogeneous
hidden Markov model for unsupervised clustering of zero-inflated seizure count
data. The proposed model allows for a probabilistic estimate of the sequence of
seizure risk states at the individual level. It also offers significant
improvement over prior approaches by incorporating a variable selection prior
for the identification of clinical covariates that drive seizure risk changes
and accommodating highly granular data. For inference, we implement an
efficient sampler that employs stochastic search and data augmentation
techniques. We evaluate model performance on simulated seizure count data. We
then demonstrate the clinical utility of the proposed model by analyzing daily
seizure count data from 133 patients with Dravet syndrome collected through the
Seizure Tracker TM system, a patient-reported electronic seizure diary. We
report on the dynamics of seizure risk cycling, including validation of several
known pharmacologic relationships. We also uncover novel findings
characterizing the presence and volatility of risk states in Dravet syndrome,
which may directly inform counseling to reduce the unpredictability of seizures
for patients with this devastating cause of epilepsy."
"Irregularly sampled time series data are common in a variety of fields. Many
typical methods for drawing insight from data fail in this case. Here we
attempt to generalize methods for clustering trajectories to irregularly and
sparsely sampled data. We first construct synthetic data sets, then propose and
assess four methods of data alignment to allow for application of spectral
clustering. We also repeat the same process for real data drawn from medical
records of patients with sickle cell disease -- patients whose subjective
experiences of pain were tracked for several months via a mobile app.
  We find that different methods for aligning irregularly sampled sparse data
sets can lead to different optimal numbers of clusters, even for synthetic data
with known properties. For the case of sickle cell disease, we find that three
clusters is a reasonable choice, and these appear to correspond to (1) a low
pain group with occasionally acute pain, (2) a group which experiences moderate
mean pain that fluctuates often from low to high, and (3) a group that
experiences persistent high levels of pain.
  Our results may help physicians and patients better understand and manage
patients' pain levels over time, and we expect that the methods we develop will
apply to a wide range of other data sources in medicine and beyond."
"Obstructive Sleep Apnea Syndrome (OSAS) is the most common sleep-related
breathing disorder. It is caused by an increased upper airway resistance during
sleep, which determines episodes of partial or complete interruption of
airflow. The detection and treatment of OSAS is particularly important in
stroke patients, because the presence of severe OSAS is associated with higher
mortality, worse neurological deficits, worse functional outcome after
rehabilitation, and a higher likelihood of uncontrolled hypertension. The gold
standard test for diagnosing OSAS is polysomnography (PSG). Unfortunately,
performing a PSG in an electrically hostile environment, like a stroke unit, on
neurologically impaired patients is a difficult task; also, the number of
strokes per day outnumbers the availability of polysomnographs and dedicated
healthcare professionals. Thus, a simple and automated recognition system to
identify OSAS among acute stroke patients, relying on routinely recorded vital
signs, is desirable. The majority of the work done so far focuses on data
recorded in ideal conditions and highly selected patients, and thus it is
hardly exploitable in real-life settings, where it would be of actual use. In
this paper, we propose a convolutional deep learning architecture able to
reduce the temporal resolution of raw waveform data, like physiological
signals, extracting key features that can be used for further processing. We
exploit models based on such an architecture to detect OSAS events in stroke
unit recordings obtained from the monitoring of unselected patients. Unlike
existing approaches, annotations are performed at one-second granularity,
allowing physicians to better interpret the model outcome. Results are
considered to be satisfactory by the domain experts. Moreover, based on a
widely-used benchmark, we show that the proposed approach outperforms current
state-of-the-art solutions."
"Development of resistance limits efficiency of present anticancer therapies
and preventing it remains big challenge in cancer research. It is accepted, at
intuitive level, that the resistance emerges as a consequence of cancer cells
heterogeneity at molecular, genetic and cellular levels. Produced by many
sources, tumor heterogeneity is extremely complex time dependent statistical
characteristics which may be quantified by the measures defined in many
different ways, most of them coming from statistical mechanics. In the paper we
apply Markovian framework to relate population heterogeneity with the
statistics of environment. As, from the evolutionary viewpoint, therapy
corresponds to a purposeful modification of the cells fitness landscape, we
assume that understanding general relation between spatiotemporal statistics of
tumor microenvironment and intratumor heterogeneity enables to conceive the
therapy as the inverse problem and solve it by optimization techniques. To
account for the inherent stochasticity of biological processes at cellular
scale, the generalized distance-based concept was applied to express distances
between probabilistically described cell states and environmental conditions,
respectively."
"A dataset of COVID-19-related scientific literature is compiled, combining
the articles from several online libraries and selecting those with open access
and full text available. Then, hierarchical nonnegative matrix factorization is
used to organize literature related to the novel coronavirus into a tree
structure that allows researchers to search for relevant literature based on
detected topics. We discover eight major latent topics and 52 granular
subtopics in the body of literature, related to vaccines, genetic structure and
modeling of the disease and patient studies, as well as related diseases and
virology. In order that our tool may help current researchers, an interactive
website is created that organizes available literature using this hierarchical
structure."
"Recent advances in DNA sequencing technologies have put ubiquitous
availability of fully sequenced human genomes within reach. It is no longer
hard to imagine the day when everyone will have the means to obtain and store
one's own DNA sequence. Widespread and affordable availability of fully
sequenced genomes immediately opens up important opportunities in a number of
health-related fields. In particular, common genomic applications and tests
performed in vitro today will soon be conducted computationally, using
digitized genomes. New applications will be developed as genome-enabled
medicine becomes increasingly preventive and personalized. However, this
progress also prompts significant privacy challenges associated with potential
loss, theft, or misuse of genomic data. In this paper, we begin to address
genomic privacy by focusing on three important applications: Paternity Tests,
Personalized Medicine, and Genetic Compatibility Tests. After carefully
analyzing these applications and their privacy requirements, we propose a set
of efficient techniques based on private set operations. This allows us to
implement in in silico some operations that are currently performed via in
vitro methods, in a secure fashion. Experimental results demonstrate that
proposed techniques are both feasible and practical today."
"Health professionals extensively use Two- Dimensional (2D) Ultrasound (US)
videos and images to visualize and measure internal organs for various purposes
including evaluation of muscle architectural changes. US images can be used to
measure abdominal muscles dimensions for the diagnosis and creation of
customized treatment plans for patients with Low Back Pain (LBP), however, they
are difficult to interpret. Due to high variability, skilled professionals with
specialized training are required to take measurements to avoid low
intra-observer reliability. This variability stems from the challenging nature
of accurately finding the correct spatial location of measurement endpoints in
abdominal US images. In this paper, we use a Deep Learning (DL) approach to
automate the measurement of the abdominal muscle thickness in 2D US images. By
treating the problem as a localization task, we develop a modified Fully
Convolutional Network (FCN) architecture to generate blobs of coordinate
locations of measurement endpoints, similar to what a human operator does. We
demonstrate that using the TrA400 US image dataset, our network achieves a Mean
Absolute Error (MAE) of 0.3125 on the test set, which almost matches the
performance of skilled ultrasound technicians. Our approach can facilitate next
steps for automating the process of measurements in 2D US images, while
reducing inter-observer as well as intra-observer variability for more
effective clinical outcomes."
"The generation of stylish Chinese fonts is an important problem involved in
many applications. Most of existing generation methods are based on the deep
generative models, particularly, the generative adversarial networks (GAN)
based models. However, these deep generative models may suffer from the mode
collapse issue, which significantly degrades the diversity and quality of
generated results. In this paper, we introduce a one-bit stroke encoding to
capture the key mode information of Chinese characters and then incorporate it
into CycleGAN, a popular deep generative model for Chinese font generation. As
a result we propose an efficient method called StrokeGAN, mainly motivated by
the observation that the stroke encoding contains amount of mode information of
Chinese characters. In order to reconstruct the one-bit stroke encoding of the
associated generated characters, we introduce a stroke-encoding reconstruction
loss imposed on the discriminator. Equipped with such one-bit stroke encoding
and stroke-encoding reconstruction loss, the mode collapse issue of CycleGAN
can be significantly alleviated, with an improved preservation of strokes and
diversity of generated characters. The effectiveness of StrokeGAN is
demonstrated by a series of generation tasks over nine datasets with different
fonts. The numerical results demonstrate that StrokeGAN generally outperforms
the state-of-the-art methods in terms of content and recognition accuracies, as
well as certain stroke error, and also generates more realistic characters."
"Appointment scheduling systems are utilized mainly by specialty care clinics
to manage access to service providers as well as by hospitals to schedule
patient appointments. When attending hospitals in Tanzania, patients experience
challenges to see an appropriate specialist doctor because of service interval
inconsistency. Timely availability of doctors is critical whenever a patient
needs to see a specialist doctor for treatment and a serious bottleneck lies in
the application of appropriate technology techniques to enhance appointment
scheduling. In this paper, we present a mobile based application scheduling
system for managing patient appointments. Furthermore, forthcoming
opportunities for the innovative use of the mobile based application scheduling
system are identified."
"Previous studies on ultrasound-propelled nano- and microparticles have
considered only systems where the particle orientation is perpendicular to the
direction of propagation of the ultrasound. However, in future applications of
these particles, they will typically be able to attain also other orientations.
Therefore, using direct acoustofluidic simulations, we here study how the
propulsion of cone-shaped nano- and microparticles, which are known to have a
particularly efficient acoustic propulsion and are therefore promising
candidates for future applications, depends on their orientation relative to
the propagation direction of a traveling ultrasound wave. Our results reveal
that the propulsion of the particles depends strongly on their orientation
relative to the direction of wave propagation and that the particles tend to
orient perpendicularly to the wave direction. We also present the
orientation-averaged translational and angular velocities of the particles,
which correspond to the particles' effective propulsion for an isotropic
exposure to ultrasound. Our results allow assessing how free
ultrasound-propelled colloidal particles move in three spatial dimensions and
thus constitute an important step towards the realization of the envisaged
future applications of such particles."
"Assistive ankle-foot orthoses (AAFOs) are powerful solutions to assist or
rehabilitate gait on humans. Existing AAFO technologies include passive,
quasi-passive, and active principles to provide assistance to the users, and
their mechanical configuration and control depend on the eventual support they
aim for within the gait pattern. In this research we analyze the
state-of-the-art of AAFO and classify the different approaches into clusters,
describing their basis and working principles. Additionally, we reviewed the
purpose and experimental validation of the devices, providing the reader with a
better view of the technology readiness level. Finally, the reviewed designs,
limitations, and future steps in the field are summarized and discussed."
"Medical knowledge graphs (KGs) constructed from Electronic Medical Records
(EMR) contain abundant information about patients and medical entities. The
utilization of KG embedding models on these data has proven to be efficient for
different medical tasks. However, existing models do not properly incorporate
patient demographics and most of them ignore the probabilistic features of the
medical KG. In this paper, we propose DARLING (Demographic Aware pRobabiListic
medIcal kNowledge embeddinG), a demographic-aware medical KG embedding
framework that explicitly incorporates demographics in the medical entities
space by associating patient demographics with a corresponding hyperplane. Our
framework leverages the probabilistic features within the medical entities for
learning their representations through demographic guidance. We evaluate
DARLING through link prediction for treatments and medicines, on a medical KG
constructed from EMR data, and illustrate its superior performance compared to
existing KG embedding models."
"In the current study, the authors demonstrate the method aimed at analyzing
the distribution of acute coronary syndrome (ACS) cases in Saint Petersburg
using the synthetic population approach and a statistical model for arterial
hypertension prevalence. The cumulative number of emergency services calls in a
separate geographical area (a grid cell of a map) associated with ACS is
matched with the assessed number of dwellers and individuals with arterial
hypertension, which makes it possible to find locations with excessive ACS
incidence. The proposed method is implemented in Python programming language,
the visualization results are shown using QGIS open software. Three categories
of locations are proposed based on the analysis results. The demonstrated
method might be applied for using the statistical assessments of hidden health
conditions in the population to categorize spatial distributions of their
visible consequences."
"In this study, we analyze discordance between the transcriptome and proteome
using paired scRNA-Seq and multiplexed spatial proteomics data from HuBMAP. Our
findings highlight persistent transcripts in key immune markers, including
CD45-RO, Ki67, CD45, CD20, and HLA-DR. CD45-RO is consistently expressed in
memory T cells, while Ki67, associated with cell proliferation, also displays
sustained expression. Furthermore, HLA-DR, part of the MHC class II molecules,
demonstrates continuous expression, possibly crucial for APCs to trigger an
effective immune response. This investigation provides novel insights into the
complexity of gene expression regulation and protein function."
"Hospital readmissions are expensive and reflect the inadequacies in
healthcare system. In the United States alone, treatment of readmitted diabetic
patients exceeds 250 million dollars per year. Early identification of patients
facing a high risk of readmission can enable healthcare providers to to conduct
additional investigations and possibly prevent future readmissions. This not
only improves the quality of care but also reduces the medical expenses on
readmission. Machine learning methods have been leveraged on public health data
to build a system for identifying diabetic patients facing a high risk of
future readmission. Number of inpatient visits, discharge disposition and
admission type were identified as strong predictors of readmission. Further, it
was found that the number of laboratory tests and discharge disposition
together predict whether the patient will be readmitted shortly after being
discharged from the hospital (i.e. <30 days) or after a longer period of time
(i.e. >30 days). These insights can help healthcare providers to improve
inpatient diabetic care. Finally, the cost analysis suggests that \$252.76
million can be saved across 98,053 diabetic patient encounters by incorporating
the proposed cost sensitive analysis model."
"We aimed to develop a population pharmacokinetic model of tacrolimus in
Chinese lung transplant recipients, and propose model based dosing regimens for
individualized treatment. We obtained 807 tacrolimus whole blood concentrations
from 52 lung transplant patients and genotyped CYP3A5*3. Population
pharmacokinetic analysis was performed using nonlinear mixed effects modeling.
Monte Carlo simulations were employed to design initial dosing regimens.
Tacrolimus pharmacokinetics was described by a one compartment model with first
order absorption and elimination process. The mean estimated apparent clearance
was 13.1 l/h with 20.1% inter subject variability in CYP3A5*3/*3 70kg patients
with 30% hematocrit and voriconazole free therapy, which is lower than that in
Caucasian(17.5 to 36.5 l/h). Hematocrit, postoperative days, tacrolimus daily
dose, voriconazole cotherapy, and CYP3A5*3 genotype were identified as
significant covariates for tacrolimus clearance. To achieve the target trough
concentration (10 to 15 ng/ml) on the 8th day after transplantation,
CYP3A5*1/*3 patients with voriconazole free cotherapy, a higher initial dosage
than the current regimen of 0.04 mg/kg q12h should be recommened. Given the
nonlinear kinetics of tacrolimus and large variability, population
pharmacokinetic model should be combined with therapeutic drug monitoring to
optimize individualized therapy."
"The rise of Alzheimers Disease worldwide has prompted a search for efficient
tools which can be used to predict deterioration in cognitive decline leading
to dementia. In this paper, we explore the potential of survival machine
learning as such a tool for building models capable of predicting not only
deterioration but also the likely time to deterioration. We demonstrate good
predictive ability (0.86 C-Index), lending support to its use in clinical
investigation and prediction of Alzheimers Disease risk."
"Sickle Cell Disease (SCD) is a chronic genetic disorder characterized by
recurrent acute painful episodes. Opioids are often used to manage these
painful episodes; the extent of their use in managing pain in this disorder is
an issue of debate. The risk of addiction and side effects of these opioid
treatments can often lead to more pain episodes in the future. Hence, it is
crucial to forecast future patient pain trajectories to help patients manage
their SCD to improve their quality of life without compromising their
treatment. It is challenging to obtain many pain records to design forecasting
models since it is mainly recorded by patients' self-report. Therefore, it is
expensive and painful (due to the need for patient compliance) to solve pain
forecasting problems in a purely supervised manner. In light of this challenge,
we propose to solve the pain forecasting problem using self-supervised learning
methods. Also, clustering such time-series data is crucial for patient
phenotyping, anticipating patients' prognoses by identifying ""similar""
patients, and designing treatment guidelines tailored to homogeneous patient
subgroups. Hence, we propose a self-supervised learning approach for clustering
time-series data, where each cluster comprises patients who share similar
future pain profiles. Experiments on five years of real-world datasets show
that our models achieve superior performance over state-of-the-art benchmarks
and identify meaningful clusters that can be translated into actionable
information for clinical decision-making."
"We describe team ielab from CSIRO and The University of Queensland's approach
to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers
but to utilise Large Language Models to overcome the issue of lack of training
data for such rankers. Specifically, we employ ChatGPT to generate relevant
patient descriptions for randomly selected clinical trials from the corpus.
This synthetic dataset, combined with human-annotated training data from
previous years, is used to train both dense and sparse retrievers based on
PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the
system. To further enhance the effectiveness of our approach, we prompting
GPT-4 as a TREC annotator to provide judgments on our run files. These
judgments are subsequently employed to re-rank the results. This architecture
tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large
Language Models, demonstrating a new approach to clinical trial retrieval."
"Computational pathology is part of precision oncology medicine. The
integration of high-throughput data including genomics, transcriptomics,
proteomics, metabolomics, pathomics, and radiomics into clinical practice
improves cancer treatment plans, treatment cycles, and cure rates, and helps
doctors open up innovative approaches to patient prognosis. In the past decade,
rapid advances in artificial intelligence, chip design and manufacturing, and
mobile computing have facilitated research in computational pathology and have
the potential to provide better-integrated solutions for whole-slide images,
multi-omics data, and clinical informatics. However, tumor computational
pathology now brings some challenges to the application of tumour screening,
diagnosis and prognosis in terms of data integration, hardware processing,
network sharing bandwidth and machine learning technology. This review
investigates image preprocessing methods in computational pathology from a
pathological and technical perspective, machine learning-based methods, and
applications of computational pathology in breast, colon, prostate, lung, and
various tumour disease scenarios. Finally, the challenges and prospects of
machine learning in computational pathology applications are discussed."
"We propose that the distribution of DNA words in genomic sequences can be
primarily characterized by a double Pareto-lognormal distribution, which
explains lognormal and power-law features found across all known genomes. Such
a distribution may be the result of completely random sequence evolution by
duplication processes. The parametrization of genomic word frequencies allows
for an assessment of significance for frequent or rare sequence motifs."
"The Population-based HIV Impact Assessment (PHIA) is an ongoing project that
conducts nationally representative HIV-focused surveys for measuring national
and regional progress toward UNAIDS' 90-90-90 targets, the primary strategy to
end the HIV epidemic. We believe the PHIA survey offers a unique opportunity to
better understand the key factors that drive the HIV epidemics in the most
affected countries in sub-Saharan Africa. In this article, we propose a novel
causal structural learning algorithm to discover important covariates and
potential causal pathways for 90-90-90 targets. Existing constrained-based
causal structural learning algorithms are quite aggressive in edge removal. The
proposed algorithm preserves more information about important features and
potential causal pathways. It is applied to the Malawi PHIA (MPHIA) data set
and leads to interesting results. For example, it discovers age and condom
usage to be important for female HIV awareness; the number of sexual partners
to be important for male HIV awareness; and knowing the travel time to HIV care
facilities leads to a higher chance of being treated for both females and
males. We further compare and validate the proposed algorithm using BIC and
using Monte Carlo simulations, and show that the proposed algorithm achieves
improvement in true positive rates in important feature discovery over existing
algorithms."
"The human-machine interface is of critical importance for master-slave
control of the robotic system for surgery, in which current systems offer the
control or two robotic arms teleoperated by the surgeon's hands. To relax the
need for surgical assistants and augment dexterity in surgery, it has been
recently proposed to use a robot like a third arm that can be controlled
seamlessly, independently from the natural arms, and work together with them.
This report will develop and investigate this concept by implementing foot
control of a robotic surgical arm. A novel passive haptic foot-machine
interface system and analysis of its performances were introduced in this
report. This interface using a parallel-serial hybrid structure with springs
and force sensors, which allows intuitive control of a slave robotic arm with
four degrees of freedom (dof). The elastic isometric design enables a user to
control the interface system accurately and adaptively, with an enlarged
sensing range breaking the physical restriction of the pedal size. A subject
specific (independent component analysis, ICA) model is identified to map the
surgeon's foot movements into kinematic parameters of the slave robotic arm. To
validate the system and assess the performance it allows, 10 subjects carried
out experiments to manipulate the foot-machine interface system in various
movements. With these experimental data, the mapping models were built and
verified. A comparison between different mapping models was made and analyzed
proving the ICA algorithm is obviously dominant over other methods."
"The impact of a kination-dominated phase generated by a quintessential
exponential model on the thermal abundance of Supersymmetric (SUSY) extremely
Weekly Interacting Massive Particles (e-WIMPs) is investigated. For values of
the quintessential energy-density parameter on the eve of nucleosynthesis close
to its upper bound, we find that: (i) the gravitino constraint is totally
evaded for unstable gravitinos; (ii) the thermal abundance of stable gravitinos
is not sufficient to account for the cold dark matter of the universe; (iii)
the thermal abundance of axinos can satisfy the cold dark matter constraint for
values of the initial (``reheating'') temperature well above those required in
the standard cosmology."
"Understanding the origin of infectious diseases provides scientifically based
rationales for implementing public health measures that may help to avoid or
mitigate future epidemics. The recent ancestors of a pandemic virus provide
invaluable information about the set of minimal genomic alterations that
transformed a zoonotic agent into a full human pandemic. Since the first
confirmed cases of the H1N1 pandemic virus in the spring of 2009, several
hypotheses about the strain's origins have been proposed. However, how, where,
and when it first infected humans is still far from clear. The only way to
piece together this epidemiological puzzle relies on the collective effort of
the international scientific community to increase genomic sequencing of
influenza isolates, especially ones collected in the months prior to the origin
of the pandemic."
"We demonstrate how to use lattice surgery to enact a universal set of
fault-tolerant quantum operations with color codes. Along the way, we also
improve existing surface-code lattice-surgery methods. Lattice-surgery methods
use fewer qubits and the same time or less than associated defect-braiding
methods. Furthermore, per code distance, color-code lattice surgery uses
approximately half the qubits and the same time or less than surface-code
lattice surgery. Color-code lattice surgery can also implement the Hadamard and
phase gates in a single transversal step---much faster than surface-code
lattice surgery can. Against uncorrelated circuit-level depolarizing noise,
color-code lattice surgery uses fewer qubits to achieve the same degree of
fault-tolerant error suppression as surface-code lattice surgery when the noise
rate is low enough and the error suppression demand is high enough."
"Point of care diagnostics using microscopy and computer vision methods have
been applied to a number of practical problems, and are particularly relevant
to low-income, high disease burden areas. However, this is subject to the
limitations in sensitivity and specificity of the computer vision methods used.
In general, deep learning has recently revolutionised the field of computer
vision, in some cases surpassing human performance for other object recognition
tasks. In this paper, we evaluate the performance of deep convolutional neural
networks on three different microscopy tasks: diagnosis of malaria in thick
blood smears, tuberculosis in sputum samples, and intestinal parasite eggs in
stool samples. In all cases accuracy is very high and substantially better than
an alternative approach more representative of traditional medical imaging
techniques."
"This paper aims to classify a single PCG recording as normal or abnormal for
computer-aided diagnosis. The proposed framework for this challenge has four
steps: preprocessing, feature extraction, training and validation. In the
preprocessing step, a recording is segmented into four states, i.e., the first
heart sound, systolic interval, the second heart sound, and diastolic interval
by the Springer Segmentation algorithm. In the feature extraction step, the
authors extract 324 features from multi-domains to perform classification. A
back propagation neural network is used as predication model. The optimal
threshold for distinguishing normal and abnormal is determined by the
statistics of model output for both normal and abnormal. The performance of the
proposed predictor tested by the six training sets is sensitivity 0.812 and
specificity 0.860 (overall accuracy is 0.836). However, the performance reduces
to sensitivity 0.807 and specificity 0.829 (overall accuracy is 0.818) for the
hidden test set."
"Cancer is one of the leading causes of human death. Many efforts have made to
understand its mechanism and have further identified many proteins and DNA
sequence variations as suspected targets for therapy. However, drugs targeting
these targets have low success rates, suggesting the basic mechanism still
remains unclear. Here, we develop a computational software combining Cox
proportional-hazards model and stability-selection to unearth an overlooked,
yet the most important cancer drivers hidden in massive data from The Cancer
Genome Atlas (TCGA), including 11,574 RNAseq samples and clinic data.
Generally, noncoding RNAs primarily regulate cancer deaths and work as the
deadliest cancer inducers and repressors, in contrast to proteins as
conventionally thought. Especially, processed-pseudogenes serve as the primary
cancer inducers, while lincRNA and antisense RNAs dominate the repressors.
Strikingly, noncoding RNAs serves as the universal strongest regulators for all
cancer types although personal clinic variables such as alcohol and smoking
significantly alter cancer genome. Furthermore, noncoding RNAs also work as
central hubs in cancer regulatory network and as biomarkers to discriminate
cancer types. Therefore, noncoding RNAs overall serve as the deadliest cancer
regulators, which refreshes the basic concept of cancer mechanism and builds a
novel basis for cancer research and therapy. Biological functions of
pseudogenes have rarely been recognized. Here we reveal them as the most
important cancer drivers for all cancer types from big data, breaking a wall to
explore their biological potentials."
"This paper proposes a novel, unsupervised super-resolution (SR) approach for
performing the SR of a clinical CT into the resolution level of a micro CT
($\mu$CT). The precise non-invasive diagnosis of lung cancer typically utilizes
clinical CT data. Due to the resolution limitations of clinical CT (about $0.5
\times 0.5 \times 0.5$ mm$^3$), it is difficult to obtain enough pathological
information such as the invasion area at alveoli level. On the other hand,
$\mu$CT scanning allows the acquisition of volumes of lung specimens with much
higher resolution ($50 \times 50 \times 50 \mu {\rm m}^3$ or higher). Thus,
super-resolution of clinical CT volume may be helpful for diagnosis of lung
cancer. Typical SR methods require aligned pairs of low-resolution (LR) and
high-resolution (HR) images for training. Unfortunately, obtaining paired
clinical CT and $\mu$CT volumes of human lung tissues is infeasible.
Unsupervised SR methods are required that do not need paired LR and HR images.
In this paper, we create corresponding clinical CT-$\mu$CT pairs by simulating
clinical CT images from $\mu$CT images by modified CycleGAN. After this, we use
simulated clinical CT-$\mu$CT image pairs to train an SR network based on
SRGAN. Finally, we use the trained SR network to perform SR of the clinical CT
images. We compare our proposed method with another unsupervised SR method for
clinical CT images named SR-CycleGAN. Experimental results demonstrate that the
proposed method can successfully perform SR of clinical CT images of lung
cancer patients with $\mu$CT level resolution, and quantitatively and
qualitatively outperformed conventional method (SR-CycleGAN), improving the
SSIM (structure similarity) form 0.40 to 0.51."
"Segmentation and quantification of white matter hyperintensities (WMHs) are
of great importance in studying and understanding various neurological and
geriatric disorders. Although automatic methods have been proposed for WMH
segmentation on magnetic resonance imaging (MRI), manual corrections are often
necessary to achieve clinically practical results. Major challenges for WMH
segmentation stem from their inhomogeneous MRI intensities, random location and
size distributions, and MRI noise. The presence of other brain anatomies or
diseases with enhanced intensities adds further difficulties. To cope with
these challenges, we present a specifically designed fully convolutional neural
network (FCN) with residual connections to segment WMHs by using combined T1
and fluid-attenuated inversion recovery (FLAIR) images. Our customized FCN is
designed to be straightforward and generalizable, providing efficient
end-to-end training due to its enhanced information propagation. We tested our
method on the open WMH Segmentation Challenge MICCAI2017 dataset, and, despite
our method's relative simplicity, results show that it performs amongst the
leading techniques across five metrics. More importantly, our method achieves
the best score for hausdorff distance and average volume difference in testing
datasets from two MRI scanners that were not included in training,
demonstrating better generalization ability of our proposed method over its
competitors."
"Access and adherence to antiretroviral therapy (ART) has transformed the face
of HIV infection from a fatal to a chronic disease. However, ART is also known
for its side effects. Studies have reported that ART is associated with
depressive symptomatology. Large-scale HIV clinical databases with individuals'
longitudinal depression records, ART medications, and clinical characteristics
offer researchers unprecedented opportunities to study the effects of ART drugs
on depression over time. We develop BAGEL, a Bayesian graphical model to
investigate longitudinal effects of ART drugs on a range of depressive symptoms
while adjusting for participants' demographic, behavior, and clinical
characteristics, and taking into account the heterogeneous population through a
Bayesian nonparametric prior. We evaluate BAGEL through simulation studies.
Application to a dataset from the Women's Interagency HIV Study yields
interpretable and clinically useful results. BAGEL not only can improve our
understanding of ART drugs effects on disparate depression symptoms, but also
has clinical utility in guiding informed and effective treatment selection to
facilitate precision medicine in HIV."
"Driven by the large foundation models, the development of artificial
intelligence has witnessed tremendous progress lately, leading to a surge of
general interest from the public. In this study, we aim to assess the
performance of OpenAI's newest model, GPT-4V(ision), specifically in the realm
of multimodal medical diagnosis. Our evaluation encompasses 17 human body
systems, including Central Nervous System, Head and Neck, Cardiac, Chest,
Hematology, Hepatobiliary, Gastrointestinal, Urogenital, Gynecology,
Obstetrics, Breast, Musculoskeletal, Spine, Vascular, Oncology, Trauma,
Pediatrics, with images taken from 8 modalities used in daily clinic routine,
e.g., X-ray, Computed Tomography (CT), Magnetic Resonance Imaging (MRI),
Positron Emission Tomography (PET), Digital Subtraction Angiography (DSA),
Mammography, Ultrasound, and Pathology. We probe the GPT-4V's ability on
multiple clinical tasks with or without patent history provided, including
imaging modality and anatomy recognition, disease diagnosis, report generation,
disease localisation.
  Our observation shows that, while GPT-4V demonstrates proficiency in
distinguishing between medical image modalities and anatomy, it faces
significant challenges in disease diagnosis and generating comprehensive
reports. These findings underscore that while large multimodal models have made
significant advancements in computer vision and natural language processing, it
remains far from being used to effectively support real-world medical
applications and clinical decision-making.
  All images used in this report can be found in
https://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation."
"This paper shines a light on the potential of definition-based semantic
models for detecting idiomatic and semi-idiomatic multiword expressions (MWEs)
in clinical terminology. Our study focuses on biomedical entities defined in
the UMLS ontology and aims to help prioritize the translation efforts of these
entities. In particular, we develop an effective tool for scoring the
idiomaticity of biomedical MWEs based on the degree of similarity between the
semantic representations of those MWEs and a weighted average of the
representation of their constituents. We achieve this using a biomedical
language model trained to produce similar representations for entity names and
their definitions, called BioLORD. The importance of this definition-based
approach is highlighted by comparing the BioLORD model to two other
state-of-the-art biomedical language models based on Transformer: SapBERT and
CODER. Our results show that the BioLORD model has a strong ability to identify
idiomatic MWEs, not replicated in other models. Our corpus-free idiomaticity
estimation helps ontology translators to focus on more challenging MWEs."
"In this work we develop a stochastic model of acute HIV infection, based on
the well-known standard model, that allows us to simulate the complex mutation
pathways of HIV escape from multiple CTL responses. Under this model, we
describe two computational inference methods. In one, we use a Bayesian
approach to construct posteriors for the parameters of our model. In the
second, we use hypothesis testing to determine the fit of the model to data.
The methods are applied to two CHAVI datasets, demonstrating the importance of
accounting for the interaction of multiple mutant variants and
multi-directional selection in analysing HIV dynamics under CTL response."
"The transfer of the medical care services to the patient, rather than the
transport of the patient to the medical services providers is aim of the
project. This is achieved by using web-based applications including Modern
Medical Informatics Services which is easier, faster and less expensive. The
required system implements the suitable informatics and electronics solutions
efficiently for the Tele-medicine care. We proposed an approach to manage
different multimedia medical databases in the telemedicine system. In order to
be efficiently and effectively manage, search, and display database
information, we define an information package for both of doctor and patient as
a concise data set of their medical information from each visit. The
methodology for accessing various types of medical records will be provided,
also we will design two web-based interfaces, high-quality data and display for
many medical service purposes."
"With the increasing availability of new image registration approaches, an
unbiased evaluation is becoming more needed so that clinicians can choose the
most suitable approaches for their applications. Current evaluations typically
use landmarks in manually annotated datasets. As a result, the quality of
annotations is crucial for unbiased comparisons. Even though most data
providers claim to have quality control over their datasets, an objective
third-party screening can be reassuring for intended users. In this study, we
use the variogram to screen the manually annotated landmarks in two datasets
used to benchmark registration in image-guided neurosurgeries. The variogram
provides an intuitive 2D representation of the spatial characteristics of
annotated landmarks. Using variograms, we identified potentially problematic
cases and had them examined by experienced radiologists. We found that (1) a
small number of annotations may have fiducial localization errors; (2) the
landmark distribution for some cases is not ideal to offer fair comparisons. If
unresolved, both findings could incur bias in registration evaluation."
"Agricultural fertilizers are essential to enhance proper growth and crop
yield. Chemical fertilizers endanger ecosystems, soil, plants, and animal and
human lives. This has increased interest in biofertilizers which are products
that contain living microorganisms or natural compounds derived from organisms
such as bacteria, fungi, and algae that improve soil chemical and biological
properties, stimulate plant growth and restore soil fertility. This study aimed
to use natural coagulants in the management of fishpond sediment for the
potential recovery of nutrients that can be utilized in crop production as
organic fertilizers. Fishpond wastewater and sediment were collected, treated
with natural, powdered Moringa oleifera seed coagulant, and dried. Greenhouse
evaluation of the dried sediment was carried out using maize seeds on soil
primed with the sediment. Growth parameters such as plant height, leaf length,
root length, plant weight, and percentage yield were determined. The nitrate,
total nitrogen, phosphate, and total phosphorus content of the organic
fertilizer were also determined. Plant height in maize showed a 35.8-44.4 %
increase in fertilized maize and a 20.3-39.3 % increase in the leaf length.
There was a 38.8-66 % increase in root length and a 23.9-36.5 % increase in
plant weight in fertilized maize. The nutritive component was 59.80 mg/Kg,
655.56 mg/Kg, 103.87 mg/Kg, and 426.60 mg/Kg respectively. For a period of 21
days of active growth, the growth rate of maize primed with organic fertilizer
was 0.93 cm/day with a total yield of 100 % while the control was 0.68 cm/day
with a total yield of 50 %. A dried biofertilizer that can improve plant
growth, weight, and percentage yield without having to deal with smelly manure
looks promising and seems to be a better alternative to explore in agriculture."
"Malaria is one of the deadliest infectious diseases globally, causing
hundreds of thousands of deaths each year. It disproportionately affects young
children, with two-thirds of fatalities occurring in under-fives. Individuals
acquire protection from disease through repeated exposure, and this immunity
plays a crucial role in the dynamics of malaria spread. We develop a novel
age-structured PDE malaria model, which couples vector-host epidemiological
dynamics with immunity dynamics. Our model tracks the acquisition and loss of
anti-disease immunity during transmission and its corresponding nonlinear
feedback onto the transmission parameters. We derive the basic reproduction
number ($\mathcal{R}_0$) as the threshold condition for the stability of
disease-free equilibrium; we also interpret $\mathcal{R}_0$ probabilistically
as a weighted sum of cases generated by infected individuals at different
infectious stages and different ages. We parametrize our model using
demographic and immunological data from sub-Saharan regions. Numerical
bifurcation analysis demonstrates the existence of an endemic equilibrium, and
we observe a forward bifurcation in $\mathcal{R}_0$. Our numerical simulations
reproduce the heterogeneity in the age distributions of immunity profiles and
infection status created by frequent exposure. Motivated by the recently
approved RTS,S vaccine, we also study the impact of vaccination; our results
show a reduction in severe disease among young children but a small increase in
severe malaria among older children due to lower acquired immunity from delayed
exposure."
"We consider multiple diseases spreading in a static Configuration Model
network. We make standard assumptions that infection transmits from neighbor to
neighbor at a disease-specific rate and infected individuals recover at a
disease-specific rate. Infection by one disease confers immediate and permanent
immunity to infection by any disease. Under these assumptions, we find a
simple, low-dimensional ordinary differential equations model which captures
the global dynamics of the infection. The dynamics depend strongly on initial
conditions. Although we motivate this article with infectious disease, the
model may be adapted to the spread of other infectious agents such as competing
political beliefs, rumors, or adoption of new technologies if these are
influenced by contacts. As an example, we demonstrate how to model an
infectious disease which can be prevented by a behavior change."
"The functionality and viability of stored human red blood cells (RBCs) is an
important clinical issue in transfusion. To systematically investigate changes
in stored whole blood, the hematological properties of individual RBCs were
quantified in blood samples stored for various periods with and without a
preservation solution called CPDA-1. With 3-D quantitative phase imaging
techniques, the optical measurements of the 3-D refractive index (RI)
distributions and membrane fluctuations were done at the individual cell level.
From the optical measurements, the morphological (volume, surface area and
sphericity), biochemical (hemoglobin content and concentration), and mechanical
parameters (dynamic membrane fluctuation) were simultaneously quantified to
investigate the functionalities and their progressive alterations in stored
RBCs. Our results show that the stored RBCs without CPDA-1 had a dramatic
morphological transformation from discocytes to spherocytes within 2 weeks
which was accompanied with significant decreases in cell deformability and cell
surface area, and increases in sphericity. However, the stored RBCs with CPDA-1
maintained their morphology and deformability for up to 6 weeks."
"Oxidative stress, a reaction caused by the imbalance between the reactive
oxygen species of human organism and its ability to detoxify reactive
intermediates and to repair the resulting damage plays an important role in
HIV-infections. On one hand, HIV infection is responsible for the chronic
oxidative stress of the patients. On the other hand, the oxidative stress
contributions to the HIV disease pathogenesis. In this paper, we integrate
oxidative stress into an HIV infection model to investigate its effects on the
virus dynamics. Through mathematical analysis, we obtain the basic reproduction
number R0 of the model which describes the persistence of viruses. In
particular, we show that for R0 > 1, the model has a bistable interval with
virus rebound threshold and elite control threshold. Numerical simulations and
bifurcation analysis are presented to illustrate the viral dynamics under
oxidative stress. Our investigation reveals the interplay between viruses and
the reaction of human organism including immune response and oxidative stress,
and their effects on the health of human being."
"Background: Shared decision-making (SDM) aims to empower patients to take an
active role in their treatment choices, supported by clinicians and patient
decision aids (PDAs). The purpose of this study is to explore barriers and
possible facilitators to SDM and a PDA in the prostate cancer trajectory. In
the process we identify possible actions that organizations and individuals can
take to support implementation in practice.
  Methods: We use the Ottawa Model of Research Use as a framework to determine
the barriers and facilitators to SDM and PDAs from the perspective of
clinicians. Semi-structured interviews were conducted with urologists (n=4),
radiation oncologists (n=3), and oncology nurses (n=2), focusing on the current
decision-making process experienced by these stakeholders. Questions included
their attitudes towards SDM and PDAs, barriers to implementation and possible
strategies to overcome them.
  Results: Time pressure and patient characteristics were cited as major
barriers by 55% of the clinicians we interviewed. Structural factors such as
external quotas for certain treatment procedures were also considered as
barriers by 44% of the clinicians. Facilitating factors involved organizational
changes to em-bed PDAs in the treatment trajectory, training in using PDAs as a
tool for SDM, and clinician motivation by disseminating positive clinical
outcomes. Our findings also suggest a role for external stakeholders such as
healthcare insurers in creating economic incentives to facilitate
implementation.
  Conclusion: Our findings highlight the importance of a multi-faceted
implementation strategy to support SDM. While clinician motivation and patient
activation are essential, structural/economic barriers may hamper
implementation. Action must also be taken at the administrative and policy
levels to foster a collaborative environment for SDM and, in the process, for
PDAs."
"The release of ChatGPT, a language model capable of generating text that
appears human-like and authentic, has gained significant attention beyond the
research community. We expect that the convincing performance of ChatGPT
incentivizes users to apply it to a variety of downstream tasks, including
prompting the model to simplify their own medical reports. To investigate this
phenomenon, we conducted an exploratory case study. In a questionnaire, we
asked 15 radiologists to assess the quality of radiology reports simplified by
ChatGPT. Most radiologists agreed that the simplified reports were factually
correct, complete, and not potentially harmful to the patient. Nevertheless,
instances of incorrect statements, missed key medical findings, and potentially
harmful passages were reported. While further studies are needed, the initial
insights of this study indicate a great potential in using large language
models like ChatGPT to improve patient-centered care in radiology and other
medical domains."
"With the advancements in computer technology, there is a rapid development of
intelligent systems to understand the complex relationships in data to make
predictions and classifications. Artificail Intelligence based framework is
rapidly revolutionizing the healthcare industry. These intelligent systems are
built with machine learning and deep learning based robust models for early
diagnosis of diseases and demonstrates a promising supplementary diagnostic
method for frontline clinical doctors and surgeons. Machine Learning and Deep
Learning based systems can streamline and simplify the steps involved in
diagnosis of diseases from clinical and image-based data, thus providing
significant clinician support and workflow optimization. They mimic human
cognition and are even capable of diagnosing diseases that cannot be diagnosed
with human intelligence. This paper focuses on the survey of machine learning
and deep learning applications in across 16 medical specialties, namely Dental
medicine, Haematology, Surgery, Cardiology, Pulmonology, Orthopedics,
Radiology, Oncology, General medicine, Psychiatry, Endocrinology, Neurology,
Dermatology, Hepatology, Nephrology, Ophthalmology, and Drug discovery. In this
paper along with the survey, we discuss the advancements of medical practices
with these systems and also the impact of these systems on medical
professionals."
"The hippocampus has the capacity for reactivating recently acquired memories
[1-3] and it is hypothesized that one of the functions of sleep reactivation is
the facilitation of consolidation of novel memory traces [4-11]. The dynamic
and network processes underlying such a reactivation remain, however, unknown.
We show that such a reactivation characterized by local, self-sustained
activity of a network region may be an inherent property of the recurrent
excitatory-inhibitory network with a heterogeneous structure. The entry into
the reactivation phase is mediated through a physiologically feasible
regulation of global excitability and external input sources, while the
reactivated component of the network is formed through induced network
heterogeneities during learning. We show that structural changes needed for
robust reactivation of a given network region are well within known
physiological parameters [12,13]."
"This is the preprint version of our paper on 2015 International Conference on
Virtual Rehabilitation (ICVR2015). In this paper, we described the imagination
scenarios of a touch-less interaction technology for hemiplegia, which can
support either hand or foot interaction with the smartphone or head mounted
device (HMD). The computer vision interaction technology is implemented in our
previous work, which provides a core support for gesture interaction by
accurately detecting and tracking the hand or foot gesture. The patients
interact with the application using hand/foot gesture motion in the camera
view."
"In order to uncover users' attitudes towards ChatGPT in mental health, this
study examines public opinions about ChatGPT in mental health discussions on
Reddit. Researchers used the bert-base-multilingual-uncased-sentiment
techniques for sentiment analysis and the BERTopic model for topic modeling. It
was found that overall, negative sentiments prevail, followed by positive ones,
with neutral sentiments being the least common. The prevalence of negative
emotions has increased over time. Negative emotions encompass discussions on
ChatGPT providing bad mental health advice, debates on machine vs. human value,
the fear of AI, and concerns about Universal Basic Income (UBI). In contrast,
positive emotions highlight ChatGPT's effectiveness in counseling, with
mentions of keywords like ""time"" and ""wallet."" Neutral discussions center
around private data concerns. These findings shed light on public attitudes
toward ChatGPT in mental health, potentially contributing to the development of
trustworthy AI in mental health from the public perspective."
"Motile cilia are a striking example of functional cellular organelle,
conserved across all the eukaryotic species. Motile cilia allow swimming of
cells and small organisms and transport of liquids across epithelial tissues.
Whilst the molecular structure is now very well understood, the dynamics of
cilia is not well established either at the single cilium level nor at the
level of collective beating. Indeed, a full understanding of this requires
connecting together behaviour across various lengthscales, from the molecular
to the organelle, then at cellular level and up to the tissue scale. Aside from
the fundamental interest in this system, understanding beating is important to
elucidate aspects of embryonic development and a variety of health conditions
from fertility to genetic and infectious diseases of the airways."
"The massive collection of user posts across social media platforms is
primarily untapped for artificial intelligence (AI) use cases based on the
sheer volume and velocity of textual data. Natural language processing (NLP) is
a subfield of AI that leverages bodies of documents, known as corpora, to train
computers in human-like language understanding. Using a word ranking method,
term frequency-inverse document frequency (TF-IDF), to create features across
documents, it is possible to perform unsupervised analytics, machine learning
(ML) that can group the documents without a human manually labeling the data.
For large datasets with thousands of features, t-distributed stochastic
neighbor embedding (t-SNE), k-means clustering and Latent Dirichlet allocation
(LDA) are employed to learn top words and generate topics for a Reddit and
Twitter combined corpus. Using extremely simple deep learning models, this
study demonstrates that the applied results of unsupervised analysis allow a
computer to predict either negative, positive, or neutral user sentiment
towards plastic surgery based on a tweet or subreddit post with almost 90%
accuracy. Furthermore, the model is capable of achieving higher accuracy on the
unsupervised sentiment task than on a rudimentary supervised document
classification task. Therefore, unsupervised learning may be considered a
viable option in labeling social media documents for NLP tasks."
"Doctors and Pharmacists play a foremost role in safe, effective use of
medication in health care. Still, there is no database available through which
Doctor can communicate with all field of pharmacy such as hospital Pharmacy,
Clinical Pharmacy, Community Pharmacy, Nutrition Pharmacy and Drug research
center so that they would like to cooperate with pharmacists in Medication
error prevention, Drug-Disease management, Nutrition management, and
pharmacotherapy. The authors examined the comprehensive project of implementing
Electronic Drug Information Record (EDIR), introduce the new term
Pharmacybernetic and how to reduce the medication error by integrated
management system (IMS). This paper presented EDIR conceptual model and the
flow sheet of the Pharmacybernetic system, which describes the integration of
different Pharmaceutical related aspect in the field of Cybernetic."
"Surgical robotics is a rapidly evolving field that is transforming the
landscape of surgeries. Surgical robots have been shown to enhance precision,
minimize invasiveness, and alleviate surgeon fatigue. One promising area of
research in surgical robotics is the use of reinforcement learning to enhance
the automation level. Reinforcement learning is a type of machine learning that
involves training an agent to make decisions based on rewards and punishments.
This literature review aims to comprehensively analyze existing research on
reinforcement learning in surgical robotics. The review identified various
applications of reinforcement learning in surgical robotics, including
pre-operative, intra-body, and percutaneous procedures, listed the typical
studies, and compared their methodologies and results. The findings show that
reinforcement learning has great potential to improve the autonomy of surgical
robots. Reinforcement learning can teach robots to perform complex surgical
tasks, such as suturing and tissue manipulation. It can also improve the
accuracy and precision of surgical robots, making them more effective at
performing surgeries."
"One of the most fascinating aspects of quantum mechanics is the principle
impossibility of deterministic errorless discrimination of nonorthogonal
signals, such as coherent states. On the one hand, it prevents perfect cloning
of quantum states and enables secure communication. On the other hand, it makes
a grand challenge to reach the ultimate measurement precision. Although the
minimum possible error rate (the Helstrom bound) has been known for almost five
decades, there is no practical way to achieve it. Developing the realistic
optimal measurement strategies to attain the Helstrom bound is of utmost
importance for high-precision applications, long-distance free-space and
optical fiber communication, gravitational wave detection, optical sensing in
biology and medicine, to name a few. In this work, we show an optimal receiver
for coherent states which admits a relatively simple technological
implementation. The receiver is based on multichannel splitting of the signal,
followed by feed-forward signal displacement and photon detection."
"The recent COVID-19 pandemic has become a major threat to human health and
well-being. Non-pharmaceutical interventions such as contact tracing solutions
are important to contain the spreads of COVID-19-like infectious diseases.
However, current contact tracing solutions are fragmented with limited use of
sensing technologies and centered on monitoring the interactions between
individuals without an analytical framework for evaluating effectiveness.
Therefore, we need to first explore generic architecture for contact tracing in
the context of today's Internet of Things (IoT) technologies based on a broad
range of applicable sensors. A new architecture for IoT based solutions to
contact tracing is proposed and its overall effectiveness for disease
containment is analyzed based on the traditional epidemiological models with
the simulation results. The proposed work aims to provide a framework for
assisting future designs and evaluation of IoT-based contact tracing solutions
and to enable data-driven collective efforts on combating current and future
infectious diseases."
"In this paper, we propose a general framework for combining evidence of
varying quality to estimate underlying binary latent variables in the presence
of restrictions imposed to respect the scientific context. The resulting
algorithms cluster the multivariate binary data in a manner partly guided by
prior knowledge. The primary model assumptions are that 1) subjects belong to
classes defined by unobserved binary states, such as the true presence or
absence of pathogens in epidemiology, or of antibodies in medicine, or the
""ability"" to correctly answer test questions in psychology, 2) a binary design
matrix $\Gamma$ specifies relevant features in each class, and 3) measurements
are independent given the latent class but can have different error rates.
Conditions ensuring parameter identifiability from the likelihood function are
discussed and inform the design of a novel posterior inference algorithm that
simultaneously estimates the number of clusters, design matrix $\Gamma$, and
model parameters. In finite samples and dimensions, we propose prior
assumptions so that the posterior distribution of the number of clusters and
the patterns of latent states tend to concentrate on smaller values and sparser
patterns, respectively. The model readily extends to studies where some
subjects' latent classes are known or important prior knowledge about
differential measurement accuracy is available from external sources. The
methods are illustrated with an analysis of protein data to detect clusters
representing auto-antibody classes among scleroderma patients."
"While a large body of research has formally identified apolipoprotein E
(APOE) as a major genetic risk marker for Alzheimer disease, accumulating
evidence supports the notion that other risk markers may exist. The traditional
Alzheimer-specific signature analysis methods, however, have not been able to
make full use of rich protein expression data, especially the interaction
between attributes. This paper develops a novel feature selection method to
identify pathogenic factors of Alzheimer disease using the proteomic and
clinical data. This approach has taken the weights of network nodes as the
importance order of signaling protein expression values. After generating and
evaluating the candidate subset, the method helps to select an optimal subset
of proteins that achieved an accuracy greater than 90%, which is superior to
traditional machine learning methods for clinical Alzheimer disease diagnosis.
Besides identifying a proteomic risk marker and further reinforce the link
between metabolic risk factors and Alzheimer disease, this paper also suggests
that apidonectin-linked pathways are a possible therapeutic drug target."
"We present the EVONANO platform for the evolution of nanomedicines with
application to anti-cancer treatments. EVONANO includes a simulator to grow
tumours, extract representative scenarios, and then simulate nanoparticle
transport through these scenarios to predict nanoparticle distribution. The
nanoparticle designs are optimised using machine learning to efficiently find
the most effective anti-cancer treatments. We demonstrate our platform with two
examples optimising the properties of nanoparticles and treatment to
selectively kill cancer cells over a range of tumour environments."
"Patient-specific left ventricle (LV) myocardial models have the potential to
be used in a variety of clinical scenarios for improved diagnosis and treatment
plans. Cine cardiac magnetic resonance (MR) imaging provides high resolution
images to reconstruct patient-specific geometric models of the LV myocardium.
With the advent of deep learning, accurate segmentation of cardiac chambers
from cine cardiac MR images and unsupervised learning for image registration
for cardiac motion estimation on a large number of image datasets is
attainable. Here, we propose a deep leaning-based framework for the development
of patient-specific geometric models of LV myocardium from cine cardiac MR
images, using the Automated Cardiac Diagnosis Challenge (ACDC) dataset. We use
the deformation field estimated from the VoxelMorph-based convolutional neural
network (CNN) to propagate the isosurface mesh and volume mesh of the
end-diastole (ED) frame to the subsequent frames of the cardiac cycle. We
assess the CNN-based propagated models against segmented models at each cardiac
phase, as well as models propagated using another traditional nonrigid image
registration technique."
"Tuberculosis (TB) remains a global health problem, and is the leading cause
of death from an infectious disease. A crucial step in the treatment of
tuberculosis is screening high risk populations and the early detection of the
disease, with chest x-ray (CXR) imaging being the most widely-used imaging
modality. As such, there has been significant recent interest in artificial
intelligence-based TB screening solutions for use in resource-limited scenarios
where there is a lack of trained healthcare workers with expertise in CXR
interpretation. Motivated by this pressing need and the recent recommendation
by the World Health Organization (WHO) for the use of computer-aided diagnosis
of TB, we introduce TB-Net, a self-attention deep convolutional neural network
tailored for TB case screening. More specifically, we leveraged machine-driven
design exploration to build a highly customized deep neural network
architecture with attention condensers. We conducted an explainability-driven
performance validation process to validate TB-Net's decision-making behaviour.
Experiments on CXR data from a multi-national patient cohort showed that the
proposed TB-Net is able to achieve accuracy/sensitivity/specificity of
99.86%/100.0%/99.71%. Radiologist validation was conducted on select cases by
two board-certified radiologists with over 10 and 19 years of experience,
respectively, and showed consistency between radiologist interpretation and
critical factors leveraged by TB-Net for TB case detection for the case where
radiologists identified anomalies. While not a production-ready solution, we
hope that the open-source release of TB-Net as part of the COVID-Net initiative
will support researchers, clinicians, and citizen data scientists in advancing
this field in the fight against this global public health crisis."
"Surgeon hand tremor limits human capability during microsurgical procedures
such as those that treat the eye. In contrast, elimination of hand tremor
through the introduction of microsurgical robots diminishes the surgeon's
tactile perception of useful and familiar tool-to-sclera forces. While the
large mass and inertia of eye surgical robot prevents surgeon microtremor, loss
of perception of small scleral forces may put the sclera at risk of injury. In
this paper, we have applied and compared two different methods to assure the
safety of sclera tissue during robot-assisted eye surgery. In the active
control method, an adaptive force control strategy is implemented on the
Steady-Hand Eye Robot in order to control the magnitude of scleral forces when
they exceed safe boundaries. This autonomous force compensation is then
compared to a passive force control method in which the surgeon performs manual
adjustments in response to the provided audio feedback proportional to the
magnitude of sclera force. A pilot study with three users indicate that the
active control method is potentially more efficient."
"This research introduces a sophisticated transfer learning model based on
Google's MobileNetV2 for breast cancer tumor classification into normal,
benign, and malignant categories, utilizing a dataset of 1576 ultrasound images
(265 normal, 891 benign, 420 malignant). The model achieves an accuracy of
0.82, precision of 0.83, recall of 0.81, ROC-AUC of 0.94, PR-AUC of 0.88, and
MCC of 0.74. It examines image intensity distributions and misclassification
errors, offering improvements for future applications. Addressing dataset
imbalances, the study ensures a generalizable model. This work, using a dataset
from Baheya Hospital, Cairo, Egypt, compiled by Walid Al-Dhabyani et al.,
emphasizes MobileNetV2's potential in medical imaging, aiming to improve
diagnostic precision in oncology. Additionally, the paper explores
Streamlit-based deployment for real-time tumor classification, demonstrating
MobileNetV2's applicability in medical imaging and setting a benchmark for
future research in oncology diagnostics."
"Recent advances in robot-assisted surgery have resulted in progressively more
precise, efficient, and minimally invasive procedures, sparking a new era of
robotic surgical intervention. This enables doctors, in collaborative
interaction with robots, to perform traditional or minimally invasive surgeries
with improved outcomes through smaller incisions. Recent efforts are working
toward making robotic surgery more autonomous which has the potential to reduce
variability of surgical outcomes and reduce complication rates. Deep
reinforcement learning methodologies offer scalable solutions for surgical
automation, but their effectiveness relies on extensive data acquisition due to
the absence of prior knowledge in successfully accomplishing tasks. Due to the
intensive nature of simulated data collection, previous works have focused on
making existing algorithms more efficient. In this work, we focus on making the
simulator more efficient, making training data much more accessible than
previously possible. We introduce Surgical Gym, an open-source high performance
platform for surgical robot learning where both the physics simulation and
reinforcement learning occur directly on the GPU. We demonstrate between
100-5000x faster training times compared with previous surgical learning
platforms. The code is available at:
https://github.com/SamuelSchmidgall/SurgicalGym."
"Cataract is a common ophthalmic disease in which a cloudy area is formed in
the lens of the eye and requires surgical removal and replacement of eye lens.
Careful selection of the intraocular lens (IOL) is critical for the
post-surgery satisfaction of the patient. Although there are various types of
IOLs in the market with different properties, it is challenging for the patient
to imagine how they will perceive the world after the surgery. We propose a
novel holographic vision simulator which utilizes non-cataractous regions on
eye lens to allow the cataract patients to experience post-operative visual
acuity before surgery. Computer generated holography display technology enables
to shape and street the light beam through the relatively clear areas of the
patient's lens. Another challenge for cataract surgeries is to match the right
patient with the right IOL. To evaluate various IOLs, we developed an
artificial human eye composed of a scleral lens, a glass retina, an iris, and a
replaceable IOL holder. Next, we tested different IOLs (monofocal and
multifocal) by capturing real-world scenes to demonstrate visual artifacts.
Then, the artificial eye was implemented in the benchtop holographic simulator
to evaluate various IOLs using different light sources and holographic
contents."
"We present multimodal neural posterior estimation (MultiNPE), a method to
integrate heterogeneous data from different sources in simulation-based
inference with neural networks. Inspired by advances in attention-based deep
fusion learning, it empowers researchers to analyze data from different domains
and infer the parameters of complex mathematical models with increased
accuracy. We formulate different multimodal fusion approaches for MultiNPE
(early, late, and hybrid) and evaluate their performance in three challenging
numerical experiments. MultiNPE not only outperforms na\""ive baselines on a
benchmark model, but also achieves superior inference on representative
scientific models from neuroscience and cardiology. In addition, we
systematically investigate the impact of partially missing data on the
different fusion strategies. Across our different experiments, late and hybrid
fusion techniques emerge as the methods of choice for practical applications of
multimodal simulation-based inference."
"In hospitals, data are siloed to specific information systems that make the
same information available under different modalities such as the different
medical imaging exams the patient undergoes (CT scans, MRI, PET, Ultrasound,
etc.) and their associated radiology reports. This offers unique opportunities
to obtain and use at train-time those multiple views of the same information
that might not always be available at test-time.
  In this paper, we propose an innovative framework that makes the most of
available data by learning good representations of a multi-modal input that are
resilient to modality dropping at test-time, using recent advances in mutual
information maximization. By maximizing cross-modal information at train time,
we are able to outperform several state-of-the-art baselines in two different
settings, medical image classification, and segmentation. In particular, our
method is shown to have a strong impact on the inference-time performance of
weaker modalities."
"Cognitive psychology delves on understanding perception, attention, memory,
language, problem-solving, decision-making, and reasoning. Large language
models (LLMs) are emerging as potent tools increasingly capable of performing
human-level tasks. The recent development in the form of GPT-4 and its
demonstrated success in tasks complex to humans exam and complex problems has
led to an increased confidence in the LLMs to become perfect instruments of
intelligence. Although GPT-4 report has shown performance on some cognitive
psychology tasks, a comprehensive assessment of GPT-4, via the existing
well-established datasets is required. In this study, we focus on the
evaluation of GPT-4's performance on a set of cognitive psychology datasets
such as CommonsenseQA, SuperGLUE, MATH and HANS. In doing so, we understand how
GPT-4 processes and integrates cognitive psychology with contextual
information, providing insight into the underlying cognitive processes that
enable its ability to generate the responses. We show that GPT-4 exhibits a
high level of accuracy in cognitive psychology tasks relative to the prior
state-of-the-art models. Our results strengthen the already available
assessments and confidence on GPT-4's cognitive psychology abilities. It has
significant potential to revolutionize the field of AI, by enabling machines to
bridge the gap between human and machine reasoning."
"Convolutional neural networks (CNNs) have gained significant popularity in
orthopedic imaging in recent years due to their ability to solve fracture
classification problems. A common criticism of CNNs is their opaque learning
and reasoning process, making it difficult to trust machine diagnosis and the
subsequent adoption of such algorithms in clinical setting. This is especially
true when the CNN is trained with limited amount of medical data, which is a
common issue as curating sufficiently large amount of annotated medical imaging
data is a long and costly process. While interest has been devoted to
explaining CNN learnt knowledge by visualizing network attention, the
utilization of the visualized attention to improve network learning has been
rarely investigated. This paper explores the effectiveness of regularizing CNN
network with human-provided attention guidance on where in the image the
network should look for answering clues. On two orthopedics radiographic
fracture classification datasets, through extensive experiments we demonstrate
that explicit human-guided attention indeed can direct correct network
attention and consequently significantly improve classification performance.
The development code for the proposed attention guidance is publicly available
on GitHub."
"Parkinson's disease is the second most common neurodegenerative disease,
affecting more than 1.2 million people in Europe. Medications are available for
the management of its symptoms, but the exact cause of the disease is unknown
and there is currently no cure on the market. To better understand the
relations between new findings and current medical knowledge, we need tools
able to analyse published medical papers based on natural language processing
and tools capable to identify various relationships of new findings with the
current medical knowledge. Our work aims to fill the above technological gap.
  To identify conflicting information in medical documents, we enact textual
entailment technology. To encapsulate existing medical knowledge, we rely on
ontologies. To connect the formal axioms in ontologies with natural text in
medical articles, we exploit ontology verbalisation techniques. To assess the
level of disagreement between human agents with respect to a medical issue, we
rely on fuzzy aggregation. To harmonize this disagreement, we design mediation
protocols within a multi-agent framework."
"Despite growing interest in quantifying and modeling the scoring dynamics
within professional sports games, relative little is known about what patterns
or principles, if any, cut across different sports. Using a comprehensive data
set of scoring events in nearly a dozen consecutive seasons of college and
professional (American) football, professional hockey, and professional
basketball, we identify several common patterns in scoring dynamics. Across
these sports, scoring tempo---when scoring events occur---closely follows a
common Poisson process, with a sport-specific rate. Similarly, scoring
balance---how often a team wins an event---follows a common Bernoulli process,
with a parameter that effectively varies with the size of the lead. Combining
these processes within a generative model of gameplay, we find they both
reproduce the observed dynamics in all four sports and accurately predict game
outcomes. These results demonstrate common dynamical patterns underlying
within-game scoring dynamics across professional team sports, and suggest
specific mechanisms for driving them. We close with a brief discussion of the
implications of our results for several popular hypotheses about sports
dynamics."
"How to compare whole genome sequences at large scale has not been achieved
via conventional methods based on pair-wisely base-to-base comparison;
nevertheless, no attention was paid to handle in-one-sitting a number of
genomes crossing genetic category (chromosome, plasmid, and phage) with farther
divergences (much less or no homologous) over large size ranges (from Kbp to
Mbp). We created a new method, GenomeFingerprinter, to unambiguously produce
three-dimensional coordinates from a sequence, followed by one
three-dimensional plot and six two-dimensional trajectory projections to
illustrate whole genome fingerprints. We further developed a set of concepts
and tools and thereby established a new method, universal genome fingerprint
analysis. We demonstrated their applications through case studies on over a
hundred of genome sequences. Particularly, we defined the total genetic
component configuration (TGCC) (i.e., chromosome, plasmid, and phage) for
describing a strain as a system, and the universal genome fingerprint map
(UGFM) of TGCC for differentiating a strain as a universal system, as well as
the systematic comparative genomics (SCG) for comparing in-one-sitting a number
of genomes crossing genetic category in diverse strains. By using UGFM,
UGFM-TGCC, and UGFM-TGCC-SCG, we compared a number of genome sequences with
farther divergences (chromosome, plasmid, and phage; bacterium, archaeal
bacterium, and virus) over large size ranges (6Kbp~5Mbp), giving new insights
into critical problematic issues in microbial genomics in the post-genomic era.
This paper provided a new method for rapidly computing, geometrically
visualizing, and intuitively comparing genome sequences at fingerprint level,
and hence established a new method of universal genome fingerprint analysis for
systematic comparative genomics."
"Majority of stroke survivors are left with poorly functioning paretic hands.
Current rehabilitation devices have failed to motivate the patients enough to
continue rehabilitation exercises. The objective of this project, MIDAS
(Multi-sensorial Immersive Dynamic Autonomous System) is a proof of concept by
using an immersive system to improve motivation of stroke patients for hand
rehabilitation. MIDAS is intended for stroke patients who suffer from light to
mild stroke. MIDAS is lightweight and portable. It consists of a hand
exoskeleton subsystem, a Virtual Reality (VR) subsystem, and an olfactory
subsystem. Altogether, MIDAS engages four out of five senses during
rehabilitation. To evaluate the efficacy of MIDAS a pilot study consisting of
three sessions is carried out on five stroke affected patients. Subsystems of
MIDAS are added progressively in each session. The game environment, sonic
effects, and scent released is carefully chosen to enhance the immersive
experience. 60% of the scores of user experience are above 40 (out of 56). 96%
Self Rehabilitation Motivation Scale (SRMS) rating shows that the participants
are motivated to use MIDAS and 87% rating shows that MIDAS is exciting for
rehabilitation. Participants experienced elevated motivation to continue stroke
rehabilitation using MIDAS and no undesired side effects were reported."
"The upper limb robotic exoskeleton is an electromechanical device which use
to recover a patients motor dysfunction in the rehabilitation field. It can
provide repetitive, comprehensive, focused, positive, and precise training to
regain the joints and muscles capability. It has been shown that existing
robotic exoskeletons are generally used rigid motors and mechanical structures.
Soft robotic devices can be a correct substitute for rigid ones. Soft exosuits
are flexible, portable, comfortable, user-friendly, low-cost, and
travel-friendly. Somehow, they need expertise or therapist to assist those
devices. Also, they cannot be adaptable to different patients with
non-identical physical parameters and various rehabilitation needs. For that
reason, nowadays we need intelligent exoskeletons during rehabilitation which
have to learn from patients previous data and act according to it with patients
intention. There also has a big gap between theoretical and practical
applications for using those exoskeletons. Most of the intelligent exoskeletons
are prototype in manner. To solve this problem, the robotic exoskeleton should
be made both criteria as ergonomic and portable. The exoskeletons have to the
power of decision-making to avoid the presence of expertise. In this growing
field, the present trend is to make the exoskeleton intelligent and make it
more reliable to use in clinical practice."
"Kidney exchange programs (KEPs) form an innovative approach to increasing the
donor pool through allowing the participation of renal patients together with a
willing but incompatible donor. The aim of a KEP is to identify groups of
incompatible donor-recipient pairs that could exchange donors leading to
feasible transplants. As the size of a kidney exchange grows, a larger
proportion of participants can be transplanted. Collaboration between multiple
transplant centers, by merging their separate kidney exchange pools is thus
desirable. As each transplant center has its own interest to provide the best
care to its own patients, collaboration requires balancing individual and
common objectives. We consider a class of algorithmic mechanisms for
multi-center kidney exchange programs we call rejection-proof mechanisms. Such
mechanisms propose solutions with the property that no player wishes to
unilaterally deviate. We provide a mechanism optimizing social value under this
restriction, though the underlying optimization problem is Sigma-2-p-Hard. We
also describe a computationally easier but sub-optimal alternative. Experiments
show that rejection-proofness can be achieved at limited cost compared to
optimal solutions for regular kidney exchange. Computationally, we provide
algorithms to compute optimal rejection-proof solutions for small and medium
instance sizes."
"This paper proposes an original theory of aging of multicellular organisms.
The cells of multicellular organisms, in contrast to unicellular organisms, are
burdened with a two- part genome: housekeeping and specialized (multicellular),
responsible for ontogenesis and terminal differentiation. The two parts of the
genome compete for limited adaptive resources thereby interfering with the
ability of the house-keeping part of the genome to adequately perform
reparative and adaptive functions in post mitotic cells. The necessity to
complete the ontgenesis program, leads to increased activity of the
multicellular components of the genome. As a result, the allocation of cellular
resources to specialized genome con-tinuously increases with time. This leads
to a deficit of reparative and adaptive capacity in post mitotic cells.
Suggestions for future research focus on identifying groups of genes
responsible for regulation of growth rate of specialized genome and suppressing
ability of the cell division. A better understanding of the relationship
between the two parts of the genome will not only help us to manipulate
ontogenesis and aging, but will also improve our understanding of cancer
development and ontogenesis."
"Transcranial ultrasound is more and more used for therapy and imaging of the
brain. However, the skull is a highly attenuating and aberrating medium, with
different structures and acoustic properties between samples and even within a
sample. Thus, case-specific simulations are needed to perform transcranial
focused ultrasound interventions safely. In this article, we provide a review
of the different methods used to model the skull and to simulate ultrasound
propagation through it."
"An increasing amount of geo-referenced mobile phone data enables the
identification of behavioral patterns, habits and movements of people. With
this data, we can extract the knowledge potentially useful for many
applications including the one tackled in this study - understanding spatial
variation of epidemics. We explored the datasets collected by a cell phone
service provider and linked them to spatial HIV prevalence rates estimated from
publicly available surveys. For that purpose, 224 features were extracted from
mobility and connectivity traces and related to the level of HIV epidemic in 50
Ivory Coast departments. By means of regression models, we evaluated predictive
ability of extracted features. Several models predicted HIV prevalence that are
highly correlated (>0.7) with actual values. Through contribution analysis we
identified key elements that impact the rate of infections. Our findings
indicate that night connectivity and activity, spatial area covered by users
and overall migrations are strongly linked to HIV. By visualizing the
communication and mobility flows, we strived to explain the spatial structure
of epidemics. We discovered that strong ties and hubs in communication and
mobility align with HIV hot spots."
"Background: A relative biological effectiveness (RBE) of 1.1 is used for
proton therapy though clinical evidence of varying RBE was raised. Clinical
studies on RBE variability have been conducted for decades for carbon
radiation, which could advance the understanding of the clinical proton RBE
given an ion-independent RBE model. In this work, such a model, linear and
simple, using the beam quantity Q = Z^2/E (Z = ion charge, E = kinetic energy
per nucleon) was tested and compared to the commonly used, proton-specific and
linear energy transfer (LET) based Wedenberg RBE model. Material and methods:
The Wedenberg and Q models, both predicting RBEmax and RBEmin (i.e., RBE at
vanishing and very high dose, respectively), are compared in terms of
ion-dependence and prediction power. An experimental in-vitro data ensemble
covering 115 publications for various ions was used as dataset. Results: The
model parameter of the Q model was observed to be similar for different ions
(in contrast to LET). The Q model was trained without any prior knowledge of
proton data. For proton RBE, the differences between experimental data and
corresponding predictions of the Wedenberg or the Q model were highly
comparable. Conclusions: A simple linear RBE model using Q instead of LET was
proposed and tested to be able to predict proton RBE using model parameter
trained based on only RBE data of other particles in a clinical proton energy
range for a large in-vitro dataset. Adding (pre)clinical knowledge from carbon
ion therapy may, therefore, reduce the dominating biological uncertainty in
proton RBE modelling. This would translate in reduced RBE related uncertainty
in proton therapy treatment planning."
"The ubiquitous availability of wearable sensors is responsible for driving
the Internet-of-Things but is also making an impact on sport sciences and
precision medicine. While human activity recognition from smartphone data or
other types of inertial measurement units (IMU) has evolved to one of the most
prominent daily life examples of machine learning, the underlying process of
time-series feature engineering still seems to be time-consuming. This lengthy
process inhibits the development of IMU-based machine learning applications in
sport science and precision medicine. This contribution discusses a feature
engineering workflow, which automates the extraction of time-series feature on
based on the FRESH algorithm (FeatuRe Extraction based on Scalable Hypothesis
tests) to identify statistically significant features from synchronized IMU
sensors (IMeasureU Ltd, NZ). The feature engineering workflow has five main
steps: time-series engineering, automated time-series feature extraction,
optimized feature extraction, fitting of a specialized classifier, and
deployment of optimized machine learning pipeline. The workflow is discussed
for the case of a user-specific running-walking classification, and the
generalization to a multi-user multi-activity classification is demonstrated."
"Fast testing can help mitigate the coronavirus disease 2019 (COVID-19)
pandemic. Despite their accuracy for single sample analysis, infectious
diseases diagnostic tools, like RT-PCR, require substantial resources to test
large populations. We develop a scalable approach for determining the viral
status of pooled patient samples. Our approach converts group testing to a
linear inverse problem, where false positives and negatives are interpreted as
generated by a noisy communication channel, and a message passing algorithm
estimates the illness status of patients. Numerical results reveal that our
approach estimates patient illness using fewer pooled measurements than
existing noisy group testing algorithms. Our approach can easily be extended to
various applications, including where false negatives must be minimized.
Finally, in a Utopian world we would have collaborated with RT-PCR experts; it
is difficult to form such connections during a pandemic. We welcome new
collaborators to reach out and help improve this work!"
"The surge in developing deep learning models for diagnosing skin lesions
through image analysis is notable, yet their clinical black faces challenges.
Current dermatology AI models have limitations: limited number of possible
diagnostic outputs, lack of real-world testing on uncommon skin lesions,
inability to detect out-of-distribution images, and over-reliance on
dermoscopic images. To address these, we present an All-In-One
\textbf{H}ierarchical-\textbf{O}ut of Distribution-\textbf{C}linical Triage
(HOT) model. For a clinical image, our model generates three outputs: a
hierarchical prediction, an alert for out-of-distribution images, and a
recommendation for dermoscopy if clinical image alone is insufficient for
diagnosis. When the recommendation is pursued, it integrates both clinical and
dermoscopic images to deliver final diagnosis. Extensive experiments on a
representative cutaneous lesion dataset demonstrate the effectiveness and
synergy of each component within our framework. Our versatile model provides
valuable decision support for lesion diagnosis and sets a promising precedent
for medical AI applications."
"We introduce RJUA-QA, a novel medical dataset for question answering (QA) and
reasoning with clinical evidence, contributing to bridge the gap between
general large language models (LLMs) and medical-specific LLM applications.
RJUA-QA is derived from realistic clinical scenarios and aims to facilitate
LLMs in generating reliable diagnostic and advice. The dataset contains 2,132
curated Question-Context-Answer pairs, corresponding about 25,000 diagnostic
records and clinical cases. The dataset covers 67 common urological disease
categories, where the disease coverage exceeds 97.6\% of the population seeking
medical services in urology. Each data instance in RJUA-QA comprises: (1) a
question mirroring real patient to inquiry about clinical symptoms and medical
conditions, (2) a context including comprehensive expert knowledge, serving as
a reference for medical examination and diagnosis, (3) a doctor response
offering the diagnostic conclusion and suggested examination guidance, (4) a
diagnosed clinical disease as the recommended diagnostic outcome, and (5)
clinical advice providing recommendations for medical examination. RJUA-QA is
the first medical QA dataset for clinical reasoning over the patient inquiries,
where expert-level knowledge and experience are required for yielding
diagnostic conclusions and medical examination advice. A comprehensive
evaluation is conducted to evaluate the performance of both medical-specific
and general LLMs on the RJUA-QA dataset. Our data is are publicly available at
\url{https://github.com/alipay/RJU_Ant_QA}."
"Respiratory sound classification is an important tool for remote screening of
respiratory-related diseases such as pneumonia, asthma, and COVID-19. To
facilitate the interpretability of classification results, especially ones
based on deep learning, many explanation methods have been proposed using
prototypes. However, existing explanation techniques often assume that the data
is non-biased and the prediction results can be explained by a set of
prototypical examples. In this work, we develop a unified example-based
explanation method for selecting both representative data (prototypes) and
outliers (criticisms). In particular, we propose a novel application of
adversarial attacks to generate an explanation spectrum of data instances via
an iterative fast gradient sign method. Such unified explanation can avoid
over-generalisation and bias by allowing human experts to assess the model
mistakes case by case. We performed a wide range of quantitative and
qualitative evaluations to show that our approach generates effective and
understandable explanation and is robust with many deep learning models"
"In this paper I describe a cellular automaton model of a multi-species
ecosystem, suitable for the study of emergent properties of macroevolution.
Unlike majority of ecological models, the number of coexisting species is not
fixed. Starting from one common ancestor they appear by ""mutations"" of existent
species, and then survive or extinct depending on the balance of local
ecological interactions. Monte-Carlo numerical simulations show that this model
is able to qualitatively reproduce phenomena that have been observed in other
models and in nature."
"Background, enhancing interoperability of bioinformatics knowledge bases is a
high priority requirement to maximize data reusability, and thus increase their
utility such as the return on investment for biomedical research. A knowledge
base may provide useful information for life scientists and other knowledge
bases, but it only acquires exchange value once the knowledge base is (re)used,
and without interoperability the utility lies dormant. Results, in this
article, we discuss several approaches to boost interoperability depending on
the interoperable parts. The findings are driven by several real-world scenario
examples that were mostly implemented by Bgee, a well-established gene
expression database. To better justify the findings are transferable, for each
Bgee interoperability experience, we also highlight similar implementations by
major bioinformatics knowledge bases. Moreover, we discuss ten general main
lessons learnt. These lessons can be applied in the context of any
bioinformatics knowledge base to foster data reusability. Conclusions, this
work provides pragmatic methods and transferable skills to promote reusability
of bioinformatics knowledge bases by focusing on interoperability."
"Low grade gliomas (LGGs) are a group of primary brain tumors usually
encountered in young patient populations. These tumors represent a difficult
challenge because many patients survive a decade or more and may be at a higher
risk for treatment-related complications. Specifically, radiation therapy is
known to have a relevant effect on survival but in many cases it can be
deferred to avoid side effects while maintaining its beneficial effect.
However, a subset of low-grade gliomas manifests more aggressive clinical
behavior and requires earlier intervention. Moreover, the effectiveness of
radiotherapy depends on the tumor characteristics. Recently Pallud et al.,
[Neuro-oncology, 14(4):1-10, 2012], studied patients with LGGs treated with
radiation therapy as a first line therapy. and found the counterintuitive
result that tumors with a fast response to the therapy had a worse prognosis
than those responding late. In this paper we construct a mathematical model
describing the basic facts of glioma progression and response to radiotherapy.
The model provides also an explanation to the observations of Pallud et al.
Using the model we propose radiation fractionation schemes that might be
therapeutically useful by helping to evaluate the tumor malignancy while at the
same time reducing the toxicity associated to the treatment."
"SN2005ip was a TypeIIn event notable for its sustained strong interaction
with circumstellar material (CSM), coronal emission lines, and IR excess,
interpreted as shock interaction with the very dense and clumpy wind of an
extreme red supergiant. We present a series of late-time spectra of SN2005ip
and a first radio detection of this SN, plus late-time X-rays, all of which
indicate that its CSM interaction is still strong a decade post-explosion. We
also present and discuss new spectra of geriatric SNe with continued CSM
interaction: SN1988Z, SN1993J, and SN1998S. From 3-10 yr post-explosion,
SN2005ip's H-alpha luminosity and other observed characteristics were nearly
identical to those of the radio-luminous SN1988Z, and much more luminous than
SNe1993J and 1998S. At 10 yr after explosion, SN2005ip showed a drop in
H$\alpha$ luminosity, followed by a quick resurgence over several months. We
interpret this variability as ejecta crashing into a dense shell located at
around 0.05 pc from the star, which may be the same shell that caused the IR
echo at earlier epochs. The extreme H-alpha luminosities in SN2005ip and
SN1988Z are still dominated by the forward shock at 10 yr post-explosion,
whereas SN1993J and SN1998S are dominated by the reverse shock at a similar
age. Continuous strong CSM interaction in SNe~2005ip and 1988Z is indicative of
enhanced mass loss for about 1e3 yr before core collapse, longer than Ne, O, or
Si burning phases. Instead, the episodic mass loss must extend back through C
burning and perhaps even part of He burning."
"Elucidating the genetic basis of human diseases is a central goal of genetics
and molecular biology. While traditional linkage analysis and modern
high-throughput techniques often provide long lists of tens or hundreds of
disease gene candidates, the identification of disease genes among the
candidates remains time-consuming and expensive. Efficient computational
methods are therefore needed to prioritize genes within the list of candidates,
by exploiting the wealth of information available about the genes in various
databases. Here we propose ProDiGe, a novel algorithm for Prioritization of
Disease Genes. ProDiGe implements a novel machine learning strategy based on
learning from positive and unlabeled examples, which allows to integrate
various sources of information about the genes, to share information about
known disease genes across diseases, and to perform genome-wide searches for
new disease genes. Experiments on real data show that ProDiGe outperforms
state-of-the-art methods for the prioritization of genes in human diseases."
"For all diseases, prevalence has been carefully studied. In the ""classic""
paradigm, the prevalence of different diseases has usually been studied
separately. Accumulating evidences have shown that diseases can be
""correlated"". The joint analysis of prevalence of multiple diseases can provide
important insights beyond individual-disease analysis, however, has not been
well conducted. In this study, we take advantage of the uniquely valuable
Taiwan National Health Insurance Research Database (NHIRD), and conduct a
pan-disease analysis of period prevalence trend. The goal is to identify
clusters within which diseases share similar period prevalence trends. For this
purpose, a novel penalization pursuit approach is developed, which has an
intuitive formulation and satisfactory properties. In data analysis, the period
prevalence values are computed using records on close to 1 million subjects and
14 years of observation. For 405 diseases, 35 nontrivial clusters (with sizes
larger than one) and 27 trivial clusters (with sizes one) are identified. The
results differ significantly from those of the alternatives. A closer
examination suggests that the clustering results have sound interpretations.
This study is the first to conduct a pan-disease clustering analysis of
prevalence trend using the uniquely valuable NHIRD data and can have important
value in multiple aspects."
"Research in psychopathology has shown that, at an aggregate level, the
patterns of emotional change over time -- emotion dynamics -- are indicators of
one's mental health. One's patterns of emotion change have traditionally been
determined through self-reports of emotions; however, there are known issues
with accuracy, bias, and ease of data collection. Recent approaches to
determining emotion dynamics from one's everyday utterances addresses many of
these concerns, but it is not yet known whether these measures of utterance
emotion dynamics (UED) correlate with mental health diagnoses. Here, for the
first time, we study the relationship between tweet emotion dynamics and mental
health disorders. We find that each of the UED metrics studied varied by the
user's self-disclosed diagnosis. For example: average valence was significantly
higher (i.e., more positive text) in the control group compared to users with
ADHD, MDD, and PTSD. Valence variability was significantly lower in the control
group compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but
not PPD. Rise and recovery rates of valence also exhibited significant
differences from the control. This work provides important early evidence for
how linguistic cues pertaining to emotion dynamics can play a crucial role as
biosocial markers for mental illnesses and aid in the understanding, diagnosis,
and management of mental health disorders."
"The goal of this project is to develop the Genetic Algorithms (GA) for
solving the Schaffer F6 function in fewer than 4000 function evaluations on a
total of 30 runs. Four types of Genetic Algorithms (GA) are presented -
Generational GA (GGA), Steady-State (mu+1)-GA (SSGA), Steady-Generational
(mu,mu)-GA (SGGA), and (mu+mu)-GA."
"In this paper we present a method for simultaneously segmenting brain tumors
and an extensive set of organs-at-risk for radiation therapy planning of
glioblastomas. The method combines a contrast-adaptive generative model for
whole-brain segmentation with a new spatial regularization model of tumor shape
using convolutional restricted Boltzmann machines. We demonstrate
experimentally that the method is able to adapt to image acquisitions that
differ substantially from any available training data, ensuring its
applicability across treatment sites; that its tumor segmentation accuracy is
comparable to that of the current state of the art; and that it captures most
organs-at-risk sufficiently well for radiation therapy planning purposes. The
proposed method may be a valuable step towards automating the delineation of
brain tumors and organs-at-risk in glioblastoma patients undergoing radiation
therapy."
"PM2.5 produced by freight trucks has adverse impacts on human health.
However, it is unknown to what extent freight trucking affects communities of
color and the total public health burden arising from the sector. Based on
spatially resolved US federal government data, we explore the geographic
distribution of freight trucking emissions and demonstrate that Black and
Hispanic populations are more likely to be exposed to elevated emissions from
freight trucks. Our results indicate that freight trucks contribute ~10% of NOx
and ~12% of CO2 emissions from all sources in the continental US. The annual
costs to human health and the environment due to NOx, PM2.5, SO2, and CO2 from
freight trucking in the US are estimated respectively to be $11B, $5.5B, $110M,
and $30B. Overall, the sector is responsible for nearly two-fifths (~$47B out
of $120B) of all transportation-related public health damages."
"Clinical management of cancer has continuously evolved for several decades.
Biochemical, molecular and genomics approaches have brought and still bring
numerous insights into cancerous diseases. It is now accepted that some
phenomena, allowed by favorable biological conditions, emerge via mechanical
signaling at the cellular scale and via mechanical forces at the macroscale.
Mechanical phenomena in cancer have been studied in-depth over the last
decades, and their clinical applications are starting to be understood. If
numerous models and experimental setups have been proposed, only a few have led
to clinical applications. The objective of this contribution is to propose to
review a large scope of mechanical findings which have consequences on the
clinical management of cancer. This review is mainly addressed to doctoral
candidates in mechanics and applied mathematics who are faced with the
challenge of the mechanics-based modeling of cancer with the aim of clinical
applications. We show that the collaboration of the biological and mechanical
approaches has led to promising advances in terms of modeling, experimental
design and therapeutic targets. Additionally, a specific focus is brought on
imaging-informed mechanics-based models, which we believe can further the
development of new therapeutic targets and the advent of personalized medicine.
We study in detail several successful workflows on patient-specific targeted
therapies based on mechanistic modeling."
"In recent years, community structure has emerged as a key component of
complex network analysis. As more data has been collected, researchers have
begun investigating changing community structure across multiple networks.
Several methods exist to analyze changing communities, but most of these are
limited to evolution of a single network over time. In addition, most of the
existing methods are more concerned with change at the community level than at
the level of the individual node. In this paper, we introduce scaled
inclusivity, which is a method to quantify the change in community structure
across networks. Scaled inclusivity evaluates the consistency of the
classiffication of every node in a network independently. In addition, the
method can be applied cross-sectionally as well as longitudinally. In this
paper, we calculate the scaled inclusivity for a set of simulated networks of
United States cities and a set of real networks consisting of teams that play
in the top division of American college football. We found that scaled
inclusivity yields reasonable results for the consistency of individual nodes
in both sets of networks. We propose that scaled inclusivity may provide a
useful way to quantify the change in a network's community structure."
"Background: Palliative care is referred to a set of programs for patients
that suffer life-limiting illnesses. These programs aim to guarantee a minimum
level of quality of life (QoL) for the last stage of life. They are currently
based on clinical evaluation of risk of one-year mortality.
  Objectives: The main objective of this work is to develop and validate
machine-learning based models to predict the exitus of a patient within the
next year using data gathered at hospital admission.
  Methods: Five machine learning techniques were applied in our study to
develop machine-learning predictive models: Support Vector Machines,
K-neighbors Classifier, Gradient Boosting Classifier, Random Forest and
Multilayer Perceptron. All models were trained and evaluated using the
retrospective dataset. The evaluation was performed with five metrics computed
by a resampling strategy: Accuracy, the area under the ROC curve, Specificity,
Sensitivity, and the Balanced Error Rate.
  Results: All models for forecasting one-year mortality achieved an AUC ROC
from 0.858 to 0.911. Specifically, Gradient Boosting Classifier was the best
model, producing an AUC ROC of 0.911 (CI 95%, 0.911 to 0.912), a sensitivity of
0.858 (CI 95%, 0.856 to 0.86) and a specificity of 0.807 (CI 95%, 0.806 to
0808) and a BER of 0.168 (CI 95%, 0.167 to 0.169).
  Conclusions: The analysis of common information at hospital admission
combined with machine learning techniques produced models with competitive
discriminative power. Our models reach the best results reported in state of
the art. These results demonstrate that they can be used as an accurate
data-driven palliative care criteria inclusion."
"Music has been shown to enhance motor control in patients with Parkinson's
disease (PD). Notably, musical rhythm is perceived as an external auditory cue
that helps PD patients to better control movements. The rationale of such
effects is that motor control based on auditory guidance would activate a
compensatory brain network that minimizes the recruitment of the defective
pathway involving the basal ganglia. Would associating music to movement
improve its perception and control in PD? Musical sonification consists in
modifying in real-time the playback of a preselected music according to some
movement parameters. The validation of such a method is underway for
handwriting in PD patients. When confirmed, this study will strengthen the
clinical interest of musical sonification in motor control and (re)learning in
PD."
"Contact patterns in populations fundamentally influence the spread of
infectious diseases. Current mathematical methods for epidemiological
forecasting on networks largely assume that contacts between individuals are
fixed, at least for the duration of an outbreak. In reality, contact patterns
may be quite fluid, with individuals frequently making and breaking social or
sexual relationships. Here we develop a mathematical approach to predicting
disease transmission on dynamic networks in which each individual has a
characteristic behavior (typical contact number), but the identities of their
contacts change in time. We show that dynamic contact patterns shape
epidemiological dynamics in ways that cannot be adequately captured in static
network models or mass-action models. Our new model interpolates smoothly
between static network models and mass-action models using a mixing parameter,
thereby providing a bridge between disparate classes of epidemiological models.
Using epidemiological and sexual contact data from an Atlanta high school, we
then demonstrate the utility of this method for forecasting and controlling
sexually transmitted disease outbreaks."
"With the massive damage in the world caused by Coronavirus Disease 2019
SARS-CoV-2 (COVID-19), many related research topics have been proposed in the
past two years. The Chest Computed Tomography (CT) scans are the most valuable
materials to diagnose the COVID-19 symptoms. However, most schemes for COVID-19
classification of Chest CT scan is based on a single-slice level, implying that
the most critical CT slice should be selected from the original CT scan volume
manually. We simultaneously propose 2-D and 3-D models to predict the COVID-19
of CT scan to tickle this issue. In our 2-D model, we introduce the Deep
Wilcoxon signed-rank test (DWCC) to determine the importance of each slice of a
CT scan to overcome the issue mentioned previously. Furthermore, a
Convolutional CT scan-Aware Transformer (CCAT) is proposed to discover the
context of the slices fully. The frame-level feature is extracted from each CT
slice based on any backbone network and followed by feeding the features to our
within-slice-Transformer (WST) to discover the context information in the pixel
dimension. The proposed Between-Slice-Transformer (BST) is used to aggregate
the extracted spatial-context features of every CT slice. A simple classifier
is then used to judge whether the Spatio-temporal features are COVID-19 or
non-COVID-19. The extensive experiments demonstrated that the proposed CCAT and
DWCC significantly outperform the state-of-the-art methods."
"Quantifying the action of antibiotics on biofilms is essential to devise
therapies against chronic infections. Biofilms are bacterial communities
attached to moist surfaces, sheltered from external aggressions by a polymeric
matrix. Coupling a dynamic energy budget based description of cell metabolism
to surrounding concentration fields, we are able to approximate survival curves
measured for different antibiotics. We reproduce numerically stratified
distributions of cell types within the biofilm and introduce ways to
incorporate different resistance mechanisms. Qualitative predictions follow
that are in agreement with experimental observations, such as higher survival
rates of cells close to the substratum when employing antibiotics targeting
active cells or enhanced polymer production when antibiotics are administered.
The current computational model enables validation and hypothesis testing when
developing therapies."
"Iron oxide nanoparticles have tremendous scientific and technological
potential in a broad range of technologies, from energy applications to
biomedicine. To improve their performance, single-crystalline and defect-free
nanoparticles have thus far been aspired. However, in several recent studies
defect-rich nanoparticles outperform their defect-free counterparts in magnetic
hyperthermia and magnetic particle imaging. Here, an overview on the
state-of-the-art of design and characterization of defects and resulting spin
disorder in magnetic nanoparticles is presented with a focus on iron oxide
nanoparticles. The beneficial impact of defects and disorder on intracellular
magnetic hyperthermia performance of magnetic nanoparticles for drug delivery
and cancer therapy is emphasized. Defect-engineering in iron oxide
nanoparticles emerges to become an alternative approach to tailor their
magnetic properties for biomedicine, as it is already common practice in
established systems such as semiconductors and emerging fields including
perovskite solar cells. Finally, perspectives and thoughts are given on how to
deliberately induce defects in iron oxide nanoparticles and their potential
implications for magnetic tracers to monitor cell therapy and immunotherapy by
magnetic particle imaging."
"Ultrasound is one of the most frequently used imaging modality in medicine.
The high spatial resolution, its interactive nature and non-invasiveness makes
it the first choice in many examinations. Image interpretation is one of
ultrasound's main challenges. Much training is required to obtain a confident
skill level in ultrasound-based diagnostics. State-of-the-art graphics
techniques is needed to provide meaningful visualizations of ultrasound in
real-time. In this paper we present the process-pipeline for ultrasound
visualization, including an overview of the tasks performed in the specific
steps. To provide an insight into the trends of ultrasound visualization
research, we have selected a set of significant publications and divided them
into a technique-based taxonomy covering the topics pre-processing,
segmentation, registration, rendering and augmented reality. For the different
technique types we discuss the difference between ultrasound-based techniques
and techniques for other modalities."
"Aiming at developing a medical expert system for low back pain management,
the paper proposes an efficient knowledge representation scheme using frame
data structures, and also derives a reliable resolution logic through Bayesian
Network. When a patient comes to the intended expert system for diagnosis, the
proposed inference engine outputs a number of probable diseases in sorted
order, with each disease being associated with a numeric measure to indicate
its possibility of occurrence. When two or more diseases in the list have the
same or closer possibility of occurrence, Bayesian Network is used for conflict
resolution. The proposed scheme has been validated with cases of empirically
selected thirty patients. Considering the expected value 0.75 as level of
acceptance, the proposed system offers the diagnostic inference with the
standard deviation of 0.029. The computational value of Chi-Squared test has
been obtained as 11.08 with 12 degree of freedom, implying that the derived
results from the designed system conform the homogeneity with the expected
outcomes. Prior to any clinical investigations on the selected low back pain
patients, the accuracy level (average) of 73.89% has been achieved by the
proposed system, which is quite close to the expected clinical accuracy level
of 75%."
"Physical rehabilitation plays a crucial role in the recovery process of
post-stroke patients. By personalizing therapies for patients leveraging
predictive modeling and electronic health records (EHRs), healthcare providers
can make the rehabilitation process more efficient. Before predictive modeling
can provide decision support for the assignment of treatment plans, automated
methods are necessary to extract physical rehabilitation exercise information
from unstructured EHRs. We introduce a rule-based natural language processing
algorithm to annotate therapeutic procedures for stroke patients and compare it
to several small machine learning models. We find that our algorithm
outperforms these models in extracting half of the concepts where sufficient
data is available, and individual exercise descriptions can be assigned binary
labels with an f-score of no less than 0.75 per concept. More research needs to
be done before these algorithms can be deployed on unlabeled documents, but
current progress gives promise to the potential of precision rehabilitation
research."
"We review the realization of Starobinsky-type inflation within
induced-gravity Supersymmetric (SUSY) and non-SUSY models. In both cases,
inflation is in agreement with the current data and can be attained for
subplanckian values of the inflaton. The corresponding effective theories
retain perturbative unitarity up to the Planck scale and the inflaton mass is
predicted to be 3x10^13 GeV. The supergravity embedding of these models is
achieved by employing two gauge singlet chiral supefields, a superpotential
that is uniquely determined by a continuous R and a discrete Zn symmetry, and
several (semi)logarithmic Kaehler potentials that respect these symmetries.
Checking various functional forms for the non-inflaton accompanying field in
the Kaehler potentials, we identify four cases which stabilize it without
invoking higher order terms."
"Supergenes are genomic regions containing sets of tightly linked loci that
control multi-trait phenotypic polymorphisms under balancing selection. Recent
advances in genomics have uncovered significant variation in both the genomic
architecture as well as the mode of origin of supergenes across diverse
organismal systems. Although the role of genomic architecture for the origin of
supergenes has been much discussed, differences in the genomic architecture
also subsequently affect the evolutionary trajectory of supergenes and the rate
of degeneration of supergene haplotypes. In this review, we synthesize recent
genomic work and historical models of supergene evolution, highlighting how the
genomic architecture of supergenes affects their evolutionary fate. We discuss
how recent findings on classic supergenes involved in governing ant colony
social form, mimicry in butterflies, and heterostyly in flowering plants relate
to theoretical expectations. Furthermore, we use forward simulations to
demonstrate that differences in genomic architecture affect the degeneration of
supergenes. Finally, we discuss implications of the evolution of supergene
haplotypes for the long-term fate of balanced polymorphisms governed by
supergenes."
"We describe a deep learning approach for automated brain hemorrhage detection
from computed tomography (CT) scans. Our model emulates the procedure followed
by radiologists to analyse a 3D CT scan in real-world. Similar to radiologists,
the model sifts through 2D cross-sectional slices while paying close attention
to potential hemorrhagic regions. Further, the model utilizes 3D context from
neighboring slices to improve predictions at each slice and subsequently,
aggregates the slice-level predictions to provide diagnosis at CT level. We
refer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it
employs original DenseNet architecture along with adding the components of
attention for slice level predictions and recurrent neural network layer for
incorporating 3D context. The real-world performance of RADnet has been
benchmarked against independent analysis performed by three senior radiologists
for 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at
CT level that is comparable to radiologists. Further, RADnet achieves higher
recall than two of the three radiologists, which is remarkable."
"This paper deals with the control of laser spot in the context of minimally
invasive surgery of the middle ear, e.g., cholesteatoma removal. More
precisely, our work is concerned with the exhaustive burring of residual
infected cells after primary mechanical resection of the pathological tissues
since the latter cannot guarantee the treatment of all the infected tissues,
the remaining infected cells cause regeneration of the diseases in 20%-25\-% of
cases, which require a second surgery 12-18 months later. To tackle such a
complex surgery, we have developed a robotic platform that consists of the
combination of a macro-scale system (7 degrees of freedom (DoFs) robotic arm)
and a micro-scale flexible system (2 DoFs) which operates inside the middle ear
cavity. To be able to treat the residual cholesteatoma regions, we proposed a
method to automatically generate optimal laser scanning trajectories inside the
regions and between them. The trajectories are tacked using an image-based
control scheme. The proposed method and materials were validated experimentally
using the lab-made robotic platform. The obtained results in terms of accuracy
and behaviour meet perfectly the laser surgery requirements."
"Polymer chains adsorbed onto oppositely charged spherical colloidal particles
can significantly modify the particle-particle interactions. For sufficient
amounts of added polymers, the original electrostatic repulsion can even turn
into an effective attraction and relatively large kinetically stable aggregates
can form which display several unexpected and interesting peculiarities and
some intriguing biotechnological implications. The attractive interaction
contribution between two oppositely particles arises from the correlated
adsorption of polyions at the oppositely charged particle surfaces, resulting
in a non-homogeneous surface charge distribution. Here, we investigate the
aggregation kinetics of polyion-induced colloidal complexes through Monte Carlo
simulation, in which the effect of charge anisotropy is taken into account by a
DLVO-like intra-particle potential, as recentely proposed by Velegol and Thwar
[D. Velegol and P.K. Thwar, Langmuir, 17, 2001]. The results reveal that in the
presence of a charge heterogeneity the aggregation process slows down due to
the progressive increase of the potential barrier height upon clustering.
Within this framework, the experimentally observed cluster phases in
polyelectrolyte-liposomes solutions should be considered as a kinetic arrested
state."
"Vision-Language Pretraining (VLP) has demonstrated remarkable capabilities in
learning visual representations from textual descriptions of images without
annotations. Yet, effective VLP demands large-scale image-text pairs, a
resource that suffers scarcity in the medical domain. Moreover, conventional
VLP is limited to 2D images while medical images encompass diverse modalities,
often in 3D, making the learning process more challenging. To address these
challenges, we present Generative Text-Guided 3D Vision-Language Pretraining
for Unified Medical Image Segmentation (GTGM), a framework that extends of VLP
to 3D medical images without relying on paired textual descriptions.
Specifically, GTGM utilizes large language models (LLM) to generate
medical-style text from 3D medical images. This synthetic text is then used to
supervise 3D visual representation learning. Furthermore, a negative-free
contrastive learning objective strategy is introduced to cultivate consistent
visual representations between augmented 3D medical image patches, which
effectively mitigates the biases associated with strict positive-negative
sample pairings. We evaluate GTGM on three imaging modalities - Computed
Tomography (CT), Magnetic Resonance Imaging (MRI), and electron microscopy (EM)
over 13 datasets. GTGM's superior performance across various medical image
segmentation tasks underscores its effectiveness and versatility, by enabling
VLP extension into 3D medical imagery while bypassing the need for paired text."
"We consider a class of well motivated supersymmetric models of F-term hybrid
inflation (FHI) which can be linked to the supersymmetric grand unification.
The predicted scalar spectral index n_s cannot be smaller than 0.97 and can
exceed unity including corrections from minimal supergravity, if the number of
e-foldings corresponding to the pivot scale k_*=0.002/Mpc is around 50. These
results are marginally consistent with the fitting of the three-year Wilkinson
microwave anisotropy probe data by the standard power-law cosmological model
with cold dark matter and a cosmological constant. However, n_s can be reduced
by applying two mechanisms: (i) The utilization of a quasi-canonical Kahler
potential with a convenient choice of a sign and (ii) the restriction of the
number of e-foldings that k_* suffered during FHI. In the case (i), we
investigate the possible reduction of n_s without generating maxima and minima
of the potential on the inflationary path. In the case (ii), the additional
e-foldings required for solving the horizon and flatness problems can be
generated by a subsequent stage of fast-roll [slow-roll] modular inflation
realized by a string modulus which does [does not] acquire effective mass
before the onset of modular inflation."
"Multi-scale biomedical knowledge networks are expanding with emerging
experimental technologies that generates multi-scale biomedical big data. Link
prediction is increasingly used especially in bipartite biomedical networks to
identify hidden biological interactions and relationshipts between key entities
such as compounds, targets, gene and diseases. We propose a Graph Neural
Networks (GNN) method, namely Graph Pair based Link Prediction model (GPLP),
for predicting biomedical network links simply based on their topological
interaction information. In GPLP, 1-hop subgraphs extracted from known network
interaction matrix is learnt to predict missing links. To evaluate our method,
three heterogeneous biomedical networks were used, i.e. Drug-Target Interaction
network (DTI), Compound-Protein Interaction network (CPI) from NIH Tox21, and
Compound-Virus Inhibition network (CVI). Our proposed GPLP method significantly
outperforms over the state-of-the-art baselines. In addition, different network
incompleteness is analysed with our devised protocol, and we also design an
effective approach to improve the model robustness towards incomplete networks.
Our method demonstrates the potential applications in other biomedical
networks."
"Time-to-event estimands are central to many oncology clinical trials. The
estimand framework (addendum to the ICH E9 guideline) calls for precisely
defining the treatment effect of interest to align with the clinical question
of interest and requires predefining the handling of intercurrent events that
occur after treatment initiation and either preclude the observation of an
event of interest or impact the interpretation of the treatment effect. We
discuss a practical problem in clinical trial design and execution, i.e. in
some clinical contexts it is not feasible to systematically follow patients to
an event of interest. Loss to follow-up in the presence of intercurrent events
can affect the meaning and interpretation of the study results. We provide
recommendations for trial design, stressing the need for close alignment of the
clinical question of interest and study design, impact on data collection and
other practical implications. When patients cannot be systematically followed,
compromise may be necessary to select the best available estimand that can be
feasibly estimated under the circumstances. We discuss the use of sensitivity
and supplementary analyses to examine assumptions of interest."
"Chromosome analysis is essential for diagnosing genetic disorders. For
hematologic malignancies, identification of somatic clonal aberrations by
karyotype analysis remains the standard of care. However, karyotyping is costly
and time-consuming because of the largely manual process and the expertise
required in identifying and annotating aberrations. Efforts to automate
karyotype analysis to date fell short in aberration detection. Using a training
set of ~10k patient specimens and ~50k karyograms from over 5 years from the
Fred Hutchinson Cancer Center, we created a labeled set of images representing
individual chromosomes. These individual chromosomes were used to train and
assess deep learning models for classifying the 24 human chromosomes and
identifying chromosomal aberrations. The top-accuracy models utilized the
recently introduced Topological Vision Transformers (TopViTs) with
2-level-block-Toeplitz masking, to incorporate structural inductive bias.
TopViT outperformed CNN (Inception) models with >99.3% accuracy for chromosome
identification, and exhibited accuracies >99% for aberration detection in most
aberrations. Notably, we were able to show high-quality performance even in
""few shot"" learning scenarios. Incorporating the definition of clonality
substantially improved both precision and recall (sensitivity). When applied to
""zero shot"" scenarios, the model captured aberrations without training, with
perfect precision at >50% recall. Together these results show that modern deep
learning models can approach expert-level performance for chromosome aberration
detection. To our knowledge, this is the first study demonstrating the
downstream effectiveness of TopViTs. These results open up exciting
opportunities for not only expediting patient results but providing a scalable
technology for early screening of low-abundance chromosomal lesions."
"We introduce a particle-based model of self-replicating cells on a deformable
substrate composed of the dermis and the basement membrane and investigate the
relationship between dermal deformations and stem cell pattering on it. We show
that our model reproduces the formation of dermal papillae, protuberances
directing from the dermis to the epidermis, and the preferential stem cell
distributions on the tips of the dermal papillae, which the basic buckling
mechanism fails to explain. We argue that cell-type-dependent adhesion strength
of the cells to the basement membrane is crucial factors of these patterns."
"The latest large language models (LLMs) such as ChatGPT, exhibit strong
capabilities in automated mental health analysis. However, existing relevant
studies bear several limitations, including inadequate evaluations, lack of
prompting strategies, and ignorance of exploring LLMs for explainability. To
bridge these gaps, we comprehensively evaluate the mental health analysis and
emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore
the effects of different prompting strategies with unsupervised and distantly
supervised emotional information. Based on these prompts, we explore LLMs for
interpretable mental health analysis by instructing them to generate
explanations for each of their decisions. We convey strict human evaluations to
assess the quality of the generated explanations, leading to a novel dataset
with 163 human-assessed explanations. We benchmark existing automatic
evaluation metrics on this dataset to guide future related works. According to
the results, ChatGPT shows strong in-context learning ability but still has a
significant gap with advanced task-specific methods. Careful prompt engineering
with emotional cues and expert-written few-shot examples can also effectively
improve performance on mental health analysis. In addition, ChatGPT generates
explanations that approach human performance, showing its great potential in
explainable mental health analysis."
"Microarray analysis to monitor expression activities in thousands of genes
simultaneously has become routine in biomedical research during the past
decade. A tremendous amount of expression profiles are generated and stored in
the public domain and information integration by meta-analysis to detect
differentially expressed (DE) genes has become popular to obtain increased
statistical power and validated findings. Methods that aggregate transformed
$p$-value evidence have been widely used in genomic settings, among which
Fisher's and Stouffer's methods are the most popular ones. In practice, raw
data and $p$-values of DE evidence are often not available in genomic studies
that are to be combined. Instead, only the detected DE gene lists under a
certain $p$-value threshold (e.g., DE genes with $p$-value${}<0.001$) are
reported in journal publications. The truncated $p$-value information makes the
aforementioned meta-analysis methods inapplicable and researchers are forced to
apply a less efficient vote counting method or na\""{i}vely drop the studies
with incomplete information. The purpose of this paper is to develop effective
meta-analysis methods for such situations with partially censored $p$-values.
We developed and compared three imputation methods - mean imputation, single
random imputation and multiple imputation - for a general class of evidence
aggregation methods of which Fisher's and Stouffer's methods are special
examples. The null distribution of each method was analytically derived and
subsequent inference and genomic analysis frameworks were established.
Simulations were performed to investigate the type I error, power and the
control of false discovery rate (FDR) for (correlated) gene expression data.
The proposed methods were applied to several genomic applications in colorectal
cancer, pain and liquid association analysis of major depressive disorder
(MDD). The results showed that imputation methods outperformed existing
na\""{i}ve approaches. Mean imputation and multiple imputation methods performed
the best and are recommended for future applications."
"As a principled dimension reduction technique, factor models have been widely
adopted in social science, economics, bioinformatics, and many other fields.
However, in high-dimensional settings, conducting a 'correct' Bayesianfactor
analysis can be subtle since it requires both a careful prescription of the
prior distribution and a suitable computational strategy. In particular, we
analyze the issues related to the attempt of being ""noninformative"" for
elements of the factor loading matrix, especially for sparse Bayesian factor
models in high dimensions, and propose solutions to them. We show here why
adopting the orthogonal factor assumption is appropriate and can result in a
consistent posterior inference of the loading matrix conditional on the true
idiosyncratic variance and the allocation of nonzero elements in the true
loading matrix. We also provide an efficient Gibbs sampler to conduct the full
posterior inference based on the prior setup from Rockova and George (2016)and
a uniform orthogonal factor assumption on the factor matrix."
"Objective: We hypothesized that prenatal stress (PS) exerts lasting impact on
fetal heart rate (fHR). We sought to validate the presence of such PS signature
in fHR by measuring coupling between maternal HR (mHR) and fHR. Study design:
Prospective observational cohort study in stressed group (SG) mothers with
controls matched for gestational age during screening at third trimester using
Cohen Perceived Stress Scale (PSS) questionnaire with PSS-10 equal or above 19
classified as SG. Women with PSS-10 less than 19 served as control group (CG).
Setting: Klinikum rechts der Isar of the Technical University of Munich.
Population: Singleton 3rd trimester pregnant women. Methods: Transabdominal
fetal electrocardiograms (fECG) were recorded. We deployed a signal processing
algorithm termed bivariate phase-rectified signal averaging (BPRSA) to quantify
coupling between mHR and fHR resulting in a fetal stress index (FSI). Maternal
hair cortisol was measured at birth. Differences were assumed to be significant
for p value less than 0.05. Main Outcome Measures: Differences for FSI between
both groups. Results: We screened 1500 women enrolling 538 of which 16.5 %
showed a PSS-10 score equal or above 19 at 34+0 weeks. Fifty five women
eventually comprised the SG and n=55 served as CG. Median PSS was 22.0 (IQR
21.0-24.0) in the SG and 9.0 (6.0-12.0) in the CG, respectively. Maternal hair
cortisol was higher in SG than CG at 86.6 (48.0-169.2) versus 53.0 (34.4-105.9)
pg/mg. At 36+5 weeks, FSI was significantly higher in fetuses of stressed
mothers when compared to controls [0.43 (0.18-0.85) versus 0.00 (-0.49-0.18)].
Conclusion: Our findings show a persistent effect of PS affecting fetuses in
the last trimester."
"Currently, many countries are facing the problems of aging population,
serious imbalance of medical resources supply and demand, as well as uneven
geographical distribution, resulting in a huge demand for remote e-health.
Particularly, with invasions of COVID-19, the health of people and even social
stability have been challenged unprecedentedly. To contribute to these urgent
problems, this article proposes a general architecture of the remote e-health,
where the city hospital provides the technical supports and services for remote
hospitals. Meanwhile, 5G technologies supported telemedicine is introduced to
satisfy the high-speed transmission of massive multimedia medical data, and
further realize the sharing of medical resources. Moreover, to turn passivity
into initiative to prevent COVID-19, a broad area epidemic prevention and
control scheme is also investigated, especially for the remote areas. We
discuss their principles and key features, and foresee the challenges,
opportunities, and future research trends. Finally, a node value and content
popularity based caching strategy is introduced to provide a preliminary
solution of the massive data storage and low-latency transmission."
"Knowing the reflection of game theory and ethics, we develop a mathematical
representation to bridge the gap between the concepts in moral philosophy
(e.g., Kantian and Utilitarian) and AI ethics industry technology standard
(e.g., IEEE P7000 standard series for Ethical AI). As an application, we
demonstrate how human value can be obtained from the experimental game theory
(e.g., trust game experiment) so as to build an ethical AI. Moreover, an
approach to test the ethics (rightness or wrongness) of a given AI algorithm by
using an iterated Prisoner's Dilemma Game experiment is discussed as an
example. Compared with existing mathematical frameworks and testing method on
AI ethics technology, the advantages of the proposed approach are analyzed."
"Reinforcement learning (RL) can be used to learn treatment policies and aid
decision making in healthcare. However, given the need for generalization over
complex state/action spaces, the incorporation of function approximators (e.g.,
deep neural networks) requires model selection to reduce overfitting and
improve policy performance at deployment. Yet a standard validation pipeline
for model selection requires running a learned policy in the actual
environment, which is often infeasible in a healthcare setting. In this work,
we investigate a model selection pipeline for offline RL that relies on
off-policy evaluation (OPE) as a proxy for validation performance. We present
an in-depth analysis of popular OPE methods, highlighting the additional
hyperparameters and computational requirements (fitting/inference of auxiliary
models) when used to rank a set of candidate policies. We compare the utility
of different OPE methods as part of the model selection pipeline in the context
of learning to treat patients with sepsis. Among all the OPE methods we
considered, fitted Q evaluation (FQE) consistently leads to the best validation
ranking, but at a high computational cost. To balance this trade-off between
accuracy of ranking and computational efficiency, we propose a simple two-stage
approach to accelerate model selection by avoiding potentially unnecessary
computation. Our work serves as a practical guide for offline RL model
selection and can help RL practitioners select policies using real-world
datasets. To facilitate reproducibility and future extensions, the code
accompanying this paper is available online at
https://github.com/MLD3/OfflineRL_ModelSelection."
"Online proceedings for the first workshop on complex systems in sports; index
pointing to the papers that will be presented and discussed in that workshop.
The papers deal with sports from a complex systems point of view, and include
papers on a network analysis of the performance of the Spanish team in the 2010
world cup and basketball scoring, study of populations of sports fans, try to
select attributes for sports forecasting and finally try to analyze the
physical condition from the perspective of complexity."
"Background: Virtual reality simulators and machine learning have the
potential to augment understanding, assessment and training of psychomotor
performance in neurosurgery residents. Objective: This study outlines the first
application of machine learning to distinguish ""skilled"" and ""novice""
psychomotor performance during a virtual reality neurosurgical task. Methods:
Twenty-three neurosurgeons and senior neurosurgery residents comprising the
""skilled"" group and 92 junior neurosurgery residents and medical students the
""novice"" group. The task involved removing a series of virtual brain tumors
without causing injury to surrounding tissue. Over 100 features were extracted
and 68 selected using t-test analysis. These features were provided to 4
classifiers: K-Nearest Neighbors, Parzen Window, Support Vector Machine, and
Fuzzy K-Nearest Neighbors. Equal Error Rate was used to assess classifier
performance. Results: Ratios of train set size to test set size from 10% to 90%
and 5 to 30 features, chosen by the forward feature selection algorithm, were
employed. A working point of 50% train to test set size ratio and 15 features
resulted in an equal error rates as low as 8.3% using the Fuzzy K-Nearest
Neighbors classifier. Conclusion: Machine learning may be one component helping
realign the traditional apprenticeship educational paradigm to a more objective
model based on proven performance standards.
  Keywords: Artificial intelligence, Classifiers, Machine learning,
Neurosurgery skill assessment, Surgical education, Tumor resection, Virtual
reality simulation"
"Understanding the latent processes from Electronic Medical Records could be a
game changer in modern healthcare. However, the processes are complex due to
the interaction between at least three dynamic components: the illness, the
care and the recording practice. Existing methods are inadequate in capturing
the dynamic structure of care. We propose an end-to-end model that reads
medical record and predicts future risk. The model adopts the algebraic view in
that discrete medical objects are embedded into continuous vectors lying in the
same space. The bag of disease and comorbidities recorded at each hospital
visit are modeled as function of sets. The same holds for the bag of
treatments. The interaction between diseases and treatments at a visit is
modeled as the residual of the diseases minus the treatments. Finally, the
health trajectory, which is a sequence of visits, is modeled using a recurrent
neural network. We report preliminary results on chronic diseases - diabetes
and mental health - for predicting unplanned readmission."
"Cells are regulated by networks of controllers having many targets, and
targets affected by many controllers, but these ""many-to-many"" combinatorial
control systems are poorly understood. Here we analyze distinct cellular
networks (transcription factors, microRNAs, and protein kinases) and a
drug-target network. Certain network properties seem universal across systems
and species, suggesting the existence of common control strategies in biology.
The number of controllers is ~8% of targets and the density of links is 2.5%
\pm 1.2%. Links per node are predominantly exponentially distributed, implying
conservation of the average, which we explain using a mathematical model of
robustness in control networks. These findings suggest that optimal
pharmacological strategies may benefit from a similar, many-to-many
combinatorial structure, and molecular tools are available to test this
approach."
"Accurate immunological models offer the possibility of performing
highthroughput experiments in silico that can predict, or at least suggest, in
vivo phenomena. In this chapter, we compare various models of immunological
memory. We first validate an experimental immunological simulator, developed by
the authors, by simulating several theories of immunological memory with known
results. We then use the same system to evaluate the predicted effects of a
theory of immunological memory. The resulting model has not been explored
before in artificial immune systems research, and we compare the simulated in
silico output with in vivo measurements. Although the theory appears valid, we
suggest that there are a common set of reasons why immunological memory models
are a useful support tool; not conclusive in themselves."
"This study proposes an effective positive control design strategy for cancer
treatment by resorting to the combination of immunotherapy and chemotherapy.
The treatment objective is to transfer the initial number of tumor cells and
immune-competent cells from the malignant region into the region of benign
growth where the immune system can inhibit tumor growth. In order to achieve
this goal, a new modeling strategy is used that is based on Takagi-Sugen. A
Takagi-Sugeno fuzzy model is derived based on the Stepanova nonlinear model
that enables a systematic design of the controller. Then, a positive Parallel
Distributed Compensation controller is proposed based on a linear copositive
Lyapunov Function so that the tumor volume and administration of the
chemotherapeutic and immunotherapeutic drugs is reduced, while the density of
the immune-competent cells is reached to an acceptable level. Thanks to the
proposed strategy, the entire control design is formulated as a Linear
Programming problem, which can be solved very efficiently. Finally, the
simulation results show the effectiveness of the proposed control approach for
the cancer treatment. Keywords: Co-positive linear Lyapunov function, Cancer,
Chemotherapy, Immunotherapy, Positive system, Takagi-Sugeno fuzzy system."
"Early diagnosis of Alzheimer's disease is a challenge because the existing
methodologies do not identify the patients in their preclinical stage, which
can last up to a decade prior to the onset of clinical symptoms. Several
research studies demonstrate the potential of cerebrospinal fluid biomarkers,
amyloid beta 1-42, T-tau, and P-tau, in early diagnosis of Alzheimer's disease
stages. In this work, we used machine learning models to classify different
stages of Alzheimer's disease based on the cerebrospinal fluid biomarker levels
alone. An electronic health record of patients from the National Alzheimer's
Coordinating Centre database was analyzed and the patients were subdivided
based on mini-mental state scores and clinical dementia ratings. Statistical
and correlation analyses were performed to identify significant differences
between the Alzheimer's stages. Afterward, machine learning classifiers
including K-Nearest Neighbors, Ensemble Boosted Tree, Ensemble Bagged Tree,
Support Vector Machine, Logistic Regression, and Naive Bayes classifiers were
employed to classify the Alzheimer's disease stages. The results demonstrate
that Ensemble Boosted Tree (84.4%) and Logistic Regression (73.4%) provide the
highest accuracy for binary classification, while Ensemble Bagged Tree (75.4%)
demonstrates better accuracy for multiclassification. The findings from this
research are expected to help clinicians in making an informed decision
regarding the early diagnosis of Alzheimer's from the cerebrospinal fluid
biomarkers alone, monitoring of the disease progression, and implementation of
appropriate intervention measures."
"A successful intelligent control of patient food for treatment purpose must
combines patient interesting food list and doctors efficient treatment food
list. Actually, many rural communities in Sudan have extremely limited access
to diabetic diet centers. People travel long distances to clinics or medical
facilities, and there is a shortage of medical experts in most of these
facilities. This results in slow service, and patients end up waiting long
hours without receiving any attention. Hence diabetic diet expert systems can
play a significant role in such cases where medical experts are not readily
available. This paper presents the design and implementation of an intelligent
medical expert system for diabetes diet that intended to be used in Sudan. The
development of the proposed expert system went through a number of stages such
problem and need identification, requirements analysis, knowledge acquisition,
formalization, design and implementation. Visual prolog was used for designing
the graphical user interface and the implementation of the system. The proposed
expert system is a promising helpful tool that reduces the workload for
physicians and provides diabetics with simple and valuable assistance."
"Paralytic Ileus (PI) patients are at high risk of death when admitted to the
Intensive care unit (ICU), with mortality as high as 40\%. There is minimal
research concerning PI patient mortality prediction. There is a need for more
accurate prediction modeling for ICU patients diagnosed with PI. This paper
demonstrates performance improvements in predicting the mortality of ICU
patients diagnosed with PI after 24 hours of being admitted. The proposed
framework, PMPI(Process Mining Model to predict mortality of PI patients), is a
modification of the work used for prediction of in-hospital mortality for ICU
patients with diabetes. PMPI demonstrates similar if not better performance
with an Area under the ROC Curve (AUC) score of 0.82 compared to the best
results of the existing literature. PMPI uses patient medical history, the time
related to the events, and demographic information for prediction. The PMPI
prediction framework has the potential to help medical teams in making better
decisions for treatment and care for ICU patients with PI to increase their
life expectancy."
"We describe a non-LTE photoionization code to calculate the wind structure
and emergent spectrum of a red giant wind illuminated by the hot component of a
symbiotic binary system. We consider spherically symmetric winds with several
different velocity and temperature laws and derive predicted line fluxes as a
function of the red giant mass loss rate, \mdot. Our models generally match
observations of the symbiotic stars EG And and AG Peg for \mdot about 10^{-8}
\msunyr to 10^{-7} \msunyr. The optically thick cross- section of the red giant
wind as viewed from the hot component is a crucial parameter in these models.
Winds with cross-sections of 2--3 red giant radii reproduce the observed
fluxes, because the wind density is then high, about 10^9 cm^{-3}. Our models
favor winds with acceleration regions that either lie far from the red giant
photosphere or extend for 2--3 red giant radii."
"Biomedical named entities often play important roles in many biomedical text
mining tools. However, due to the incompleteness of provided synonyms and
numerous variations in their surface forms, normalization of biomedical
entities is very challenging. In this paper, we focus on learning
representations of biomedical entities solely based on the synonyms of
entities. To learn from the incomplete synonyms, we use a model-based candidate
selection and maximize the marginal likelihood of the synonyms present in top
candidates. Our model-based candidates are iteratively updated to contain more
difficult negative samples as our model evolves. In this way, we avoid the
explicit pre-selection of negative samples from more than 400K candidates. On
four biomedical entity normalization datasets having three different entity
types (disease, chemical, adverse reaction), our model BioSyn consistently
outperforms previous state-of-the-art models almost reaching the upper bound on
each dataset."
"Epidemiological early warning systems for dengue fever rely on up-to-date
epidemiological data to forecast future incidence. However, epidemiological
data typically requires time to be available, due to the application of
time-consuming laboratorial tests. This implies that epidemiological models
need to issue predictions with larger antecedence, making their task even more
difficult. On the other hand, online platforms, such as Twitter or Google,
allow us to obtain samples of users' interaction in near real-time and can be
used as sensors to monitor current incidence. In this work, we propose a
framework to exploit online data sources to mitigate the lack of up-to-date
epidemiological data by obtaining estimates of current incidence, which are
then explored by traditional epidemiological models. We show that the proposed
framework obtains more accurate predictions than alternative approaches, with
statistically better results for delays greater or equal to 4 weeks."
"We develop simple models for the global spread of infectious diseases,
emphasizing human mobility via air travel and the variation of public health
infrastructure from region to region. We derive formulas relating the total and
peak number of infections in two countries to the rate of travel between them
and their respective epidemiological parameters."
"We present a descriptive analysis of Twitter data. Our study focuses on
extracting the main side effects associated with HIV treatments. The crux of
our work was the identification of personal tweets referring to HIV. We
summarize our results in an infographic aimed at the general public. In
addition, we present a measure of user sentiment based on hand-rated tweets."
"In recent years, photoacoustics has attracted intensive research for both
anatomical and functional biomedical imaging. However, the physical interaction
between photoacoustic generated endogenous waves and an exogenous ultrasound
wave is a largely unexplored area. Here, we report the initial results about
the interaction of photoacoustic and external ultrasound waves leading to a
micro-Doppler photoacoustic (mDPA) effect, which is experimentally observed and
consistently modelled. It is based on a simultaneous excitation on the target
with a pulsed laser and continuous wave (CW) ultrasound. The thermoelastically
induced expansion will modulate the CW ultrasound and leads to transient
Doppler frequency shift. The reported mDPA effect can be described as frequency
modulation of the intense CW ultrasound carrier through photoacoustic
vibrations. This technique may open the possibility to sensitively detect the
photoacoustic vibration in deep optically and acoustically scattering medium,
avoiding acoustic distortion that exists in state-of-the-art pulsed
photoacoustic imaging systems."
"Knowing the physicochemical properties of exhaled droplets and aerosol
particles is a prerequisite for a detailed mechanistic understanding and
effective prevention of the airborne transmission of infectious human diseases.
This article provides a critical review and synthesis of scientific knowledge
on the number concentrations, size distributions, composition, mixing state,
and related properties of respiratory particles emitted upon breathing,
speaking, singing, coughing, and sneezing. We derive and present a
parameterization of respiratory particle size distributions based on five
lognormal modes related to different origins in the respiratory tract, which
can be used to trace and localize the sources of infectious particles. This
approach may support the medical treatment as well as the risk assessment for
aerosol and droplet transmission of infectious diseases. It was applied to
analyze which respiratory activities may drive the spread of specific
pathogens, such as Mycobacterium tuberculosis, influenza viruses, and
SARS-CoV-2 viruses. The results confirm the high relevance of vocalization for
the transmission of SARS-CoV-2 as well as the usefulness of physical
distancing, face masks, room ventilation, and air filtration as preventive
measures against COVID-19 and other airborne infectious diseases."
"In the field of health-care and bio-medical research, understanding the
relationship between the symptoms of diseases is crucial for early diagnosis
and determining hidden relationships between diseases. The study aimed to
understand the extent of symptom types in disease prediction tasks. In this
research, we analyze a pre-generated symptom-based human disease dataset and
demonstrate the degree of predictability for each disease based on the
Convolutional Neural Network and the Support Vector Machine. Ambiguity of
disease is studied using the K-Means and the Principal Component Analysis. Our
results indicate that machine learning can potentially diagnose diseases with
the 98-100% accuracy in the early stage, taking the characteristics of symptoms
into account. Our result highlights that types of unusual symptoms are a good
proxy for disease early identification accurately. We also highlight that
unusual symptoms increase the accuracy of the disease prediction task."
"The robot's objective is to rehabilitate the pipe joints of fresh water
supply systems by crawling into water canals and applying a restoration
material to repair the pipes. The robot's structure consists of six
wheeled-legs, three on the front separated 120{\deg} and three on the back in
the same configuration, supporting the structure along the centre of the pipe.
In this configuration the robot is able to clean and seal with a rotating tool,
similar to a cylindrical robot, covering the entire 3D in-pipe space."
"Effective therapy of complex diseases requires control of highly non-linear
complex networks that remain incompletely characterized. In particular, drug
intervention can be seen as control of signaling in cellular networks.
Identification of control parameters presents an extreme challenge due to the
combinatorial explosion of control possibilities in combination therapy and to
the incomplete knowledge of the systems biology of cells. In this review paper
we describe the main current and proposed approaches to the design of
combinatorial therapies, including the empirical methods used now by clinicians
and alternative approaches suggested recently by several authors. New
approaches for designing combinations arising from systems biology are
described. We discuss in special detail the design of algorithms that identify
optimal control parameters in cellular networks based on a quantitative
characterization of control landscapes, maximizing utilization of incomplete
knowledge of the state and structure of intracellular networks. The use of new
technology for high-throughput measurements is key to these new approaches to
combination therapy and essential for the characterization of control
landscapes and implementation of the algorithms. Combinatorial optimization in
medical therapy is also compared with the combinatorial optimization of
engineering and materials science and similarities and differences are
delineated."
"Non-invasive prenatal testing or NIPT is currently among the top researched
topic in obstetric care. While the performance of the current state-of-the-art
NIPT solutions achieve high sensitivity and specificity, they still struggle
with a considerable number of samples that cannot be concluded with certainty.
Such uninformative results are often subject to repeated blood sampling and
re-analysis, usually after two weeks, and this period may cause a stress to the
future mothers as well as increase the overall cost of the test. We propose a
supplementary method to traditional z-scores to reduce the number of such
uninformative calls. The method is based on a novel analysis of the length
profile of circulating cell free DNA which compares the change in such profiles
when random-based and length-based elimination of some fragments is performed.
The proposed method is not as accurate as the standard z-score; however, our
results suggest that combination of these two independent methods correctly
resolves a substantial portion of healthy samples with an uninformative result.
Additionally, we discuss how the proposed method can be used to identify
maternal aberrations, thus reducing the risk of false positive and false
negative calls.
  Keywords: Next-generation sequencing, Cell-free DNA, Uninformative result,
Method, Trisomy, Prenatal testing"
"DNA sequencing allows for the determination of the genetic code of an
organism, and therefore is an indispensable tool that has applications in
Medicine, Life Sciences, Evolutionary Biology, Food Sciences and Technology,
and Agriculture. In this paper, we present several novel methods of performing
classical-to-quantum data encoding inspired by various mathematical fields, and
we demonstrate these ideas within Bioinformatics. In particular, we introduce
algorithms that draw inspiration from diverse fields such as Electrical and
Electronic Engineering, Information Theory, Differential Geometry, and Neural
Network architectures. We provide a complete overview of the existing data
encoding schemes and show how to use them in Genomics. The algorithms provided
utilise lossless compression, wavelet-based encoding, and information entropy.
Moreover, we propose a contemporary method for testing encoded DNA sequences
using Quantum Boltzmann Machines. To evaluate the effectiveness of our
algorithms, we discuss a potential dataset that serves as a sandbox environment
for testing against real-world scenarios. Our research contributes to
developing classical-to-quantum data encoding methods in the science of
Bioinformatics by introducing innovative algorithms that utilise diverse fields
and advanced techniques. Our findings offer insights into the potential of
Quantum Computing in Bioinformatics and have implications for future research
in this area."
"Freehand three-dimensional ultrasound (3D-US) has gained considerable
interest in research, but even today suffers from its high inter-operator
variability in clinical practice. The high variability mainly arises from
tracking inaccuracies as well as the directionality of the ultrasound data,
being neglected in most of today's reconstruction methods. By providing a novel
paradigm for the acquisition and reconstruction of tracked freehand 3D
ultrasound, this work presents the concept of Computational Sonography (CS) to
model the directionality of ultrasound information. CS preserves the
directionality of the acquired data, and allows for its exploitation by
computational algorithms. In this regard, we propose a set of mathematical
models to represent 3D-US data, inspired by the physics of ultrasound imaging.
We compare different models of Computational Sonography to classical scalar
compounding for freehand acquisitions, providing both an improved preservation
of US directionality as well as improved image quality in 3D. The novel concept
is evaluated for a set of phantom datasets, as well as for in-vivo acquisitions
of muscoloskeletal and vascular applications."
"The volume of stroke lesion is the gold standard for predicting the clinical
outcome of stroke patients. However, the presence of stroke lesion may cause
neural disruptions to other brain regions, and these potentially damaged
regions may affect the clinical outcome of stroke patients. In this paper, we
introduce the tractographic feature to capture these potentially damaged
regions and predict the modified Rankin Scale (mRS), which is a widely used
outcome measure in stroke clinical trials. The tractographic feature is built
from the stroke lesion and average connectome information from a group of
normal subjects. The tractographic feature takes into account different
functional regions that may be affected by the stroke, thus complementing the
commonly used stroke volume features. The proposed tractographic feature is
tested on a public stroke benchmark Ischemic Stroke Lesion Segmentation 2017
and achieves higher accuracy than the stroke volume and the state-of-the-art
feature on predicting the mRS grades of stroke patients. In addition, the
tractographic feature also yields a lower average absolute error than the
commonly used stroke volume feature."
"Bangladesh, a developing country with a large and dense population, has
recently seen significant economic as well as technological developments. The
growth of technology has resulted in a dramatic increase in the number of
smartphone users in Bangladesh, and as such, mobile apps have become an
increasingly important part of peoples' life, even encompassing healthcare
services. However, the apps used in healthcare (telemedicine to be specific) in
Bangladesh are yet to be studied from the perspective of their features as per
the voices of the users as well as service providers. Therefore, in this study,
we focus on the features of the telemedicine apps used in Bangladesh. First, we
evaluated the present status of existing telemedicine apps in Bangladesh, as
well as their benefits and drawbacks in the context of HCI. We analyzed
publicly accessible reviews of several Bangladeshi telemedicine apps (N = 14)
to evaluate the user impressions. Additionally, to ascertain the public opinion
of these apps, we performed a survey in which the patients (N = 87)
participated willingly. Our analysis of the collected opinions reveals what
users experience, what they appreciate, and what they are concerned about when
they use telemedicine apps. Additionally, our study demonstrates what users
expect from telemedicine apps, independent of their past experience. Finally,
we explore how to address the issues we discovered and how telemedicine may be
used to effectively offer healthcare services throughout the country. To the
best of our knowledge, this study is the first to analyze the perception of the
people of Bangladesh towards telemedicine apps from the perspective of features
of the apps."
"This study is to test the feasibility of using trans-pars-planar illumination
for ultrawide field pediatric fundus photography. Fundus examination of the
peripheral retina is essential for clinical management of pediatric eye
diseases. However, current pediatric fundus cameras with traditional
trans-pupillary illumination provide a limited field of view (FOV), making it
difficult to access the peripheral retina adequately for a comprehensive
assessment of eye conditions. Here, we report the first demonstration of
trans-pars-planar illumination in ultra-wide field pediatric fundus
photography. For proof-of-concept validation, all off-the-shelf optical
components were selected to construct a lab prototype pediatric camera
(PedCam). By freeing the entire pupil for imaging purpose only, the
trans-pars-planar illumination enables a 200o FOV in a snapshot fundus image,
allowing easy visualization of both the central and peripheral retina up to the
ora serrata. A low-cost, easy-to-use ultra-wide field PedCam provides a unique
opportunity to foster affordable telemedicine in rural and underserved areas."
"Despite recent developments in CT planning that enabled automation in patient
positioning, time-consuming scout scans are still needed to compute dose
profile and ensure the patient is properly positioned. In this paper, we
present a novel method which eliminates the need for scout scans in CT lung
cancer screening by estimating patient scan range, isocenter, and Water
Equivalent Diameter (WED) from 3D camera images. We achieve this task by
training an implicit generative model on over 60,000 CT scans and introduce a
novel approach for updating the prediction using real-time scan data. We
demonstrate the effectiveness of our method on a testing set of 110 pairs of
depth data and CT scan, resulting in an average error of 5mm in estimating the
isocenter, 13mm in determining the scan range, 10mm and 16mm in estimating the
AP and lateral WED respectively. The relative WED error of our method is 4%,
which is well within the International Electrotechnical Commission (IEC)
acceptance criteria of 10%."
"Diabetes, especially T2DM, continues to be a significant health problem. One
of the major concerns associated with diabetes is the development of its
complications. Diabetic nephropathy, one of the chronic complication of
diabetes, adversely affects the kidneys, leading to kidney damage. Diagnosing
diabetic nephropathy involves considering various criteria, one of which is the
presence of a pathologically significant quantity of albumin in urine, known as
albuminuria. Thus, early prediction of albuminuria in diabetic patients holds
the potential for timely preventive measures. This study aimed to develop a
supervised learning model to predict the risk of developing albuminuria in T2DM
patients. The selected supervised learning algorithms included Na\""ive Bayes,
Support Vector Machine (SVM), decision tree, random forest, AdaBoost, XGBoost,
and Multi-Layer Perceptron (MLP). Our private dataset, comprising 184 entries
of diabetes complications risk factors, was used to train the algorithms. It
consisted of 10 attributes as features and 1 attribute as the target
(albuminuria). Upon conducting the experiments, the MLP demonstrated superior
performance compared to the other algorithms. It achieved accuracy and f1-score
values as high as 0.74 and 0.75, respectively, making it suitable for screening
purposes in predicting albuminuria in T2DM. Nonetheless, further studies are
warranted to enhance the model's performance."
"Multiple genome alignment remains a challenging problem. Effects of
recombination including rearrangement, segmental duplication, gain, and loss
can create a mosaic pattern of homology even among closely related organisms.
We describe a method to align two or more genomes that have undergone
large-scale recombination, particularly genomes that have undergone substantial
amounts of gene gain and loss (gene flux). The method utilizes a novel
alignment objective score, referred to as a sum-of-pairs breakpoint score. We
also apply a probabilistic alignment filtering method to remove erroneous
alignments of unrelated sequences, which are commonly observed in other genome
alignment methods. We describe new metrics for quantifying genome alignment
accuracy which measure the quality of rearrangement breakpoint predictions and
indel predictions. The progressive genome alignment algorithm demonstrates
markedly improved accuracy over previous approaches in situations where genomes
have undergone realistic amounts of genome rearrangement, gene gain, loss, and
duplication. We apply the progressive genome alignment algorithm to a set of 23
completely sequenced genomes from the genera Escherichia, Shigella, and
Salmonella. The 23 enterobacteria have an estimated 2.46Mbp of genomic content
conserved among all taxa and total unique content of 15.2Mbp. We document
substantial population-level variability among these organisms driven by
homologous recombination, gene gain, and gene loss. Free, open-source software
implementing the described genome alignment approach is available from
http://gel.ahabs.wisc.edu/mauve ."
"This work presents a new mathematical model to depict the effect of obesity
on cancerous tumor growth when chemotherapy as well as immunotherapy have been
administered. We consider an optimal control problem to destroy the tumor
population and minimize the drug dose over a finite time interval. The
constraint is a model including tumor cells, immune cells, fat cells,
chemotherapeutic and immunotherapeutic drug concentrations with Caputo time
fractional derivative. We investigate the existence and stability of the
equilibrium points namely, tumor free equilibrium and coexisting equilibrium,
analytically. We discretize the cancer-obesity model using L1-method.
Simulation results of the proposed model are presented to compare three
different treatment strategies: chemotherapy, immunotherapy and their
combination. In addition, we investigate the effect of the differentiation
order $\alpha$ and the value of the decay rate of the amount of
chemotherapeutic drug to the value of the cost functional. We find out the
optimal treatment schedule in case of chemotherapy and immunotherapy applied."
"Optical Coherence Tomography (OCT) is an emerging technique in the field of
biomedical imaging, with applications in ophthalmology, dermatology, coronary
imaging etc. OCT images usually suffer from a granular pattern, called speckle
noise, which restricts the process of interpretation. Therefore the need for
speckle noise reduction techniques is of high importance. To the best of our
knowledge, use of Independent Component Analysis (ICA) techniques has never
been explored for speckle reduction of OCT images. Here, a comparative study of
several ICA techniques (InfoMax, JADE, FastICA and SOBI) is provided for noise
reduction of retinal OCT images. Having multiple B-scans of the same location,
the eye movements are compensated using a rigid registration technique. Then,
different ICA techniques are applied to the aggregated set of B-scans for
extracting the noise-free image. Signal-to-Noise-Ratio (SNR),
Contrast-to-Noise-Ratio (CNR) and Equivalent-Number-of-Looks (ENL), as well as
analysis on the computational complexity of the methods, are considered as
metrics for comparison. The results show that use of ICA can be beneficial,
especially in case of having fewer number of B-scans."
"The time delayed cytotoxic T-lymphocyte response on the tumor growth has been
developed on the basis of discrete approximation (2-dimensional map). The
growth kinetic has been described by logistic law with growth rate being the
bifurcation parameter. Increase in the growth rate results in instability of
the tumor state and causes period-doubling bifurcations in the immune+tumor
system. For larger values of tumor growth rate a strange attractor has been
observed. The model proposed is able to describe the metastable-state
production when time series data of the immune state and the number of tumor
cells are irregular and unpredictable. This metastatic disease may be caused
not by exterior (medical) factors, but interior density dependent ones."
"Is it possible to develop an ""AI Pathologist"" to pass the board-certified
examination of the American Board of Pathology (ABP)? To build such a system,
three challenges need to be addressed. First, we need to create a visual
question answering (VQA) dataset where the AI agent is presented with a
pathology image together with a question and is asked to give the correct
answer. Due to privacy concerns, pathology images are usually not publicly
available. Besides, only well-trained pathologists can understand pathology
images, but they barely have time to help create datasets for AI research. The
second challenge is: since it is difficult to hire highly experienced
pathologists to create pathology visual questions and answers, the resulting
pathology VQA dataset may contain errors. Training pathology VQA models using
these noisy or even erroneous data will lead to problematic models that cannot
generalize well on unseen images. The third challenge is: the medical concepts
and knowledge covered in pathology question-answer (QA) pairs are very diverse
while the number of QA pairs available for modeling training is limited. How to
learn effective representations of diverse medical concepts based on limited
data is technically demanding. In this paper, we aim to address these three
challenges. To our best knowledge, our work represents the first one addressing
the pathology VQA problem. To deal with the issue that a publicly available
pathology VQA dataset is lacking, we create PathVQA dataset. To address the
second challenge, we propose a learning-by-ignoring approach. To address the
third challenge, we propose to use cross-modal self-supervised learning. We
perform experiments on our created PathVQA dataset and the results demonstrate
the effectiveness of our proposed learning-by-ignoring method and cross-modal
self-supervised learning methods."
"Many people are affected by diabetes around the world. This disease may have
type 1 and 2. Diabetes brings with it several complications including diabetic
retinopathy, which is a disease that if not treated correctly can lead to
irreversible damage in the patient's vision. The earlier it is detected, the
better the chances that the patient will not lose vision. Methods of automating
manual procedures are currently in evidence and the diagnostic process for
retinopathy is manual with the physician analyzing the patient's retina on the
monitor. The practice of image recognition can aid this detection by
recognizing Diabetic Retinopathy patterns and comparing it with the patient's
retina in diagnosis. This method can also assist in the act of telemedicine, in
which people without access to the exam can benefit from the diagnosis provided
by the application. The application development took place through
convolutional neural networks, which do digital image processing analyzing each
image pixel. The use of VGG-16 as a pre-trained model to the application basis
was very useful and the final model accuracy was 82%."
"Antibodies, disruptive potent therapeutic agents against pharmacological
targets, face a barrier crossing immune-system and cellular-membranes. To
overcome these, various strategies have been explored including shuttling via
liposomes or bio-camouflaged nanoparticles. Here, we demonstrate the
feasibility to load antibodies into exosome-mimetic nanovesicles derived from
human red-blood-cell-membranes. The goat-anti-chicken antibodies are loaded
into erythrocyte-membrane derived nanovesicles and their loading yields are
characterized and compared with smaller dUTP-cargo. Applying dual-color
coincident fluorescence burst methodology, the loading yield of nanocarriers is
profiled at single-vesicle level overcoming their size-heterogeneity and
achieving a maximum of 38-41% antibody-loading yield at peak radius of 52 nm.
The average of 14 % yield and more than two antibodies per vesicle is
estimated, comparable to those of dUTP-loaded nanovesicles after additional
purification through exosome-spin-column. These results suggest a promising
route for enhancing biodistribution and intracellular accessibility for
therapeutic antibodies using novel, biocompatible, and low-immunogenicity
nanocarriers, suitable for large-scale pharmacological applications."
"The aim of this paper is to study the (clinical) time-series data of three
diseases with complex dynamics: Parkinson's disease, Huntington's disease and
Amyotrophic Lateral Sclerosis. For this purpose, first all of the time series
data are embedded in a vector space of suitable dimension and then the
correlation dimension of the above mentioned diseases is estimated. The results
are also compared with healthy control subjects. At the next step, existence of
chaos in these diseases is investigated by means of the so-called 0-1 test. The
simulations show that none of the above mentioned diseases are chaotic."
"The ability to quantitatively assess the health of an ecosystem is often of
great interest to those tasked with monitoring and conserving ecosystems. For
decades, research in this area has relied upon multimetric indices of various
forms. Although indices may be numbers, many are constructed based on
procedures that are highly qualitative in nature, thus limiting the
quantitative rigour of the practical interpretations made from these indices.
The statistical modelling approach to construct the latent health factor index
(LHFI) was recently developed to express ecological data, collected to
construct conventional multimetric health indices, in a rigorous quantitative
model that integrates qualitative features of ecosystem health and preconceived
ecological relationships among such features. This hierarchical modelling
approach allows (a) statistical inference of health for observed sites and (b)
prediction of health for unobserved sites, all accompanied by formal
uncertainty statements. Thus far, the LHFI approach has been demonstrated and
validated on freshwater ecosystems. The goal of this paper is to adapt this
approach to modelling estuarine ecosystem health, particularly that of the
previously unassessed system in Richibucto in New Brunswick, Canada. Field data
correspond to biotic health metrics that constitute the AZTI marine biotic
index (AMBI) and abiotic predictors preconceived to influence biota. We also
briefly discuss related LHFI research involving additional metrics that form
the infaunal trophic index (ITI). Our paper is the first to construct a
scientifically sensible model to rigorously identify the collective explanatory
capacity of salinity, distance downstream, channel depth, and silt-clay content
--- all regarded a priori as qualitatively important abiotic drivers ---
towards site health in the Richibucto ecosystem."
"Propensity score methods are common for estimating a binary treatment effect
when treatment assignment is not randomized. When exposure is measured on an
ordinal scale (i.e., low - medium - high), however, propensity score inference
requires extensions which have received limited attention. Estimands of
possible interest with an ordinal exposure are the average treatment effects
between each pair of exposure levels. Using these estimands, it is possible to
determine an optimal exposure level. Traditional methods, including
dichotomization of the exposure or a series of binary propensity score
comparisons across exposure pairs, are generally inadequate for identification
of optimal levels.We combine subclassification with regression adjustment to
estimate transitive, unbiased average causal effects across an ordered
exposure, and apply our method on the 2005-06 National Health and Nutrition
Examination Survey to estimate the effects of nutritional label use on body
mass index."
"Feature selection techniques are essential for high-dimensional data
analysis. In the last two decades, their popularity has been fuelled by the
increasing availability of high-throughput biomolecular data where
high-dimensionality is a common data property. Recent advances in
biotechnologies enable global profiling of various molecular and cellular
features at single-cell resolution, resulting in large-scale datasets with
increased complexity. These technological developments have led to a resurgence
in feature selection research and application in the single-cell field. Here,
we revisit feature selection techniques and summarise recent developments. We
review their versatile application to a range of single-cell data types
including those generated from traditional cytometry and imaging technologies
and the latest array of single-cell omics technologies. We highlight some of
the challenges and future directions on which feature selection could have a
significant impact. Finally, we consider the scalability and make general
recommendations on the utility of each type of feature selection method. We
hope this review serves as a reference point to stimulate future research and
application of feature selection in the single-cell era."
"Pain is a significant public health problem as the number of individuals with
a history of pain globally keeps growing. In response, many synergistic
research areas have been coming together to address pain-related issues. This
work conducts a review and analysis of a vast body of pain-related literature
using the keyword co-occurrence network (KCN) methodology. In this method, a
set of KCNs is constructed by treating keywords as nodes and the co-occurrence
of keywords as links between the nodes. Since keywords represent the knowledge
components of research articles, analysis of KCNs will reveal the knowledge
structure and research trends in the literature. This study extracted and
analyzed keywords from 264,560 pain-related research articles indexed in IEEE,
PubMed, Engineering Village, and Web of Science published between 2002 and
2021. We observed rapid growth in pain literature in the last two decades: the
number of articles has grown nearly threefold, and the number of keywords has
grown by a factor of 7. We identified emerging and declining research trends in
sensors/methods, biomedical, and treatment tracks. We also extracted the most
frequently co-occurring keyword pairs and clusters to help researchers
recognize the synergies among different pain-related topics."
"Using machine learning, especially deep learning, to facilitate biological
research is a fascinating research direction. However, in addition to the
standard classification or regression problems, in bioinformatics, we often
need to predict more complex structured targets, such as 2D images and 3D
molecular structures. The above complex prediction tasks are referred to as
structured prediction. Structured prediction is more complicated than the
traditional classification but has much broader applications, considering that
most of the original bioinformatics problems have complex output objects. Due
to the properties of those structured prediction problems, such as having
problem-specific constraints and dependency within the labeling space, the
straightforward application of existing deep learning models can lead to
unsatisfactory results. Here, we argue that the following ideas can help
resolve structured prediction problems in bioinformatics. Firstly, we can
combine deep learning with other classic algorithms, such as probabilistic
graphical models, which model the problem structure explicitly. Secondly, we
can design the problem-specific deep learning architectures or methods by
considering the structured labeling space and problem constraints, either
explicitly or implicitly. We demonstrate our ideas with six projects from four
bioinformatics subfields, including sequencing analysis, structure prediction,
function annotation, and network analysis. The structured outputs cover 1D
signals, 2D images, 3D structures, hierarchical labeling, and heterogeneous
networks. With the help of the above ideas, all of our methods can achieve SOTA
performance on the corresponding problems. The success of these projects
motivates us to extend our work towards other more challenging but important
problems, such as health-care problems, which can directly benefit people's
health and wellness."
"'Trojan horses', 'logic bombs', 'armoured viruses' and 'cryptovirology' are
terms recalling war gears. In fact, concepts of attack and defence drive the
world of computer virology, which looks like a war universe in an information
society. This war has several shapes, from invasions of a network by worms, to
military and industrial espionage ..."
"In this work, two mathematical models for malaria under resistance are
presented. More precisely, the first model shows the interaction between humans
and mosquitoes inside a patch under infection of malaria when the human
population is resistant to antimalarial drug and mosquitoes population is
resistant to insecticides. For the second model, human-mosquitoes population
movements in two patches is analyzed under the same malaria transmission
dynamic established in one patch. For a single patch, existence and stability
conditions for the equilibrium solutions in terms of the local basic
reproductive number are developed. These results reveal the existence of a
forward bifurcation and the global stability of disease-free equilibrium. In
the case of two patches, a theoretical and numerical framework on sensitivity
analysis of parameters is presented. After that, the use of antimalarial drugs
and insecticides are incorporated as control strategies and an optimal control
problem is formulated. Numerical experiments are carried out in both models to
show the feasibility of our theoretical results."
"The rotary motor of bacteria is a natural nano-technological marvel that
enables cell locomotion by powering the rotation of semi-rigid helical
flagellar filaments in fluid environments. It is well known that the motor
operates essentially at constant torque in counter-clockwise direction but past
work have reported a large range of values of this torque. Focusing on
Escherichia coli cells that are swimming and cells that are stuck on a glass
surface for which all geometrical and environmental parameters are known
(Darnton et al., J. Bacteriology, 2007, 189, 1756-1764), we use two validated
numerical methods to compute the value of the motor torque consistent with
experiments. Specifically, we use (and compare) a numerical method based on the
boundary integral representation of Stokes flow and also develop a hybrid
method combining boundary element and slender body theory to model the cell
body and flagellar filament, respectively. Using measured rotation speed of the
motor, our computations predict a value of the motor torque in the range 440
pNnm to 829 pNnm, depending critically on the distance between the flagellar
filaments and the nearby surface."
"This paper explores the frontiers of large language models (LLMs) in
psychology applications. Psychology has undergone several theoretical changes,
and the current use of Artificial Intelligence (AI) and Machine Learning,
particularly LLMs, promises to open up new research directions. We provide a
detailed exploration of how LLMs like ChatGPT are transforming psychological
research. It discusses the impact of LLMs across various branches of
psychology, including cognitive and behavioral, clinical and counseling,
educational and developmental, and social and cultural psychology, highlighting
their potential to simulate aspects of human cognition and behavior. The paper
delves into the capabilities of these models to emulate human-like text
generation, offering innovative tools for literature review, hypothesis
generation, experimental design, experimental subjects, data analysis, academic
writing, and peer review in psychology. While LLMs are essential in advancing
research methodologies in psychology, the paper also cautions about their
technical and ethical challenges. There are issues like data privacy, the
ethical implications of using LLMs in psychological research, and the need for
a deeper understanding of these models' limitations. Researchers should
responsibly use LLMs in psychological studies, adhering to ethical standards
and considering the potential consequences of deploying these technologies in
sensitive areas. Overall, the article provides a comprehensive overview of the
current state of LLMs in psychology, exploring potential benefits and
challenges. It serves as a call to action for researchers to leverage LLMs'
advantages responsibly while addressing associated risks."
"Coronavirus Disease 2019 (COVID-19) is a rapidly emerging respiratory disease
caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Due
to the rapid human-to-human transmission of SARS-CoV-2, many healthcare systems
are at risk of exceeding their healthcare capacities, in particular in terms of
SARS-CoV-2 tests, hospital and intensive care unit (ICU) beds and mechanical
ventilators. Predictive algorithms could potentially ease the strain on
healthcare systems by identifying those who are most likely to receive a
positive SARS-CoV-2 test, be hospitalised or admitted to the ICU. Here, we
study clinical predictive models that estimate, using machine learning and
based on routinely collected clinical data, which patients are likely to
receive a positive SARS-CoV-2 test, require hospitalisation or intensive care.
To evaluate the predictive performance of our models, we perform a
retrospective evaluation on clinical and blood analysis data from a cohort of
5644 patients. Our experimental results indicate that our predictive models
identify (i) patients that test positive for SARS-CoV-2 a priori at a
sensitivity of 75% (95% CI: 67%, 81%) and a specificity of 49% (95% CI: 46%,
51%), (ii) SARS-CoV-2 positive patients that require hospitalisation with 0.92
AUC (95% CI: 0.81, 0.98), and (iii) SARS-CoV-2 positive patients that require
critical care with 0.98 AUC (95% CI: 0.95, 1.00). In addition, we determine
which clinical features are predictive to what degree for each of the
aforementioned clinical tasks. Our results indicate that predictive models
trained on routinely collected clinical data could be used to predict clinical
pathways for COVID-19, and therefore help inform care and prioritise resources."
"It is demonstrated that the renormalization group (RG) flows of depinning
transitions do not depend on whether the driving force or the system velocity
is kept constant. This allows for a comparison between RG results and
corresponding self-organized critical models. However, close to the critical
point, scaling functions cross over to forms that can have singular behavior
not seen in equilibrium thermal phase transitions. These can be different for
the constant force and constant velocity driving modes, leading to different
apparent critical exponents. This is illustrated by comparing extremal dynamics
for interface depinning with RG results, deriving the change in apparent
exponents. Thus care has to be exercised in such comparisons."
"Conversational AI tools that can generate and discuss clinically correct
radiology reports for a given medical image have the potential to transform
radiology. Such a human-in-the-loop radiology assistant could facilitate a
collaborative diagnostic process, thus saving time and improving the quality of
reports. Towards this goal, we introduce RaDialog, the first thoroughly
evaluated and publicly available large vision-language model for radiology
report generation and interactive dialog. RaDialog effectively integrates
visual image features and structured pathology findings with a large language
model (LLM) while simultaneously adapting it to a specialized domain using
parameter-efficient fine-tuning. To keep the conversational abilities of the
underlying LLM, we propose a comprehensive, semi-automatically labeled,
image-grounded instruct dataset for chest X-ray radiology tasks. By training
with this dataset, our method achieves state-of-the-art clinical correctness in
report generation and shows impressive abilities in interactive tasks such as
correcting reports and answering questions, serving as a foundational step
toward clinical dialog systems. Our code is available on github:
https://github.com/ChantalMP/RaDialog."
"Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systems
can obtain functional and anatomical scans. PET suffers from a low
signal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRI
is time-consuming. The study aims to accelerate MRI and enhance PET image
quality. Conventional approaches involve the separate reconstruction of each
modality within PET-MRI systems. However, there exists complementary
information among multi-modal images. The complementary information can
contribute to image reconstruction. In this study, we propose a novel PET-MRI
joint reconstruction model employing a mutual consistency-driven diffusion
mode, namely MC-Diffusion. MC-Diffusion learns the joint probability
distribution of PET and MRI for utilizing complementary information. We
conducted a series of contrast experiments about LPLS, Joint ISAT-net and
MC-Diffusion by the ADNI dataset. The results underscore the qualitative and
quantitative improvements achieved by MC-Diffusion, surpassing the
state-of-the-art method."
"Health datasets have immense potential to drive research advancements and
improve healthcare outcomes. However, realizing this potential requires careful
consideration of governance and ownership frameworks. This article explores the
importance of nurturing governance and ownership models that facilitate
responsible and ethical use of health datasets for research purposes. We
highlight the importance of adopting governance and ownership models that
enable responsible and ethical utilization of health datasets and clinical data
registries for research purposes. The article addresses the important local and
international regulations related to the utilization of health data/medical
records in research, and emphasizes the urgent need for developing clear
institutional and national guidelines on data access, sharing, and utilization,
ensuring transparency, privacy, and data protection. By establishing robust
governance structures and fostering ownership among stakeholders,
collaboration, innovation, and equitable access to health data can be promoted,
ultimately unlocking its full power for transformative research and improving
global health outcomes."
"The Severe Acute Respiratory Syndrome Corona Virus 2 (SARS-CoV-2), or
Covid-19, burst into a pandemic in the beginning of 2020. An unprecedented
worldwide effort involving academic institutions, regulatory agencies and
industry is facing the challenges imposed by the rapidly spreading disease.
Emergency use authorization for vaccines were granted in the beginning of
December 2020 in Europe and nine days later in the United States. The urge for
vaccination started a race, forcing governs and health care agencies to take
decisions on the fly regarding the vaccination strategy and logistics. So far,
the vaccination strategies and non-pharmaceutical interventions, such as social
distancing and the use of face masks, are the only efficient actions to stop
the pandemic. In this context, it is of fundamental importance to understand
the dynamical behavior of the Covid-19 spread along with possible vaccination
strategies. In this work a Susceptible - Infected - Removed - Sick with
vaccination (SIRSi-Vaccine) model is proposed. In addtion, the SIRSi-Vaccine
model also accounts for unreported, or asymptomatic, cases and the possibility
of temporary immunity, either after infection or vaccination. Disease free and
endemic equilibrium points existence conditions are determined in the (! ? ?)
vaccine-effort and social distancing parameter space. The model is adjusted to
the data from S\~ao Paulo, Santos and Campinas, three major cities in the State
of S\~ao Paulo, Brazil."
"Large-scale manufacturing of induced pluripotent stem cells (iPSCs) is
essential for cell therapies and regenerative medicines. Yet, iPSCs form large
cell aggregates in suspension bioreactors, resulting in insufficient nutrient
supply and extra metabolic waste build-up for the cells located at the core.
Since subtle changes in micro-environment can lead to a heterogeneous cell
population, a novel Biological System-of-Systems (Bio-SoS) framework is
proposed to model cell-to-cell interactions, spatial and metabolic
heterogeneity, and cell response to micro-environmental variation. Building on
stochastic metabolic reaction network, aggregation kinetics, and
reaction-diffusion mechanisms, the Bio-SoS model characterizes causal
interdependencies at individual cell, aggregate, and cell population levels. It
has a modular design that enables data integration and improves predictions for
different monolayer and aggregate culture processes. In addition, a variance
decomposition analysis is derived to quantify the impact of factors (i.e.,
aggregate size) on cell product health and quality heterogeneity."
"Objective: In this paper, we develop a personalized real-time risk scoring
algorithm that provides timely and granular assessments for the clinical acuity
of ward patients based on their (temporal) lab tests and vital signs; the
proposed risk scoring system ensures timely intensive care unit (ICU)
admissions for clinically deteriorating patients. Methods: The risk scoring
system learns a set of latent patient subtypes from the offline electronic
health record data, and trains a mixture of Gaussian Process (GP) experts,
where each expert models the physiological data streams associated with a
specific patient subtype. Transfer learning techniques are used to learn the
relationship between a patient's latent subtype and her static admission
information (e.g. age, gender, transfer status, ICD-9 codes, etc). Results:
Experiments conducted on data from a heterogeneous cohort of 6,321 patients
admitted to Ronald Reagan UCLA medical center show that our risk score
significantly and consistently outperforms the currently deployed risk scores,
such as the Rothman index, MEWS, APACHE and SOFA scores, in terms of
timeliness, true positive rate (TPR), and positive predictive value (PPV).
Conclusion: Our results reflect the importance of adopting the concepts of
personalized medicine in critical care settings; significant accuracy and
timeliness gains can be achieved by accounting for the patients' heterogeneity.
Significance: The proposed risk scoring methodology can confer huge clinical
and social benefits on more than 200,000 critically ill inpatient who exhibit
cardiac arrests in the US every year."
"Designing a new clinical trial entails many decisions, such as defining a
cohort and setting the study objectives to name a few, and therefore can
benefit from recommendations based on exhaustive mining of past clinical trial
records. Here, we propose a novel recommendation methodology, based on neural
embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We
addressed several important research questions in this context, including
designing a knowledge graph (KG) for clinical trial data, effectiveness of
various KG embedding (KGE) methods for it, a novel inductive inference using
KGE, and its use in generating recommendations for clinical trial design. We
used publicly available data from clinicaltrials.gov for the study. Results
show that our recommendations approach achieves relevance scores of 70%-83%,
measured as the text similarity to actual clinical trial elements, and the most
relevant recommendation can be found near the top of list. Our study also
suggests potential improvement in training KGE using node semantics."
"Automated emotion classification could aid those who struggle to recognize
emotion, including children with developmental behavioral conditions such as
autism. However, most computer vision emotion models are trained on adult
affect and therefore underperform on child faces. In this study, we designed a
strategy to gamify the collection and the labeling of child affect data in an
effort to boost the performance of automatic child emotion detection to a level
closer to what will be needed for translational digital healthcare. We
leveraged our therapeutic smartphone game, GuessWhat, which was designed in
large part for children with developmental and behavioral conditions, to gamify
the secure collection of video data of children expressing a variety of
emotions prompted by the game. Through a secure web interface gamifying the
human labeling effort, we gathered and labeled 2,155 videos, 39,968 emotion
frames, and 106,001 labels on all images. With this drastically expanded
pediatric emotion centric database (>30x larger than existing public pediatric
affect datasets), we trained a pediatric emotion classification convolutional
neural network (CNN) classifier of happy, sad, surprised, fearful, angry,
disgust, and neutral expressions in children. The classifier achieved 66.9%
balanced accuracy and 67.4% F1-score on the entirety of CAFE as well as 79.1%
balanced accuracy and 78.0% F1-score on CAFE Subset A, a subset containing at
least 60% human agreement on emotions labels. This performance is at least 10%
higher than all previously published classifiers, the best of which reached
56.% balanced accuracy even when combining ""anger"" and ""disgust"" into a single
class. This work validates that mobile games designed for pediatric therapies
can generate high volumes of domain-relevant datasets to train state of the art
classifiers to perform tasks highly relevant to precision health efforts."
"The aim of this manuscript is to explore semiparametric methods for inferring
subgroup-specific relative vaccine efficacy in a partially vaccinated
population against multiple strains of a virus. We consider methods for
observational case-only studies with informative missingness in viral strain
type due to vaccination status, pre-vaccination variables, and also
post-vaccination factors such as viral load. We establish general causal
conditions under which the relative conditional vaccine efficacy between
strains can be identified nonparametrically from the observed data-generating
distribution. Assuming that the relative strain-specific conditional vaccine
efficacy has a known parametric form, we propose semiparametric asymptotically
linear estimators of the parameters based on targeted (debiased) machine
learning estimators for partially linear logistic regression models. Finally,
we apply our methods to estimate the relative strain-specific conditional
vaccine efficacy in the ENSEMBLE COVID-19 vaccine trial."
"We apply computer vision pose estimation techniques developed expressly for
the data-scarce infant domain to the study of torticollis, a common condition
in infants for which early identification and treatment is critical.
Specifically, we use a combination of facial landmark and body joint estimation
techniques designed for infants to estimate a range of geometric measures
pertaining to face and upper body symmetry, drawn from an array of sources in
the physical therapy and ophthalmology research literature in torticollis. We
gauge performance with a range of metrics and show that the estimates of most
these geometric measures are successful, yielding strong to very strong
Spearman's $\rho$ correlation with ground truth values. Furthermore, we show
that these estimates, derived from pose estimation neural networks designed for
the infant domain, cleanly outperform estimates derived from more widely known
networks designed for the adult domain"
"The novel research area of computational empathy is in its infancy and moving
towards developing methods and standards. One major problem is the lack of
agreement on the evaluation of empathy in artificial interactive systems. Even
though the existence of well-established methods from psychology, psychiatry
and neuroscience, the translation between these methods and computational
empathy is not straightforward. It requires a collective effort to develop
metrics that are more suitable for interactive artificial agents. This paper is
aimed as an attempt to initiate the dialogue on this important problem. We
examine the evaluation methods for empathy in humans and provide suggestions
for the development of better metrics to evaluate empathy in artificial agents.
We acknowledge the difficulty of arriving at a single solution in a vast
variety of interactive systems and propose a set of systematic approaches that
can be used with a variety of applications and systems."
"In total hip arthroplasty, analysis of postoperative medical images is
important to evaluate surgical outcome. Since Computed Tomography (CT) is most
prevalent modality in orthopedic surgery, we aimed at the analysis of CT image.
In this work, we focus on the metal artifact in postoperative CT caused by the
metallic implant, which reduces the accuracy of segmentation especially in the
vicinity of the implant. Our goal was to develop an automated segmentation
method of the bones and muscles in the postoperative CT images. We propose a
method that combines Normalized Metal Artifact Reduction (NMAR), which is one
of the state-of-the-art metal artifact reduction methods, and a Convolutional
Neural Network-based segmentation using two U-net architectures. The first
U-net refines the result of NMAR and the muscle segmentation is performed by
the second U-net. We conducted experiments using simulated images of 20
patients and real images of three patients to evaluate the segmentation
accuracy of 19 muscles. In simulation study, the proposed method showed
statistically significant improvement (p<0.05) in the average symmetric surface
distance (ASD) metric for 14 muscles out of 19 muscles and the average ASD of
all muscles from 1.17 +/- 0.543 mm (mean +/- std over all patients) to 1.10 +/-
0.509 mm over our previous method. The real image study using the manual trace
of gluteus maximus and medius muscles showed ASD of 1.32 +/- 0.25 mm. Our
future work includes training of a network in an end-to-end manner for both the
metal artifact reduction and muscle segmentation."
"Visualization is a useful technology in health science, and especially for
community network analysis. Because visualization applications in healthcare
are typically risk-averse, health psychologists can play a significant role in
ensuring appropriate and effective uses of visualization techniques in
healthcare. In this paper, we examine the role of health psychologists in the
triangle of ""health science"", ""visualization technology"", and ""visualization
psychology"". We conclude that health psychologists can use visualization to aid
data intelligence workflows in healthcare and health psychology, while
researching into visualization psychology to aid the improvement and
optimization of data visualization processes."
"The assumption that vector mortality remains constant with age is used widely
to assess malaria transmission risk and predict the public health consequences
of vector control strategies. However, laboratory studies commonly demonstrate
clear evidence of senescence, or a decrease in physiological function and
increase in vector mortality rate with age. We developed methods to integrate
available field data to understand mortality in wild Anopheles gambiae, the
most import vector of malaria in sub-Saharan Africa. We found evidence for an
increase in rates of mortality with age, a component of senescence. As
expected, we also found that overall mortality is far greater in wild cohorts
than commonly observed under protected laboratory conditions. The magnitude of
senescence increases with An. gambiae lifespan, implying that wild mosquitoes
die long before cohorts can exhibit strong senescence. We reviewed available
published mortality studies of Anopheles spp. to confirm this fundamental
prediction of aging in wild populations. Senescence becomes most apparent in
long-living mosquito cohorts, and cohorts with low extrinsic mortality, such as
those raised under protected laboratory conditions, suffer a relatively high
proportion of senescent deaths. Imprecision in estimates of vector mortality
and changes in mortality with age will severely bias models of vector borne
disease transmission risk, such as malaria, and the sensitivity of transmission
to bias increases as the extrinsic incubation period of the parasite decreases.
While we focus here on malaria, we caution that future models for
anti-vectorial interventions must therefore incorporate both realistic
mortality rates and age-dependent changes in vector mortality."
"Robot-assisted minimally invasive surgery has shown to improve patient
outcomes, as well as reduce complications and recovery time for several
clinical applications. While increasingly configurable robotic arms can
maximize reach and avoid collisions in cluttered environments, positioning them
appropriately during surgery is complicated because safety regulations prevent
automatic driving. We propose a head-mounted display (HMD) based augmented
reality (AR) system designed to guide optimal surgical arm set up. The staff
equipped with HMD aligns the robot with its planned virtual counterpart. In
this user-centric setting, the main challenge is the perspective ambiguities
hindering such collaborative robotic solution. To overcome this challenge, we
introduce a novel registration concept for intuitive alignment of AR content to
its physical counterpart by providing a multi-view AR experience via
reflective-AR displays that simultaneously show the augmentations from multiple
viewpoints. Using this system, users can visualize different perspectives while
actively adjusting the pose to determine the registration transformation that
most closely superimposes the virtual onto the real. The experimental results
demonstrate improvement in the interactive alignment of a virtual and real
robot when using a reflective-AR display. We also present measurements from
configuring a robotic manipulator in a simulated trocar placement surgery using
the AR guidance methodology."
"Recovery after stroke is often incomplete, but rehabilitation training may
potentiate recovery by engaging endogenous neuroplasticity. In preclinical
models of stroke, high doses of rehabilitation training are required to restore
functional movement to the affected limbs of animals. In humans, however, the
necessary dose of training to potentiate recovery is not known. This ignorance
stems from the lack of objective, pragmatic approaches for measuring training
doses in rehabilitation activities. Here, to develop a measurement approach, we
took the critical first step of automatically identifying functional
primitives, the basic building block of activities. Forty-eight individuals
with chronic stroke performed a variety of rehabilitation activities while
wearing inertial measurement units (IMUs) to capture upper body motion.
Primitives were identified by human labelers, who labeled and segmented the
associated IMU data. We performed automatic classification of these primitives
using machine learning. We designed a convolutional neural network model that
outperformed existing methods. The model includes an initial module to compute
separate embeddings of different physical quantities in the sensor data. In
addition, it replaces batch normalization (which performs normalization based
on statistics computed from the training data) with instance normalization
(which uses statistics computed from the test data). This increases robustness
to possible distributional shifts when applying the method to new patients.
With this approach, we attained an average classification accuracy of 70%.
Thus, using a combination of IMU-based motion capture and deep learning, we
were able to identify primitives automatically. This approach builds towards
objectively-measured rehabilitation training, enabling the identification and
counting of functional primitives that accrues to a training dose."
"The goal of immunotherapy is to enhance the ability of the immune system to
kill cancer cells. Immunotherapy is more effective and, in general, the
prognosis is better, when more immune cells infiltrate the tumor. We explore
the question of whether the spatial distribution rather than just the density
of immune cells in the tumor is important in forecasting whether cancer recurs.
After reviewing previous work on this issue, we introduce a novel application
of maximum entropy to quantify the spatial distribution of discrete point-like
objects. We apply our approach to B and T cells in images of tumor tissue taken
from triple negative breast cancer (TBNC) patients. We find that there is a
distinct difference in the spatial distribution of immune cells between good
clinical outcome (no recurrence of cancer within at least 5 years of diagnosis)
and poor clinical outcome (recurrence within 3 years of diagnosis). Our results
highlight the importance of spatial distribution of immune cells within tumors
with regard to clinical outcome, and raise new questions on their role in
cancer recurrence."
"Immunotherapies use components of the patient immune system to selectively
target cancer cells. The use of CAR T cells to treat B-cell malignancies
--leukaemias and lymphomas-- is one of the most successful examples, with many
patients experiencing long-lasting complete responses to this therapy. This
treatment works by extracting the patient's T cells and adding them the CAR
group, which enables them to recognize and target cells carrying the antigen
CD19+, that is expressed in these haematological tumors.
  Here we put forward a mathematical model describing the time response of
leukaemias to the injection of CAR T-cells. The model accounts for mature and
progenitor B-cells, tumor cells, CAR T cells and side effects by incorporating
the main biological processes involved. The model explains the early
post-injection dynamics of the different compartments and the fact that the
number of CAR T cells injected does not critically affect the treatment
outcome. An explicit formula is found that provides the maximum CAR T cell
expansion in-vivo and the severity of side effects. Our mathematical model
captures other known features of the response to this immunotherapy. It also
predicts that CD19+ tumor relapses could be the result of the competition
between tumor and CAR T cells analogous to predator-prey dynamics. We discuss
this fact on the light of available evidences and the possibility of
controlling relapses by early re-challenging of the tumor with stored CAR T
cells."
"There has been considerable efforts to understand the underlying complex
dynamics in physiological time series. Methods originated from statistical
physics revealed a non-Gaussian statistics and long range correlations in those
signals. This suggests that the regulatory system operates out of equilibrium.
Herein the complex fluctuations in blood pressure time series were successful
described by physiological motivated Langevin equation under a sigmoid
restoring force with multiplicative noise."
"There is limited evidence of health interventions impact on cognitive
function and educational outcomes. We build on two prior systematic reviews to
conduct a meta-analysis, exploring the effects of one of the most consequential
health interventions, malaria chemoprevention, on education outcomes. We pool
data from nine study treatment groups (N=4,075) and outcomes across four
countries. We find evidence of a positive effect (Cohen's d = 0.12, 95% CI
[0.08, 0.16]) on student cognitive function, achieved at low cost. These
results show that malaria chemoprevention can be highly cost effective in
improving some cognitive skills, such as sustained attention. Moreover, we
conduct simulations using a new common metric (learning-adjusted years of
development) to compare cost-effectiveness across diverse interventions. While
we might expect that traditional education interventions provide an immediate
learning gain, health interventions such as malaria prevention can have
surprisingly cost-effective education benefits, enabling children to achieve
their full human capital potential."
"In obstetric ultrasound (US) scanning, the learner's ability to mentally
build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US
image represents a significant challenge in skill acquisition. We aim to build
a US plane localization system for 3D visualization, training, and guidance
without integrating additional sensors. This work builds on top of our previous
work, which predicts the six-dimensional (6D) pose of arbitrarily oriented US
planes slicing the fetal brain with respect to a normalized reference frame
using a convolutional neural network (CNN) regression network. Here, we analyze
in detail the assumptions of the normalized fetal brain reference frame and
quantify its accuracy with respect to the acquisition of transventricular (TV)
standard plane (SP) for fetal biometry. We investigate the impact of
registration quality in the training and testing data and its subsequent effect
on trained models. Finally, we introduce data augmentations and larger training
sets that improve the results of our previous work, achieving median errors of
2.97 mm and 6.63 degrees for translation and rotation, respectively."
"Since the appearance of Covid-19 in late 2019, Covid-19 has become an active
research topic for the artificial intelligence (AI) community. One of the most
interesting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging
is the most informative tool about this disease. This work is part of the 2nd
COV19D competition, where two challenges are set: Covid-19 Detection and
Covid-19 Severity Detection from the CT-scans. For Covid-19 detection from
CT-scans, we proposed an ensemble of 2D Convolution blocks with Densenet-161
models. Here, each 2D convolutional block with Densenet-161 architecture is
trained separately and in testing phase, the ensemble model is based on the
average of their probabilities. On the other hand, we proposed an ensemble of
Convolutional Layers with Inception models for Covid-19 severity detection. In
addition to the Convolutional Layers, three Inception variants were used,
namely Inception-v3, Inception-v4 and Inception-Resnet. Our proposed approaches
outperformed the baseline approach in the validation data of the 2nd COV19D
competition by 11% and 16% for Covid-19 detection and Covid-19 severity
detection, respectively."
"Whole exome sequencing was performed on HLA-matched stem cell donors and
transplant recipients to measure sequence variation contributing to minor
histocompatibility antigen differences between the two. A large number of
nonsynonymous single nucleotide polymorphisms were identified in each of the
nine unique donor-recipient pairs tested. This variation was greater in
magnitude in unrelated donors as compared with matched related donors.
Knowledge of the magnitude of exome variation between stem cell transplant
recipients and donors may allow more accurate titration of immunosuppressive
therapy following stem cell transplantation."
"Endometriosis is a common chronic gynecological disorder that has many
characteristics, including the pouch of Douglas (POD) obliteration, which can
be diagnosed using Transvaginal gynecological ultrasound (TVUS) scans and
magnetic resonance imaging (MRI). TVUS and MRI are complementary non-invasive
endometriosis diagnosis imaging techniques, but patients are usually not
scanned using both modalities and, it is generally more challenging to detect
POD obliteration from MRI than TVUS. To mitigate this classification imbalance,
we propose in this paper a knowledge distillation training algorithm to improve
the POD obliteration detection from MRI by leveraging the detection results
from unpaired TVUS data. More specifically, our algorithm pre-trains a teacher
model to detect POD obliteration from TVUS data, and it also pre-trains a
student model with 3D masked auto-encoder using a large amount of unlabelled
pelvic 3D MRI volumes. Next, we distill the knowledge from the teacher TVUS POD
obliteration detector to train the student MRI model by minimizing a regression
loss that approximates the output of the student to the teacher using unpaired
TVUS and MRI data. Experimental results on our endometriosis dataset containing
TVUS and MRI data demonstrate the effectiveness of our method to improve the
POD detection accuracy from MRI."
"With the development of high throughput sequencing technology, it becomes
possible to directly analyze mutation distribution in a genome-wide fashion,
dissociating mutation rate measurements from the traditional underlying
assumptions. Here, we sequenced several genomes of Escherichia coli from
colonies obtained after chemical mutagenesis and observed a strikingly
nonrandom distribution of the induced mutations. These include long stretches
of exclusively G to A or C to T transitions along the genome and orders of
magnitude intra- and inter-genomic differences in mutation density. Whereas
most of these observations can be explained by the known features of enzymatic
processes, the others could reflect stochasticity in the molecular processes at
the single-cell level. Our results demonstrate how analysis of the molecular
records left in the genomes of the descendants of an individual mutagenized
cell allows for genome-scale observations of fixation and segregation of
mutations, as well as recombination events, in the single genome of their
progenitor."
"Radiology reports have been widely used for extraction of various clinically
significant information about patients' imaging studies. However, limited
research has focused on standardizing the entities to a common
radiology-specific vocabulary. Further, no study to date has attempted to
leverage RadLex for standardization. In this paper, we aim to normalize a
diverse set of radiological entities to RadLex terms. We manually construct a
normalization corpus by annotating entities from three types of reports. This
contains 1706 entity mentions. We propose two deep learning-based NLP methods
based on a pre-trained language model (BERT) for automatic normalization.
First, we employ BM25 to retrieve candidate concepts for the BERT-based models
(re-ranker and span detector) to predict the normalized concept. The results
are promising, with the best accuracy (78.44%) obtained by the span detector.
Additionally, we discuss the challenges involved in corpus construction and
propose new RadLex terms."
"X-ray radiography is the most readily available imaging modality and has a
broad range of applications that spans from diagnosis to intra-operative
guidance in cardiac, orthopedics, and trauma procedures. Proper interpretation
of the hidden and obscured anatomy in X-ray images remains a challenge and
often requires high radiation dose and imaging from several perspectives. In
this work, we aim at decomposing the conventional X-ray image into d X-ray
components of independent, non-overlapped, clipped sub-volumes using deep
learning approach. Despite the challenging aspects of modeling such a highly
ill-posed problem, exciting and encouraging results are obtained paving the
path for further contributions in this direction."
"Background: Access to medical care is strongly dependent on resource
allocation, such as the geographical distribution of medical facilities.
Nevertheless, this data is usually restricted to country official
documentation, not available to the public. While some medical facilities' data
is accessible as semantic resources on the Web, it is not consistent in its
modeling and has yet to be integrated into a complete, open, and specialized
repository. This work focuses on generating a comprehensive semantic dataset of
medical facilities worldwide containing extensive information about such
facilities' geo-location.
  Results: For this purpose, we collect, align, and link various open-source
databases where medical facilities' information may be present. This work
allows us to evaluate each data source along various dimensions, such as
completeness, correctness, and interlinking with other sources, all critical
aspects of current knowledge representation technologies.
  Conclusions: Our contributions directly benefit stakeholders in the
biomedical and health domain (patients, healthcare professionals, companies,
regulatory authorities, and researchers), who will now have a better overview
of the access to and distribution of medical facilities."
"Purpose: To demonstrate the feasibility and performance of a fully automated
deep learning framework to estimate myocardial strain from short-axis cardiac
magnetic resonance tagged images. Methods and Materials: In this retrospective
cross-sectional study, 4508 cases from the UK Biobank were split randomly into
3244 training and 812 validation cases, and 452 test cases. Ground truth
myocardial landmarks were defined and tracked by manual initialization and
correction of deformable image registration using previously validated software
with five readers. The fully automatic framework consisted of 1) a
convolutional neural network (CNN) for localization, and 2) a combination of a
recurrent neural network (RNN) and a CNN to detect and track the myocardial
landmarks through the image sequence for each slice. Radial and circumferential
strain were then calculated from the motion of the landmarks and averaged on a
slice basis. Results: Within the test set, myocardial end-systolic
circumferential Green strain errors were -0.001 +/- 0.025, -0.001 +/- 0.021,
and 0.004 +/- 0.035 in basal, mid, and apical slices respectively (mean +/-
std. dev. of differences between predicted and manual strain). The framework
reproduced significant reductions in circumferential strain in diabetics,
hypertensives, and participants with previous heart attack. Typical processing
time was ~260 frames (~13 slices) per second on an NVIDIA Tesla K40 with 12GB
RAM, compared with 6-8 minutes per slice for the manual analysis. Conclusions:
The fully automated RNNCNN framework for analysis of myocardial strain enabled
unbiased strain evaluation in a high-throughput workflow, with similar ability
to distinguish impairment due to diabetes, hypertension, and previous heart
attack."
"Futurists have predicted that new technologies, embedded with artificial
intelligence (AI) and machine learning (ML), will lead to substantial job loss
in many sectors disrupting many aspects of healthcare. Mental health appears
ripe for such disruption given the global illness burden, stigma, and shortage
of care providers. Using Sermo, a global networking platform open to verified
and licensed physicians, we measured the opinions of psychiatrists about the
likelihood that future autonomous technology (referred to as AI/ML) would be
able to fully replace the average psychiatrist in performing 10 key tasks (e.g.
mental status exam, suicidality assessment, treatment planning) carried out in
mental health care. Survey respondents were 791 psychiatrists from 22
countries. Only 3.8% of respondents felt that AI/ML was likely to replace a
human clinician for providing empathetic care. Documenting (e.g. updating
medical records) and synthesizing information to reach a diagnosis were the two
tasks where a majority predicted that future AI/ML would replace human doctors.
About 1 in 2 doctors believed their jobs could be changed substantially by
future AI/ML. However, female and US-based doctors were more uncertain that the
possible benefits of AI would outweigh potential risks, versus their male and
global counterparts. To our knowledge, this is the first global survey to seek
the opinions of physicians on the impact of autonomous AI/ML on the future of
psychiatry. Our findings provide compelling insights into how physicians think
about intelligent technologies which may better help us integrate such tools
and reskill doctors, as needed, to enhance mental health care."
"We consider the constrained minimal supersymmetric standard model which
emerges from one theory with a small deviation from Yukawa unification which is
adequate for $\mu>0$. We show that this model possesses a wide and natural
range of parameters which is consistent with the data on $b\to s\gamma$, the
muon anomalous magnetic moment, the cold dark matter abundance in the universe,
and the Higgs boson masses."
"Motivation: We introduce TRONCO (TRanslational ONCOlogy), an open-source R
package that implements the state-of-the-art algorithms for the inference of
cancer progression models from (epi)genomic mutational profiles. TRONCO can be
used to extract population-level models describing the trends of accumulation
of alterations in a cohort of cross-sectional samples, e.g., retrieved from
publicly available databases, and individual-level models that reveal the
clonal evolutionary history in single cancer patients, when multiple samples,
e.g., multiple biopsies or single-cell sequencing data, are available. The
resulting models can provide key hints in uncovering the evolutionary
trajectories of cancer, especially for precision medicine or personalized
therapy.
  Availability: TRONCO is released under the GPL license, it is hosted in the
Software section at http://bimib.disco.unimib.it/ and archived also at
bioconductor.org.
  Contact: tronco@disco.unimib.it"
"In this paper we study a feasibility-seeking problem with percentage
violation constraints. These are additional constraints, that are appended to
an existing family of constraints, which single out certain subsets of the
existing constraints and declare that up to a specified fraction of the number
of constraints in each subset is allowed to be violated by up to a specified
percentage of the existing bounds. Our motivation to investigate problems with
percentage violation constraints comes from the field of radiation therapy
treatment planning wherein the fully-discretized inverse planning problem is
formulated as a split feasibility problem and the percentage violation
constraints give rise to non-convex constraints. Following the CQ algorithm of
Byrne (2002, Inverse Problems, Vol. 18, pp. 441-53), we develop a
string-averaging CQ method that uses only projections onto the individual sets
which are half-spaces represented by linear inequalities. The question of
extending our theoretical results to the non-convex sets case is still open. We
describe how our results apply to radiation therapy treatment planning and
provide a numerical example."
"This paper is a submission to the Alzheimer's Dementia Recognition through
Spontaneous Speech (ADReSS) challenge, which aims to develop methods that can
assist in the automated prediction of severity of Alzheimer's Disease from
speech data. We focus on acoustic and natural language features for cognitive
impairment detection in spontaneous speech in the context of Alzheimer's
Disease Diagnosis and the mini-mental state examination (MMSE) score
prediction. We proposed a model that obtains unimodal decisions from different
LSTMs, one for each modality of text and audio, and then combines them using a
gating mechanism for the final prediction. We focused on sequential modelling
of text and audio and investigated whether the disfluencies present in
individuals' speech relate to the extent of their cognitive impairment. Our
results show that the proposed classification and regression schemes obtain
very promising results on both development and test sets. This suggests
Alzheimer's Disease can be detected successfully with sequence modeling of the
speech data of medical sessions."
"Optimization of vaccine allocations among different segments of a
heterogeneous population is important for enhancing the effectiveness of
vaccination campaigns in reducing the burden of epidemics. Intuitively, it
would seem that allocations designed to minimize infections should prioritize
those with the highest risk of being infected and infecting others. This
prescription is well supported by vaccination theory, e.g., when the
vaccination campaign aims to reach herd immunity. In this work, we show,
however, that for vaccines providing partial protection (leaky vaccines) and
for sufficiently high values of the basic reproduction number, intuition is
overturned: the optimal allocation for minimizing the number of infections
prioritizes the vaccination of those who are least likely to be infected.
Furthermore, we show that this phenomenon occurs at a range of basic
reproduction numbers relevant for the currently circulating strains of
SARS-CoV-19. The work combines numerical investigations, asymptotic analysis
for a general model, and complete mathematical analysis in a simple two-group
model. The results point to important considerations in managing vaccination
campaigns for infections with high transmissibility."
"It has recently become popular to define treatment effects for subsets of the
target population characterized by variables not observable at the time a
treatment decision is made. Characterizing and estimating such treatment
effects is tricky; the most popular but naive approach inappropriately adjusts
for variables affected by treatment and so is biased. We consider several
appropriate ways to formalize the effects: principal stratification,
stratification on a single potential auxiliary variable, stratification on an
observed auxiliary variable and stratification on expected levels of auxiliary
variables. We then outline identifying assumptions for each type of estimand.
We evaluate the utility of these estimands and estimation procedures for
decision making and understanding causal processes, contrasting them with the
concepts of direct and indirect effects. We motivate our development with
examples from nephrology and cancer screening, and use simulated data and real
data on cancer screening to illustrate the estimation methods."
"Malaria is a potentially fatal plasmodium parasite injected by female
anopheles mosquitoes that infect red blood cells and millions worldwide yearly.
However, specialists' manual screening in clinical practice is laborious and
prone to error. Therefore, a novel Deep Boosted and Ensemble Learning (DBEL)
framework, comprising the stacking of new Boosted-BR-STM convolutional neural
networks (CNN) and the ensemble ML classifiers, is developed to screen malaria
parasite images. The proposed Boosted-BR-STM is based on a new
dilated-convolutional block-based split transform merge (STM) and feature-map
Squeezing-Boosting (SB) ideas. Moreover, the new STM block uses regional and
boundary operations to learn the malaria parasite's homogeneity, heterogeneity,
and boundary with patterns. Furthermore, the diverse boosted channels are
attained by employing Transfer Learning-based new feature-map SB in STM blocks
at the abstract, medium, and conclusion levels to learn minute intensity and
texture variation of the parasitic pattern. The proposed DBEL framework
implicates the stacking of prominent and diverse boosted channels and provides
the generated discriminative features of the developed Boosted-BR-STM to the
ensemble of ML classifiers. The proposed framework improves the discrimination
ability and generalization of ensemble learning. Moreover, the deep feature
spaces of the developed Boosted-BR-STM and customized CNNs are fed into ML
classifiers for comparative analysis. The proposed DBEL framework outperforms
the existing techniques on the NIH malaria dataset that are enhanced using
discrete wavelet transform to enrich feature space. The proposed DBEL framework
achieved Accuracy (98.50%), Sensitivity (0.9920), F-score (0.9850), and AUC
(0.997), which suggest it to be utilized for malaria parasite screening."
"Scientific and technological advances in medicine and systems biology have
unequivocally shown that health and disease must be viewed in the context of
the interplay among multiple molecular and environmental factors. Understanding
the effects of cellular interconnection on disease progression may lead to the
identification of novel disease genes and pathways, and hence influence
precision diagnostics and therapeutics. To accomplish this goal, the emerging
field of network medicine applies network science approaches to investigate
disease pathogenesis, integrating information from relevant Omics databases,
including protein-protein interaction, correlation-based, gene regulatory, and
Bayesian networks. However, this requires analysing and computing large amounts
of data. Moreover, if we are to efficiently search for new drugs and new drug
combinations, there is a pressing need for computational methods that could
allow us to access the immense chemical compound space until now largely
unexplored. Finally, at the microscopic level, drug-target chemistry simulation
is ultimately a quantum problem, and hence it requires a quantum solution. As
we will discuss, quantum computing may be a key ingredient in enabling the full
potential of network medicine. We propose to combine network medicine and
quantum algorithms in a novel research field, quantum network medicine, to lay
the foundations of a new era of disease prevention and drug design."
"Recently, the robotic ultrasound system has become an emerging topic owing to
the widespread use of medical ultrasound. However, it is still a challenging
task to model and to transfer the ultrasound skill from an ultrasound
physician. In this paper, we propose a learning-based framework to acquire
ultrasound scanning skills from human demonstrations. First, the ultrasound
scanning skills are encapsulated into a high-dimensional multi-modal model in
terms of interactions among ultrasound images, the probe pose and the contact
force. The parameters of the model are learned using the data collected from
skilled sonographers' demonstrations. Second, a sampling-based strategy is
proposed with the learned model to adjust the extracorporeal ultrasound
scanning process to guide a newbie sonographer or a robot arm. Finally, the
robustness of the proposed framework is validated with the experiments on real
data from sonographers."
"This paper explores how well deep learning models trained on chest CT images
can diagnose COVID-19 infected people in a fast and automated process. To this
end, we adopt advanced deep network architectures and propose a transfer
learning strategy using custom-sized input tailored for each deep architecture
to achieve the best performance. We conduct extensive sets of experiments on
two CT image datasets, namely the SARS-CoV-2 CT-scan and the COVID19-CT. The
obtained results show superior performances for our models compared with
previous studies, where our best models achieve average accuracy, precision,
sensitivity, specificity and F1 score of 99.4%, 99.6%, 99.8%, 99.6% and 99.4%
on the SARS-CoV-2 dataset; and 92.9%, 91.3%, 93.7%, 92.2% and 92.5% on the
COVID19-CT dataset, respectively. Furthermore, we apply two visualization
techniques to provide visual explanations for the models' predictions. The
visualizations show well-separated clusters for CT images of COVID-19 from
other lung diseases, and accurate localizations of the COVID-19 associated
regions."
"Background: The debate over daylight saving time has surged, with interests
in the effects of sunlight exposure on health. \commentnj{Prior studies
simulated daylight saving time and standard time conditions by analyzing
different locations within time zones and neighboring areas across time zone
borders.
  Methods: We analyzed cancer incidence rates from various longitudinal
positions within time zones and at time zone borders in the contiguous United
States. Using data from State Cancer Profiles (2016-2020), we analyzed total
cancer of 19 types and specific rates for eight cancers, adjusted for age and
includes all demographics. Log-linear regression is used to replicate a
previous study, and spatial regression models are employed to explore
discontinuities at borders.
  Results: Cancer rate differences lack statistical significance within time
zones and near borders for total cancer and most individual cancers. Exceptions
included breast, prostate, and liver \& bile duct cancers, which exhibited
significant relationships with relative position at the 95\% significance
level. Breast and liver and bile duct cancers saw decreases, while prostate
cancer incidence increased from west to east within time zones.
  Conclusions: Relative position does not have a significant impact on cancer
incidence, hence cancer development in general. Isolated exceptions may warrant
further investigation as more data becomes available.
  Impact: Our findings challenge prior research, revealing numerous
inconsistencies. These disparities urge a reconsideration of the potential
disparities in human health associated with daylight saving time and standard
time. They offer insights contribute to the ongoing discussion surrounding the
retention or abandonment of DST."
"Consumption of diets with low glycemic impact is highly recommended for
diabetics and pre-diabetics as it helps maintain their blood glucose levels.
However, laboratory analysis of dietary glycemic potency is time-consuming and
expensive. In this paper, we explore a data-driven approach utilizing online
crowdsourcing and machine learning to estimate the glycemic impact of cooking
recipes. We show that a commonly used healthiness metric may not always be
effective in determining recipes suitable for diabetics, thus emphasizing the
importance of the glycemic-impact estimation task. Our best classification
model, trained on nutritional and crowdsourced data obtained from Amazon
Mechanical Turk (AMT), can accurately identify recipes which are unhealthful
for diabetics."
"Clinical diagnosis of the pediatric musculoskeletal system relies on the
analysis of medical imaging examinations. In the medical image processing
pipeline, semantic segmentation using deep learning algorithms enables an
automatic generation of patient-specific three-dimensional anatomical models
which are crucial for morphological evaluation. However, the scarcity of
pediatric imaging resources may result in reduced accuracy and generalization
performance of individual deep segmentation models. In this study, we propose
to design a novel multi-task, multi-domain learning framework in which a single
segmentation network is optimized over the union of multiple datasets arising
from distinct parts of the anatomy. Unlike previous approaches, we
simultaneously consider multiple intensity domains and segmentation tasks to
overcome the inherent scarcity of pediatric data while leveraging shared
features between imaging datasets. To further improve generalization
capabilities, we employ a transfer learning scheme from natural image
classification, along with a multi-scale contrastive regularization aimed at
promoting domain-specific clusters in the shared representations, and
multi-joint anatomical priors to enforce anatomically consistent predictions.
We evaluate our contributions for performing bone segmentation using three
scarce and pediatric imaging datasets of the ankle, knee, and shoulder joints.
Our results demonstrate that the proposed approach outperforms individual,
transfer, and shared segmentation schemes in Dice metric with statistically
sufficient margins. The proposed model brings new perspectives towards
intelligent use of imaging resources and better management of pediatric
musculoskeletal disorders."
"Childhood obesity is a major public health concern. Multidisciplinary
pediatric weight management programs are considered standard treatment for
children with obesity and severe obesity who are not able to be successfully
managed in the primary care setting; however, high drop-out rates (referred to
as attrition) are a major hurdle in delivering successful interventions.
Predicting attrition patterns can help providers reduce the attrition rates.
Previous work has mainly focused on finding static predictors of attrition
using statistical analysis methods. In this study, we present a machine
learning model to predict (a) the likelihood of attrition, and (b) the change
in body-mass index (BMI) percentile of children, at different time points after
joining a weight management program. We use a five-year dataset containing the
information related to around 4,550 children that we have compiled using data
from the Nemours Pediatric Weight Management program. Our models show strong
prediction performance as determined by high AUROC scores across different
tasks (average AUROC of 0.75 for predicting attrition, and 0.73 for predicting
weight outcomes). Additionally, we report the top features predicting attrition
and weight outcomes in a series of explanatory experiments."
"An increasingly aging population and spiraling healthcare costs have made the
search for financially viable healthcare models an imperative of this century.
The careful and creative application of information technology can play a
significant role in meeting that challenge. Valuable lessons can be learned
from an analysis of ten innovative telemedicine and e-health initiatives.
Having proven their effectiveness in addressing a variety of medical needs,
they have progressed beyond small-scale implementations to become an
established part of healthcare delivery systems around the world."
"Simulations of three dimensional ultrasound propagation in heterogeneous
media are computationally intensive due to the constraints arising from the
large size of the domain, which is on the order of hundreds of wavelengths, and
the small size of scatterers, which are much smaller than a wavelength.
Consequently, three dimensional ultrasound imaging simulations are currently
based on models that simplify the propagation physics. Here the full three
dimensional wave physics is simulated with finite differences to generate
ultrasound images of the human body based directly on the first principles of
propagation and backscattering. The Visible Human project, a 3D data set of the
human body that was generated with photographs of 0.33 mm cryosections, is
converted into 3D acoustical maps. A full-wave nonlinear acoustic simulation
tool is used to propagate ultrasound into the liver with a 2D intercostal
ultrasound array in a $93 \times 39 \times 22$ mm domain with $6\times10^8$
points. Imaging metrics, based on the beamplots, root-mean-square phase
aberration, spatial coherence lengths, and contrast-to-noise ratio are used to
characterize the image quality. It is shown that the harmonic image quality is
better than the fundamental image quality due, in part, to a narrower beam
profile. The root-mean-square estimate of aberration after propagation through
the simulated body wall is shown to be low (23.4 ns), consistently with
previous reports of aberration measured experimentally in a human body wall.
The spatial coherence measured at the transducer surface indicates that a
transducer array element size of $<0.81 \lambda$ would be required to fully
sample the acoustic field. These simulated three dimensional ultrasound images
based directly on propagation physics provide a platform to investigate the
sources of image degradation in three dimensions (included in Part II)."
"In this pioneering study, inspired by AutoGPT, the state-of-the-art
open-source application based on the GPT-4 large language model, we develop a
novel tool called AD-AutoGPT which can conduct data collection, processing, and
analysis about complex health narratives of Alzheimer's Disease in an
autonomous manner via users' textual prompts. We collated comprehensive data
from a variety of news sources, including the Alzheimer's Association, BBC,
Mayo Clinic, and the National Institute on Aging since June 2022, leading to
the autonomous execution of robust trend analyses, intertopic distance maps
visualization, and identification of salient terms pertinent to Alzheimer's
Disease. This approach has yielded not only a quantifiable metric of relevant
discourse but also valuable insights into public focus on Alzheimer's Disease.
This application of AD-AutoGPT in public health signifies the transformative
potential of AI in facilitating a data-rich understanding of complex health
narratives like Alzheimer's Disease in an autonomous manner, setting the
groundwork for future AI-driven investigations in global health landscapes."
"The question of how individual patient data from cohort studies or historical
clinical trials can be leveraged for designing more powerful, or smaller yet
equally powerful, clinical trials becomes increasingly important in the era of
digitalisation. Today, the traditional statistical analyses approaches may seem
questionable to practitioners in light of ubiquitous historical covariate
information.
  Several methodological developments aim at incorporating historical
information in the design and analysis of future clinical trials, most
importantly Bayesian information borrowing, propensity score methods,
stratification, and covariate adjustment. Recently, adjusting the analysis with
respect to a prognostic score, which was obtained from some machine learning
procedure applied to historical data, has been suggested and we study the
potential of this approach for randomised clinical trials.
  In an idealised situation of a normal outcome in a two-arm trial with 1:1
allocation, we derive a simple sample size reduction formula as a function of
two criteria characterising the prognostic score: (1) The coefficient of
determination $R^2$ on historical data and (2) the correlation $\rho$ between
the estimated and the true unknown prognostic scores. While maintaining the
same power, the original total sample size $n$ planned for the unadjusted
analysis reduces to $(1 - R^2 \rho^2) \times n$ in an adjusted analysis.
Robustness in less ideal situations was assessed empirically. We conclude that
there is potential for substantially more powerful or smaller trials, but only
when prognostic scores can be accurately estimated."
"Drug-drug interactions (DDI) can cause severe adverse drug reactions and pose
a major challenge to medication therapy. Recently, informatics-based approaches
are emerging for DDI studies. In this paper, we aim to identify key
pharmacological components in DDI based on large-scale data from DrugBank, a
comprehensive DDI database. With pharmacological components as features,
logistic regression is used to perform DDI classification with a focus on
searching for most predictive features, a process of identifying key
pharmacological components. Using univariate feature selection with chi-squared
statistic as the ranking criteria, our study reveals that top 10% features can
achieve comparable classification performance compared to that using all
features. The top 10% features are identified to be key pharmacological
components. Furthermore, their importance is quantified by feature coefficients
in the classifier, which measures the DDI potential and provides a novel
perspective to evaluate pharmacological components."
"Asthma is one of the chronic inflammatory diseases of the airways, which
causes chest tightness, wheezing, breathlessness, and cough. Spirometry is an
effort-dependent test used to monitor and diagnose lung conditions like Asthma.
Vocal breath sound (VBS) based analysis can be an alternative to spirometry as
VBS characteristics change depending on the lung condition. VBS test consumes
less time, and it also requires less effort, unlike spirometry. In this work,
VBS characteristics are analyzed before and after administering bronchodilator
in a subject-dependent manner using linear discriminant analysis (LDA). We find
that features learned through LDA show a significant difference between VBS
recorded before and after administering bronchodilator in all 30 subjects
considered in this work, whereas the baseline features could achieve a
significant difference between VBS only for 26 subjects. We also observe that
all frequency ranges do not contribute equally to the discrimination between
pre and post bronchodilator conditions. From experiments, we find that two
frequency ranges, namely 400-500Hz and 1480-1900Hz, maximally contribute to the
discrimination of all the subjects. The study presented in this paper analyzes
the pre and post-bronchodilator effect on the inhalation sound recorded at the
mouth in a subject-dependent manner. The findings of this work suggest that,
inhalation sound recorded at mouth can be a good stimulus to discriminate pre
and post-bronchodilator conditions in asthmatic subjects. Inhale sound-based
pre and post-bronchodilator discrimination can be of potential use in clinical
settings."
"Convolutional neural networks (CNNs) have shown great promise in improving
computer aided detection (CADe). From classifying tumors found via mammography
as benign or malignant to automated detection of colorectal polyps in CT
colonography, these advances have helped reduce the need for further evaluation
with invasive testing and prevent errors from missed diagnoses by acting as a
second observer in today's fast paced and high volume clinical environment.
CADe methods have become faster and more precise thanks to innovations in deep
learning over the past several years. With advancements such as the inception
module and utilization of residual connections, the approach to designing CNN
architectures has become an art. It is customary to use proven models and fine
tune them for particular tasks given a dataset, often requiring tedious work.
We investigated using a genetic algorithm (GA) to conduct a neural
architectural search (NAS) to generate a novel CNN architecture to find early
stage lung cancer in chest x-rays (CXR). Using a dataset of over twelve
thousand biopsy proven cases of lung cancer, the trained classification model
achieved an accuracy of 97.15% with a PPV of 99.88% and a NPV of 94.81%,
beating models such as Inception-V3 and ResNet-152 while simultaneously
reducing the number of parameters a factor of 4 and 14, respectively."
"The rapid mutation of the influenza virus threatens public health.
Reassortment among viruses with different hosts can lead to a fatal pandemic.
However, it is difficult to detect the original host of the virus during or
after an outbreak as influenza viruses can circulate between different species.
Therefore, early and rapid detection of the viral host would help reduce the
further spread of the virus. We use various machine learning models with
features derived from the position-specific scoring matrix (PSSM) and features
learned from word embedding and word encoding to infer the origin host of
viruses. The results show that the performance of the PSSM-based model reaches
the MCC around 95%, and the F1 around 96%. The MCC obtained using the model
with word embedding is around 96%, and the F1 is around 97%."
"Early surgical treatment of brain tumors is crucial in reducing patient
mortality rates. However, brain tissue deformation (called brain shift) occurs
during the surgery, rendering pre-operative images invalid. As a cost-effective
and portable tool, intra-operative ultrasound (iUS) can track brain shift, and
accurate MRI-iUS registration techniques can update pre-surgical plans and
facilitate the interpretation of iUS. This can boost surgical safety and
outcomes by maximizing tumor removal while avoiding eloquent regions. However,
manual assessment of MRI-iUS registration results in real-time is difficult and
prone to errors due to the 3D nature of the data. Automatic algorithms that can
quantify the quality of inter-modal medical image registration outcomes can be
highly beneficial. Therefore, we propose a novel deep-learning (DL) based
framework with the Swin UNETR to automatically assess 3D-patch-wise dense error
maps for MRI-iUS registration in iUS-guided brain tumor resection and show its
performance with real clinical data for the first time."
"Dengue is the most prevalent arthropod-borne viral disease. Clinical symptoms
of dengue virus (DENV) infection range from classical mild dengue fever to
severe, life-threatening dengue shock syndrome. However, most DENV infections
cause few or no symptoms. Asymptomatic DENV-infected patients provide a unique
opportunity to decipher the host immune responses leading to virus elimination
without negative impact on t v 'health. We used an integrated approach of
transcriptional profiling and immunological analysis comparing a Cambodian
population of strictly asymptomatic viremic individuals with clinical dengue
patients. Whereas inflammatory pathways and innate immune responses were
similar between asymptomatic individuals and clinical dengue patients,
expression of proteins related to antigen presentation and subsequent T and B
cell activation pathways were differentially regulated, independent of viral
load or previous DENV infection. Feedback mechanisms controlled the immune
response in asymptomatic viremic individuals as demonstrated by increased
activation of T cell apoptosis-related pathways and Fc$\gamma$RIIB signaling
associated with decreased anti-DENV specific antibody concentrations. Taken
together, our data illustrate that symptom-free DENV infection in children is
determined by increased activation of the adaptive immune compartment and
proper control mechanisms leading to elimination of viral infection without
excessive immune activation, having implications for novel vaccine development
strategies."
"Rehabilitation training for patients with motor disabilities usually requires
specialized devices in rehabilitation centers. Home-based multi-purpose
training would significantly increase treatment accessibility and reduce
medical costs. While it is unlikely to equip a set of rehabilitation robots at
home, we investigate the feasibility to use the general-purpose collaborative
robot for rehabilitation therapies. In this work, we developed a new system for
multi-purpose upper-limb rehabilitation training using a generic robot arm with
human motor feedback and preference. We integrated surface electromyography,
force/torque sensors, RGB-D cameras, and robot controllers with the Robot
Operating System to enable sensing, communication, and control of the system.
Imitation learning methods were adopted to imitate expert-provided training
trajectories which could adapt to subject capabilities to facilitate in-home
training. Our rehabilitation system is able to perform gross motor function and
fine motor skill training with a gripper-based end-effector. We simulated
system control in Gazebo and training effects (muscle activation level) in
OpenSim and evaluated its real performance with human subjects. For all the
subjects enrolled, our system achieved better training outcomes compared to
specialist-assisted rehabilitation under the same conditions. Our work
demonstrates the potential of utilizing collaborative robots for in-home motor
rehabilitation training."
"In the last five years, Moroccan e-health system has focused on improving the
quality of patient care services by making use of advanced Information and
Communications Technologies (ICT) solutions. In actual fact, achieving runtime
and efficient information sharing, through large-scale distributed environments
such as e-health system, is not a trivial task. It seems to present many issues
due to the heterogeneity and complex nature of data resources. This concerns,
in particular, Moroccan Hospital Pharmacy Information System (HPIS) which needs
to interact with several disparate medical information systems. Service
Oriented Architecture (SOA) offers solution that is both flexible and practical
to effectively address the problem of interoperability of e-health systems. In
this paper, we discuss the limits and challenges of the current Moroccan
information system intended for hospital pharmacy. We therefore propose a
global Web services-based e-health architecture for integrating different
heterogeneous blocks and various data resources of this system. We also present
a solution to secure Web services communication using WS-SecurityPolicy."
"For applications in nanomedicine, particles need to be functionalized to
prevent protein corona formation and or aggregation. Most advanced strategies
take advantage of functional polymers and assembly techniques. Nowadays there
is an urgent need for coatings that are tailored according to a broad range of
surfaces and that can be produced on a large scale. Herein, we synthesize mono-
and multi-phosphonic acid based poly(ethylene glycol) (PEG) polymers with the
objective of producing efficient coats for metal oxide nanoparticles. Cerium,
iron, titanium and aluminum oxide nanoparticles of different morphologies
(spheres, platelets, nanoclusters) and sizes ranging from 7 to 40 nm are
studied in physiological and in protein rich cell culture media. It is found
that the particles coated with mono-functionalized polymers exhibit a mitigated
stability over time, whereas the multi-functionalized copolymers provide
resilient coatings and long-term stability (months). With the latter, PEG
densities in the range 0.2 - 0.5 nm-2 and layer thickness about 10 nm provide
excellent performances. The study suggests that the proposed coating allows
controlling nanomaterial interfacial properties in biological environments."
"We investigate the automatic processing of child speech therapy sessions
using ultrasound visual biofeedback, with a specific focus on complementing
acoustic features with ultrasound images of the tongue for the tasks of speaker
diarization and time-alignment of target words. For speaker diarization, we
propose an ultrasound-based time-domain signal which we call estimated tongue
activity. For word-alignment, we augment an acoustic model with low-dimensional
representations of ultrasound images of the tongue, learned by a convolutional
neural network. We conduct our experiments using the Ultrasuite repository of
ultrasound and speech recordings for child speech therapy sessions. For both
tasks, we observe that systems augmented with ultrasound data outperform
corresponding systems using only the audio signal."
"Biomedical information is growing rapidly in the recent years and retrieving
useful data through information extraction system is getting more attention. In
the current research, we focus on different aspects of relation extraction
techniques in biomedical domain and briefly describe the state-of-the-art for
relation extraction between a variety of biological elements."
"This paper presents a novel graph convolutional neural network (GCNN)-based
approach for improving the diagnosis of neurological diseases using
scalp-electroencephalograms (EEGs). Although EEG is one of the main tests used
for neurological-disease diagnosis, the sensitivity of EEG-based expert visual
diagnosis remains at $\sim$50\%. This indicates a clear need for advanced
methodology to reduce the false negative rate in detecting abnormal scalp-EEGs.
In that context, we focus on the problem of distinguishing the abnormal scalp
EEGs of patients with neurological diseases, which were originally classified
as 'normal' by experts, from the scalp EEGs of healthy individuals. The
contributions of this paper are three-fold: 1) we present EEG-GCNN, a novel
GCNN model for EEG data that captures both the spatial and functional
connectivity between the scalp electrodes, 2) using EEG-GCNN, we perform the
first large-scale evaluation of the aforementioned hypothesis, and 3) using two
large scalp-EEG databases, we demonstrate that EEG-GCNN significantly
outperforms the human baseline and classical machine learning (ML) baselines,
with an AUC of 0.90."
"Understanding dynamics of an infectious disease helps in designing
appropriate strategies for containing its spread in a population. Recent
mathematical models are aimed at studying dynamics of some specific types of
infectious diseases. In this paper we propose a new model for infectious
diseases spread having susceptible, infected, and recovered populations and
study its dynamics in presence of incubation delays and relapse of the disease.
The influence of treatment and vaccination efforts on the spread of infection
in presence of time delays are studied. Sufficient conditions for local
stability of the equilibria and change of stability are derived in various
cases. The problem of global stability is studied for an important special case
of the model. Simulations carried out in this study brought out the importance
of treatment rate in controlling the disease spread. It is observed that
incubation delays have influence on the system even under enhanced vaccination.
The present study has clearly brought out the fact that treatment rate in
presence of time delays would contain the disease as compared to popular belief
that eradication can only be done through vaccination."
"Malaria is a life-threatening disease affecting millions. Microscopy-based
assessment of thin blood films is a standard method to (i) determine malaria
species and (ii) quantitate high-parasitemia infections. Full automation of
malaria microscopy by machine learning (ML) is a challenging task because
field-prepared slides vary widely in quality and presentation, and artifacts
often heavily outnumber relatively rare parasites. In this work, we describe a
complete, fully-automated framework for thin film malaria analysis that applies
ML methods, including convolutional neural nets (CNNs), trained on a large and
diverse dataset of field-prepared thin blood films. Quantitation and species
identification results are close to sufficiently accurate for the concrete
needs of drug resistance monitoring and clinical use-cases on field-prepared
samples. We focus our methods and our performance metrics on the field use-case
requirements. We discuss key issues and important metrics for the application
of ML methods to malaria microscopy."
"Motivation: Precision medicine is a major trend in the future of medicine. It
aims to provide tailored medical treatment and prevention strategies based on
an individual's unique characteristics and needs. Biomarker is the primary
source of patients' unique features used in precision medicine. We often need
to investigate many cutoff values of a continuous biomarker to find the optimal
one and test if it can help segment patients into two groups with significantly
different clinical outcomes. This requires multiple testing adjustments on
tests conducted on overlapped data. The permutation-based approach is often a
preferred solution, since it does not suffer the limitations of state-of-art
theoretical methods. However, permutation is computationally expensive and
limits its application scenarios, such as web applications requiring a fast
response or the analysis of genomic study requiring to repeat analysis many
times on tens of thousands of genes.
  Results: We proposed a novel method BOSS, Biomarker Optimal Segmentation
System, to solve this problem. In simulation studies, we found BOSS's
statistical power and type I error control are both non-inferior to the
permutation approach, and it is hundreds of times faster than permutation. To
illustrate our method, we applied BOSS to real data and revealed potentially
converging biomarkers that have referential importance in exploring synergy and
target-matched therapies in lung adenocarcinoma.
  Availability: An R package, boss, is being developed and will be available on
CRAN"
"Purpose: In this paper, we present an automated method for article
classification, leveraging the power of Large Language Models (LLM). The
primary focus is on the field of ophthalmology, but the model is extendable to
other fields. Methods: We have developed a model based on Natural Language
Processing (NLP) techniques, including advanced LLMs, to process and analyze
the textual content of scientific papers. Specifically, we have employed
zero-shot learning (ZSL) LLM models and compared against Bidirectional and
Auto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder
Representations from Transformers (BERT), and its variant such as distilBERT,
SciBERT, PubmedBERT, BioBERT. Results: The classification results demonstrate
the effectiveness of LLMs in categorizing large number of ophthalmology papers
without human intervention. Results: To evalute the LLMs, we compiled a dataset
(RenD) of 1000 ocular disease-related articles, which were expertly annotated
by a panel of six specialists into 15 distinct categories. The model achieved
mean accuracy of 0.86 and mean F1 of 0.85 based on the RenD dataset.
Conclusion: The proposed framework achieves notable improvements in both
accuracy and efficiency. Its application in the domain of ophthalmology
showcases its potential for knowledge organization and retrieval in other
domains too. We performed trend analysis that enables the researchers and
clinicians to easily categorize and retrieve relevant papers, saving time and
effort in literature review and information gathering as well as identification
of emerging scientific trends within different disciplines. Moreover, the
extendibility of the model to other scientific fields broadens its impact in
facilitating research and trend analysis across diverse disciplines."
"Every 20 seconds, a limb is amputated somewhere in the world due to diabetes.
This is a global health problem that requires a global solution. The MICCAI
challenge discussed in this paper, which concerns the automated detection of
diabetic foot ulcers using machine learning techniques, will accelerate the
development of innovative healthcare technology to address this unmet medical
need. In an effort to improve patient care and reduce the strain on healthcare
systems, recent research has focused on the creation of cloud-based detection
algorithms. These can be consumed as a service by a mobile app that patients
(or a carer, partner or family member) could use themselves at home to monitor
their condition and to detect the appearance of a diabetic foot ulcer (DFU).
Collaborative work between Manchester Metropolitan University, Lancashire
Teaching Hospital and the Manchester University NHS Foundation Trust has
created a repository of 4,000 DFU images for the purpose of supporting research
toward more advanced methods of DFU detection. Based on a joint effort
involving the lead scientists of the UK, US, India and New Zealand, this
challenge will solicit original work, and promote interactions between
researchers and interdisciplinary collaborations. This paper presents a dataset
description and analysis, assessment methods, benchmark algorithms and initial
evaluation results. It facilitates the challenge by providing useful insights
into state-of-the-art and ongoing research. This grand challenge takes on even
greater urgency in a peri and post-pandemic period, where stresses on resource
utilization will increase the need for technology that allows people to remain
active, healthy and intact in their home."
"Estimating new HIV infections is significant yet challenging due to the
difficulty in distinguishing between recent and long-term infections. We
demonstrate that HIV recency status (recent v.s. long-term) could be determined
from the combination of self-report testing history and biomarkers, which are
increasingly available in bio-behavioral surveys. HIV recency status is
partially observed, given the self-report testing history. For example, people
who tested positive for HIV over one year ago should have a long-term
infection. Based on the nationally representative samples collected by the
Population-based HIV Impact Assessment (PHIA) Project, we propose a
likelihood-based probabilistic model for HIV recency classification. The model
incorporates both labeled and unlabeled data and integrates the mechanism of
how HIV recency status depends on biomarkers and the mechanism of how HIV
recency status, together with the self-report time of the most recent HIV test,
impacts the test results, via a set of logistic regression models. We compare
our method to logistic regression and the binary classification tree (current
practice) on Malawi, Zimbabwe, and Zambia PHIA data, as well as on simulated
data. Our model obtains more efficient and less biased parameter estimates and
is relatively robust to potential reporting error and model misspecification."
"We have made a progressive observation of Covid-19 Astra Zeneca Vaccination
effect on Skin cellular network and properties by use of well established
Intelligent Laser Speckle Classification (ILSC) image based technique and
managed to distinguish between three different subjects groups via their laser
speckle skin image samplings such as early-vaccinated, late-vaccinated and
non-vaccinated individuals. The results have proven that the ILSC technique in
association with the optimised Bayesian network is capable of classifying skin
changes of vaccinated and non-vaccinated individuals and also of detecting
progressive development made on skin cellular properties for a month period."
"Mental illnesses adversely affect a significant proportion of the population
worldwide. However, the methods traditionally used for estimating and
characterizing the prevalence of mental health conditions are time-consuming
and expensive. Consequently, best-available estimates concerning the prevalence
of mental health conditions are often years out of date. Automated approaches
to supplement these survey methods with broad, aggregated information derived
from social media content provides a potential means for near real-time
estimates at scale. These may, in turn, provide grist for supporting,
evaluating and iteratively improving upon public health programs and
interventions.
  We propose a novel model for automated mental health status quantification
that incorporates user embeddings. This builds upon recent work exploring
representation learning methods that induce embeddings by leveraging social
media post histories. Such embeddings capture latent characteristics of
individuals (e.g., political leanings) and encode a soft notion of homophily.
In this paper, we investigate whether user embeddings learned from twitter post
histories encode information that correlates with mental health statuses. To
this end, we estimated user embeddings for a set of users known to be affected
by depression and post-traumatic stress disorder (PTSD), and for a set of
demographically matched `control' users. We then evaluated these embeddings
with respect to: (i) their ability to capture homophilic relations with respect
to mental health status; and (ii) the performance of downstream mental health
prediction models based on these features. Our experimental results demonstrate
that the user embeddings capture similarities between users with respect to
mental conditions, and are predictive of mental health."
"The goal of cancer immunotherapy is to boost a patient's immune response to a
tumor. Yet, the design of an effective immunotherapy is complicated by various
factors, including a potentially immunosuppressive tumor microenvironment,
immune-modulating effects of conventional treatments, and therapy-related
toxicities. These complexities can be incorporated into mathematical and
computational models of cancer immunotherapy that can then be used to aid in
rational therapy design. In this review, we survey modeling approaches under
the umbrella of the major challenges facing immunotherapy development, which
encompass tumor classification, optimal treatment scheduling, and combination
therapy design. Although overlapping, each challenge has presented unique
opportunities for modelers to make contributions using analytical and numerical
analysis of model outcomes, as well as optimization algorithms. We discuss
several examples of models that have grown in complexity as more biological
information has become available, showcasing how model development is a dynamic
process interlinked with the rapid advances in tumor-immune biology. We
conclude the review with recommendations for modelers both with respect to
methodology and biological direction that might help keep modelers at the
forefront of cancer immunotherapy development."
"Object detection and localization are crucial tasks for biomedical image
analysis, particularly in the field of hematology where the detection and
recognition of blood cells are essential for diagnosis and treatment decisions.
While attention-based methods have shown significant progress in object
detection in various domains, their application in medical object detection has
been limited due to the unique challenges posed by medical imaging datasets. To
address this issue, we propose ADA-YOLO, a light-weight yet effective method
for medical object detection that integrates attention-based mechanisms with
the YOLOv8 architecture. Our proposed method leverages the dynamic feature
localisation and parallel regression for computer vision tasks through
\textit{adaptive head} module. Empirical experiments were conducted on the
Blood Cell Count and Detection (BCCD) dataset to evaluate the effectiveness of
ADA-YOLO. The results showed that ADA-YOLO outperforms the YOLOv8 model in mAP
(mean average precision) on the BCCD dataset by using more than 3 times less
space than YOLOv8. This indicates that our proposed method is effective.
Moreover, the light-weight nature of our proposed method makes it suitable for
deployment in resource-constrained environments such as mobile devices or edge
computing systems. which could ultimately lead to improved diagnosis and
treatment outcomes in the field of hematology."
"Previous studies have described the concept of peptide strings in qualitative
terms and illustrated it by applying its corrolaries in order to elucidate
basic questions in oncology and rheumatology. The present investigation is the
first to quantify these potential sub- and transcellular phenomena.
Accordingly, the propagation of peptide strings is proposed here to occur by
way of waves that in turn are subject to the energy equation established by
Planck. As a result of these insights, widespread future applications can now
be envisaged for peptide strings both in molecular medicine and quantum optics."
"Clinical trials are the basis of Evidence-Based Medicine. Trial results are
reviewed by experts and consensus panels for producing meta-analyses and
clinical practice guidelines. However, reviewing these results is a long and
tedious task, hence the meta-analyses and guidelines are not updated each time
a new trial is published. Moreover, the independence of experts may be
difficult to appraise. On the contrary, in many other domains, including
medical risk analysis, the advent of data science, big data and visual
analytics allowed moving from expert-based to fact-based knowledge. Since 12
years, many trial results are publicly available online in trial registries.
Nevertheless, data science methods have not yet been applied widely to trial
data. In this paper, we present a platform for analyzing the safety events
reported during clinical trials and published in trial registries. This
platform is based on an ontological model including 582 trials on pain
treatments, and uses semantic web technologies for querying this dataset at
various levels of granularity. It also relies on a 26-dimensional flower glyph
for the visualization of the Adverse Drug Events (ADE) rates in 13 categories
and 2 levels of seriousness. We illustrate the interest of this platform
through several use cases and we were able to find back conclusions that were
initially found during meta-analyses. The platform was presented to four
experts in drug safety, and is publicly available online, with the ontology of
pain treatment ADE."
"On August 9-10, 2023, a workshop was convened at the Pacific Northwest
National Laboratory (PNNL) in Richland, WA that brought together a group of
internationally recognized experts in metabolomics, natural products discovery,
chemical ecology, chemical and biological threat assessment, cheminformatics,
computational chemistry, cloud computing, artificial intelligence, and novel
technology development. These experts were invited to assess the value and
feasibility of a grand-scale project to create new technologies that would
allow the identification and quantification of all small molecules, or to
decode the molecular universe. The Decoding the Molecular Universe project
would extend and complement the success of the Human Genome Project by
developing new capabilities and technologies to measure small molecules
(defined as non-protein, non-polymer molecules less than 1500 Daltons) of any
origin and generated in biological systems or produced abiotically. Workshop
attendees 1) explored what new understanding of biological and environmental
systems could be revealed through the lens of small molecules; 2) characterized
the similarities in current needs and technical challenges between each science
or mission area for unambiguous and comprehensive determination of the
composition and quantities of small molecules of any sample; 3) determined the
extent to which technologies or methods currently exist for unambiguously and
comprehensively determining the small molecule composition of any sample and in
a reasonable time; and 4) identified the attributes of the ideal technology or
approach for universal small molecule measurement and identification. The
workshop concluded with a discussion of how a project of this scale could be
undertaken, possible thrusts for the project, early proof-of-principle
applications, and similar efforts upon which the project could be modeled."
"Gynaecologists and obstetricians visually interpret cardiotocography (CTG)
traces using the International Federation of Gynaecology and Obstetrics (FIGO)
guidelines to assess the wellbeing of the foetus during antenatal care. This
approach has raised concerns among professionals with regards to inter- and
intra-variability where clinical diagnosis only has a 30\% positive predictive
value when classifying pathological outcomes. Machine learning models, trained
with FIGO and other user derived features extracted from CTG traces, have been
shown to increase positive predictive capacity and minimise variability. This
is only possible however when class distributions are equal which is rarely the
case in clinical trials where case-control observations are heavily skewed in
favour of normal outcomes. Classes can be balanced using either synthetic data
derived from resampled case training data or by decreasing the number of
control instances. However, this either introduces bias or removes valuable
information. Concerns have also been raised regarding machine learning studies
and their reliance on manually handcrafted features. While this has led to some
interesting results, deriving an optimal set of features is considered to be an
art as well as a science and is often an empirical and time consuming process.
In this paper, we address both of these issues and propose a novel CTG analysis
methodology that a) splits CTG time-series signals into n-size windows with
equal class distributions, and b) automatically extracts features from
time-series windows using a one dimensional convolutional neural network
(1DCNN) and multilayer perceptron (MLP) ensemble. Collectively, the proposed
approach normally distributes classes and removes the need to handcrafted
features from CTG traces."
"Predicting medications is a crucial task in many intelligent healthcare
systems. It can assist doctors in making informed medication decisions for
patients according to electronic medical records (EMRs). However, medication
prediction is a challenging data mining task due to the complex relations
between medical codes. Most existing studies focus on utilizing inherent
relations between homogeneous codes of medical ontology graph to enhance their
representations using supervised methods, and few studies pay attention to the
valuable relations between heterogeneous or homogeneous medical codes from
history EMRs, which further limits the prediction performance and application
scenarios. Therefore, to address these limitations, this paper proposes
KnowAugNet, a multi-sourced medical knowledge augmented medication prediction
network which can fully capture the diverse relations between medical codes via
multi-level graph contrastive learning framework. Specifically, KnowAugNet
first leverages the graph contrastive learning using graph attention network as
the encoder to capture the implicit relations between homogeneous medical codes
from the medical ontology graph and obtains the knowledge augmented medical
codes embedding vectors. Then, it utilizes the graph contrastive learning using
a weighted graph convolutional network as the encoder to capture the
correlative relations between homogeneous or heterogeneous medical codes from
the constructed medical prior relation graph and obtains the relation augmented
medical codes embedding vectors. Finally, the augmented medical codes embedding
vectors and the supervised medical codes embedding vectors are retrieved and
input to the sequential learning network to capture the temporal relations of
medical codes and predict medications for patients."