{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd87c8a-63c5-4b2c-9c95-ddf3b3c72181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8893f-ba32-4766-9d51-80b381a326be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physics\n",
    "\n",
    "def search_arxiv_in_category(category, total_results):\n",
    "    query = f\"cat:{category}\"\n",
    "    search = arxiv.Search(query=query, max_results=total_results)\n",
    "    results = arxiv.Client().results(search)\n",
    "    return results\n",
    "\n",
    "def write_paper_info_to_csv(file_path, paper, category, processed_papers):\n",
    "    # Count the number of words in the abstract\n",
    "    word_count = len(paper.summary.split())\n",
    "\n",
    "    # Proceed only if the abstract has at least 50 words\n",
    "    if word_count >= 50:\n",
    "        with open(file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Category', 'Title', 'Authors', 'Abstract', 'URL']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Write the header only if the file is new\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            paper_info = {\n",
    "                'Category': category,\n",
    "                'Title': paper.title,\n",
    "                'Authors': ', '.join([author.name for author in paper.authors]),\n",
    "                'Abstract': paper.summary,\n",
    "                'URL': paper.pdf_url\n",
    "            }\n",
    "            # Use the paper's URL as a unique identifier\n",
    "            paper_key = paper_info['URL']\n",
    "            \n",
    "            print(f\"Processing paper with URL: {paper_key}\")\n",
    "\n",
    "            if paper_key not in processed_papers:\n",
    "                processed_papers.add(paper_key)\n",
    "                writer.writerow(paper_info)\n",
    "    else:\n",
    "        print(f\"Skipped paper with insufficient abstract length: {paper.title}\")\n",
    "\n",
    "def print_paper_info(paper, category):\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Title: {paper.title}\")\n",
    "    \n",
    "    # Extract author names from Author objects\n",
    "    authors = [author.name for author in paper.authors]\n",
    "    print(f\"Authors: {', '.join(authors)}\")\n",
    "    \n",
    "    print(f\"Abstract: {paper.summary}\")\n",
    "    print(f\"URL: {paper.pdf_url}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# List of Physics-related categories\n",
    "physics_categories = [\n",
    "    'physics:gen-ph',   # General Physics\n",
    "    'astro-ph',         # Astrophysics\n",
    "    'astro-ph.CO',      # Cosmology and Non-Galactic Astrophysics\n",
    "    'astro-ph.EP',      # Earth and Planetary Astrophysics\n",
    "    'astro-ph.GA',      # Astrophysics of Galaxies\n",
    "    'astro-ph.HE',      # High Energy Astrophysical Phenomena\n",
    "    'astro-ph.IM',      # Instrumentation and Methods for Astrophysics\n",
    "    'astro-ph.SR',      # Solar and Stellar Astrophysics\n",
    "    'cond-mat',         # Condensed Matter\n",
    "    'cond-mat.dis-nn',  # Disordered Systems and Neural Networks\n",
    "    'cond-mat.mtrl-sci',# Materials Science\n",
    "    'cond-mat.mes-hall',# Mesoscale and Nanoscale Physics\n",
    "    'cond-mat.other',   # Other Condensed Matter\n",
    "    'cond-mat.quant-gas',# Quantum Gases\n",
    "    'cond-mat.soft',    # Soft Condensed Matter\n",
    "    'cond-mat.stat-mech',# Statistical Mechanics\n",
    "    'cond-mat.str-el',  # Strongly Correlated Electrons\n",
    "    'cond-mat.supr-con',# Superconductivity\n",
    "    'gr-qc',            # General Relativity and Quantum Cosmology\n",
    "    'hep-ex',           # High Energy Physics - Experiment\n",
    "    'hep-lat',          # High Energy Physics - Lattice\n",
    "    'hep-ph',           # High Energy Physics - Phenomenology\n",
    "    'hep-th',           # High Energy Physics - Theory\n",
    "    'math-ph',          # Mathematical Physics\n",
    "    'nlin',             # Nonlinear Sciences\n",
    "    'nlin.AO',          # Adaptation and Self-Organizing Systems\n",
    "    'nlin.CG',          # Cellular Automata and Lattice Gases\n",
    "    'nlin.CD',          # Chaotic Dynamics\n",
    "    'nlin.SI',          # Exactly Solvable and Integrable Systems\n",
    "    'nucl-ex',          # Nuclear Experiment\n",
    "    'nucl-th',          # Nuclear Theory\n",
    "    'physics.ed-ph',    # Physics Education\n",
    "    'physics.soc-ph',   # Physics and Society\n",
    "    'quant-ph',         # Quantum Physics\n",
    "    'physics.bio-ph'    # Biological Physics\n",
    "    'physics.app-ph',    # Applied Physics\n",
    "    'physics.ao-ph',     # Atmospheric and Oceanic Physics\n",
    "    'physics.atom-ph',   # Atomic Physics\n",
    "    'physics.atm-clus',  # Atomic and Molecular Clusters\n",
    "    'physics.bio-ph',    # Biological Physics\n",
    "    'physics.chem-ph',   # Chemical Physics\n",
    "    'physics.class-ph',  # Classical Physics\n",
    "    'physics.comp-ph',   # Computational Physics\n",
    "    'physics.data-an',   # Data Analysis, Statistics and Probability\n",
    "    'physics.flu-dyn',   # Fluid Dynamics\n",
    "    'physics.geo-ph',    # Geophysics\n",
    "    'physics.hist-ph',   # History and Philosophy of Physics\n",
    "    'physics.ins-det',   # Instrumentation and Detectors\n",
    "    'physics.med-ph',    # Medical Physics\n",
    "    'physics.optics',    # Optics\n",
    "    'physics.plasm-ph',  # Plasma Physics\n",
    "    'physics.pop-ph',    # Popular Physics\n",
    "    'physics.space-ph',  # Space Physics\n",
    "    'quant-ph',          # Quantum Physics\n",
    "    'math.MP',           # Mathematical Physics (within Mathematics)\n",
    "    'cs.CE',             # Computational Engineering (within Computer Science)\n",
    "    'cs.SY',             # Systems and Control (within Computer Science)\n",
    "    'eess.SP',           # Signal Processing (within Electrical Engineering and Systems Science)\n",
    "    'eess.IV',           # Image and Video Processing (within Electrical Engineering and Systems Science)\n",
    "    'eess.AS'            # Audio and Speech Processing (within Electrical Engineering and Systems Science)\n",
    "]\n",
    "\n",
    "\n",
    "# Set to store processed paper information (URL)\n",
    "processed_papers = set()\n",
    "\n",
    "# Create a single CSV file for all papers\n",
    "output_csv_file = 'physics_papers.csv'\n",
    "\n",
    "# Set the target number of unique papers\n",
    "target_unique_papers = 395\n",
    "\n",
    "# Initialize the count of unique papers written\n",
    "print(len(processed_papers))\n",
    "\n",
    "while len(processed_papers) < target_unique_papers:\n",
    "    category = random.choice(physics_categories)\n",
    "    print(f\"\\nSearching in category: {category}\\n\")\n",
    "    \n",
    "    # Search for recent papers in the randomly selected category\n",
    "    papers_in_category = search_arxiv_in_category(category, total_results=100)\n",
    "    \n",
    "    # Convert the generator to a list\n",
    "    papers_list = list(papers_in_category)\n",
    "    \n",
    "    # Check if there are papers in the list\n",
    "    if not papers_list:\n",
    "        print(f\"No papers found in category: {category}\")\n",
    "        continue\n",
    "\n",
    "    # Print and write information about one random paper in the category to CSV\n",
    "    random_paper = random.choice(papers_list)\n",
    "    write_paper_info_to_csv(output_csv_file, random_paper, category, processed_papers)\n",
    "    \n",
    "    # Update the count of unique papers written\n",
    "    print(len(processed_papers))\n",
    "\n",
    "print(f\"\\nTotal unique papers written to {output_csv_file}: {len(processed_papers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f179a-7904-4233-8180-800246b4cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medicine\n",
    "\n",
    "def search_arxiv_by_keywords(keywords, total_results):\n",
    "    query = ' OR '.join(keywords)  # Constructs a query with multiple keywords\n",
    "    search = arxiv.Search(query=query, max_results=total_results)\n",
    "    results = arxiv.Client().results(search)\n",
    "    return results\n",
    "\n",
    "def write_paper_info_to_csv(file_path, paper, category, processed_papers):\n",
    "    # Count the number of words in the abstract\n",
    "    word_count = len(paper.summary.split())\n",
    "\n",
    "    # Proceed only if the abstract has at least 50 words\n",
    "    if word_count >= 50:\n",
    "        with open(file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Category', 'Title', 'Authors', 'Abstract', 'URL']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Write the header only if the file is new\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            paper_info = {\n",
    "                'Category': category,\n",
    "                'Title': paper.title,\n",
    "                'Authors': ', '.join([author.name for author in paper.authors]),\n",
    "                'Abstract': paper.summary,\n",
    "                'URL': paper.pdf_url\n",
    "            }\n",
    "            # Use the paper's URL as a unique identifier\n",
    "            paper_key = paper_info['URL']\n",
    "            \n",
    "            print(f\"Processing paper with URL: {paper_key}\")\n",
    "\n",
    "            if paper_key not in processed_papers:\n",
    "                processed_papers.add(paper_key)\n",
    "                writer.writerow(paper_info)\n",
    "    else:\n",
    "        print(f\"Skipped paper with insufficient abstract length: {paper.title}\")\n",
    "\n",
    "def print_paper_info(paper, category):\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Title: {paper.title}\")\n",
    "    \n",
    "    # Extract author names from Author objects\n",
    "    authors = [author.name for author in paper.authors]\n",
    "    print(f\"Authors: {', '.join(authors)}\")\n",
    "    \n",
    "    print(f\"Abstract: {paper.summary}\")\n",
    "    print(f\"URL: {paper.pdf_url}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "# List of Medicine-related keywords\n",
    "medicine_keywords = [\n",
    "    'medicine',\n",
    "    'medical',\n",
    "    'health',\n",
    "    'clinical',\n",
    "    'pharmacology',\n",
    "    'disease',\n",
    "    'surgery',\n",
    "    'neurology',\n",
    "    'oncology',\n",
    "    'pathology',\n",
    "    'cardiology',\n",
    "    'dermatology',\n",
    "    'endocrinology',\n",
    "    'gastroenterology',\n",
    "    'hematology',\n",
    "    'hepatology',\n",
    "    'immunology',\n",
    "    'infectious disease',\n",
    "    'nephrology',\n",
    "    'obstetrics',\n",
    "    'gynecology',\n",
    "    'ophthalmology',\n",
    "    'orthopedics',\n",
    "    'otolaryngology',\n",
    "    'pediatrics',\n",
    "    'psychiatry',\n",
    "    'pulmonology',\n",
    "    'radiology',\n",
    "    'rheumatology',\n",
    "    'urology',\n",
    "    'anesthesiology',\n",
    "    'epidemiology',\n",
    "    'geriatrics',\n",
    "    'palliative care',\n",
    "    'rehabilitation',\n",
    "    'preventive medicine',\n",
    "    'public health',\n",
    "    'nutrition',\n",
    "    'diabetes',\n",
    "    'cancer',\n",
    "    'hypertension',\n",
    "    'stroke',\n",
    "    'alzheimer',\n",
    "    'parkinson',\n",
    "    'asthma',\n",
    "    'HIV',\n",
    "    'tuberculosis',\n",
    "    'malaria',\n",
    "    'vaccination',\n",
    "    'genetics',\n",
    "    'genome',\n",
    "    'biomedical',\n",
    "    'bioinformatics',\n",
    "    'nanomedicine',\n",
    "    'robotic surgery',\n",
    "    'telemedicine',\n",
    "    'e-health',\n",
    "    'mental health',\n",
    "    'psychology',\n",
    "    'neurosurgery',\n",
    "    'cardiac surgery',\n",
    "    'transplantation',\n",
    "    'critical care',\n",
    "    'emergency medicine',\n",
    "    'sports medicine',\n",
    "    'pain management',\n",
    "    'dermatology',\n",
    "    'allergology',\n",
    "    'plastic surgery',\n",
    "    'fertility',\n",
    "    'genomics',\n",
    "    'proteomics',\n",
    "    'cell therapy',\n",
    "    'stem cells',\n",
    "    'bioengineering',\n",
    "    'biotechnology',\n",
    "    'medical imaging',\n",
    "    'MRI',\n",
    "    'CT scan',\n",
    "    'ultrasound',\n",
    "    'radiation therapy',\n",
    "    'chemotherapy',\n",
    "    'immunotherapy',\n",
    "    'clinical trials',\n",
    "    'patient care',\n",
    "    'healthcare policy',\n",
    "    'medical ethics',\n",
    "    'virology',\n",
    "    'bacteriology',\n",
    "    'parasitology',\n",
    "    'mycology',\n",
    "]\n",
    "\n",
    "# Set to store processed paper information (URL)\n",
    "processed_papers = set()\n",
    "\n",
    "# Create a single CSV file for all papers\n",
    "output_csv_file = 'medicine_papers.csv'\n",
    "\n",
    "# Set the target number of unique papers\n",
    "target_unique_papers = 395\n",
    "\n",
    "# Initialize the count of unique papers written\n",
    "print(len(processed_papers))\n",
    "\n",
    "while len(processed_papers) < target_unique_papers:\n",
    "    keywords = random.sample(medicine_keywords, k=2)  # Randomly select 2 keywords\n",
    "    print(f\"\\nSearching with keywords: {keywords}\\n\")\n",
    "    \n",
    "    # Search for recent papers using the randomly selected keywords\n",
    "    papers_by_keywords = search_arxiv_by_keywords(keywords, total_results=100)\n",
    "    \n",
    "    # Convert the generator to a list\n",
    "    papers_list = list(papers_by_keywords)\n",
    "    \n",
    "    # Check if there are papers in the list\n",
    "    if not papers_list:\n",
    "        print(f\"No papers found for keywords: {keywords}\")\n",
    "        continue\n",
    "\n",
    "    # Print and write information about one random paper to CSV\n",
    "    random_paper = random.choice(papers_list)\n",
    "    write_paper_info_to_csv(output_csv_file, random_paper, ', '.join(keywords), processed_papers)\n",
    "    \n",
    "    # Update the count of unique papers written\n",
    "    print(len(processed_papers))\n",
    "\n",
    "print(f\"\\nTotal unique papers written to {output_csv_file}: {len(processed_papers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523c134-7359-4242-b5cc-978b57f0338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cyber-Security\n",
    "\n",
    "def search_arxiv_by_keywords(keywords, total_results):\n",
    "    query = ' OR '.join(keywords)  # Constructs a query with multiple keywords\n",
    "    search = arxiv.Search(query=query, max_results=total_results)\n",
    "    results = arxiv.Client().results(search)\n",
    "    return results\n",
    "\n",
    "def write_paper_info_to_csv(file_path, paper, category, processed_papers):\n",
    "    # Count the number of words in the abstract\n",
    "    word_count = len(paper.summary.split())\n",
    "\n",
    "    # Proceed only if the abstract has at least 50 words\n",
    "    if word_count >= 50:\n",
    "        with open(file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Category', 'Title', 'Authors', 'Abstract', 'URL']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Write the header only if the file is new\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            paper_info = {\n",
    "                'Category': category,\n",
    "                'Title': paper.title,\n",
    "                'Authors': ', '.join([author.name for author in paper.authors]),\n",
    "                'Abstract': paper.summary,\n",
    "                'URL': paper.pdf_url\n",
    "            }\n",
    "            # Use the paper's URL as a unique identifier\n",
    "            paper_key = paper_info['URL']\n",
    "            \n",
    "            print(f\"Processing paper with URL: {paper_key}\")\n",
    "\n",
    "            if paper_key not in processed_papers:\n",
    "                processed_papers.add(paper_key)\n",
    "                writer.writerow(paper_info)\n",
    "    else:\n",
    "        print(f\"Skipped paper with insufficient abstract length: {paper.title}\")\n",
    "\n",
    "def print_paper_info(paper, category):\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Title: {paper.title}\")\n",
    "    \n",
    "    # Extract author names from Author objects\n",
    "    authors = [author.name for author in paper.authors]\n",
    "    print(f\"Authors: {', '.join(authors)}\")\n",
    "    \n",
    "    print(f\"Abstract: {paper.summary}\")\n",
    "    print(f\"URL: {paper.pdf_url}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "# List of Medicine-related keywords\n",
    "cybersecurity_keywords = [\n",
    "    'cybersecurity',\n",
    "    'information security',\n",
    "    'network security',\n",
    "    'computer security',\n",
    "    'cyber attack',\n",
    "    'malware',\n",
    "    'ransomware',\n",
    "    'phishing',\n",
    "    'spear phishing',\n",
    "    'DDoS',\n",
    "    'denial of service',\n",
    "    'data breach',\n",
    "    'encryption',\n",
    "    'cryptography',\n",
    "    'firewall',\n",
    "    'intrusion detection',\n",
    "    'intrusion prevention',\n",
    "    'security policy',\n",
    "    'risk management',\n",
    "    'vulnerability analysis',\n",
    "    'penetration testing',\n",
    "    'ethical hacking',\n",
    "    'zero-day',\n",
    "    'zero-day exploit',\n",
    "    'cyber espionage',\n",
    "    'cyber warfare',\n",
    "    'social engineering',\n",
    "    'identity theft',\n",
    "    'security audit',\n",
    "    'compliance',\n",
    "    'forensics',\n",
    "    'cyber forensics',\n",
    "    'incident response',\n",
    "    'threat intelligence',\n",
    "    'endpoint security',\n",
    "    'antivirus',\n",
    "    'malware analysis',\n",
    "    'cybercrime',\n",
    "    'botnet',\n",
    "    'VPN',\n",
    "    'virtual private network',\n",
    "    'blockchain',\n",
    "    'IoT security',\n",
    "    'internet of things',\n",
    "    'cloud security',\n",
    "    'mobile security',\n",
    "    'biometric security',\n",
    "    'two-factor authentication',\n",
    "    'multi-factor authentication',\n",
    "    'cyber law',\n",
    "    'privacy',\n",
    "    'data protection',\n",
    "    'GDPR',\n",
    "    'CCPA',\n",
    "    'ISO 27001',\n",
    "    'NIST framework',\n",
    "    'cybersecurity awareness',\n",
    "    'SIEM',\n",
    "    'security information and event management',\n",
    "    'artificial intelligence in security',\n",
    "    'machine learning in security',\n",
    "    'cybersecurity training',\n",
    "    'cyber insurance',\n",
    "    'APT',\n",
    "    'advanced persistent threat',\n",
    "    'security operations center',\n",
    "    'SOC',\n",
    "    'security architecture',\n",
    "    'cyber resilience',\n",
    "    'critical infrastructure security',\n",
    "    'SCADA security',\n",
    "    'industrial control systems security',\n",
    "    'quantum cryptography',\n",
    "    'quantum computing and security',\n",
    "    'cybersecurity policy',\n",
    "    'cybersecurity regulation',\n",
    "    'ethical issues in cybersecurity',\n",
    "    'cybersecurity and ethics',\n",
    "    'cyber deterrence',\n",
    "    'cybersecurity standards',\n",
    "    'cybersecurity best practices',\n",
    "    'cybersecurity governance',\n",
    "    'cybersecurity strategy',\n",
    "    'cyber threat landscape',\n",
    "    'cybersecurity metrics',\n",
    "    'cybersecurity frameworks',\n",
    "    'cyber risk assessment',\n",
    "    'cybersecurity culture',\n",
    "    'cybersecurity in healthcare',\n",
    "    'cybersecurity in finance',\n",
    "    'cybersecurity in government',\n",
    "    'cybersecurity in education',\n",
    "    'cybersecurity in business',\n",
    "    'cybersecurity in critical sectors',\n",
    "    'cybersecurity challenges',\n",
    "    'emerging cybersecurity technologies',\n",
    "    'cybersecurity innovation',\n",
    "    '5G security',\n",
    "    'wireless security',\n",
    "    'network defense',\n",
    "    'cybersecurity and COVID-19',\n",
    "    'remote work security',\n",
    "    'cybersecurity and remote work',\n",
    "    'cybersecurity in the post-COVID era',\n",
    "    'cybersecurity and globalization',\n",
    "    'cybersecurity in developing countries',\n",
    "    'cybersecurity and international relations',\n",
    "    'cybersecurity and geopolitics',\n",
    "    'cybersecurity in elections',\n",
    "    'cybersecurity and democracy',\n",
    "    'cybersecurity legislation',\n",
    "    'cybersecurity law and policy',\n",
    "    'cybersecurity and human rights',\n",
    "    'cybersecurity ethics and law',\n",
    "]\n",
    "\n",
    "# Set to store processed paper information (URL)\n",
    "processed_papers = set()\n",
    "\n",
    "# Create a single CSV file for all papers\n",
    "output_csv_file = 'cybersecurity_papers.csv'\n",
    "\n",
    "# Set the target number of unique papers\n",
    "target_unique_papers = 395\n",
    "\n",
    "# Initialize the count of unique papers written\n",
    "print(len(processed_papers))\n",
    "\n",
    "while len(processed_papers) < target_unique_papers:\n",
    "    keywords = random.sample(cybersecurity_keywords, k=4)  # Randomly select 4 keywords\n",
    "    print(f\"\\nSearching with keywords: {keywords}\\n\")\n",
    "    \n",
    "    # Search for recent papers using the randomly selected keywords\n",
    "    papers_by_keywords = search_arxiv_by_keywords(keywords, total_results=100)\n",
    "    \n",
    "    # Convert the generator to a list\n",
    "    papers_list = list(papers_by_keywords)\n",
    "    \n",
    "    # Check if there are papers in the list\n",
    "    if not papers_list:\n",
    "        print(f\"No papers found for keywords: {keywords}\")\n",
    "        continue\n",
    "\n",
    "    # Print and write information about one random paper to CSV\n",
    "    random_paper = random.choice(papers_list)\n",
    "    write_paper_info_to_csv(output_csv_file, random_paper, ', '.join(keywords), processed_papers)\n",
    "    \n",
    "    # Update the count of unique papers written\n",
    "    print(len(processed_papers))\n",
    "\n",
    "print(f\"\\nTotal unique papers written to {output_csv_file}: {len(processed_papers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4c47e-3077-4f95-b168-d2fbdf10dee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
